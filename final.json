{"1":[{"index":1,"questions":"1. You have been tasked with interviewing line-of-business owners about their needs for a new cloud application. Which of the following do you expect to find?","choices":["A. A comprehensive list of defined business and technical requirements","B. That their business requirements do not have a one-to-one correlation with technical requirements","C. Business and technical requirements in conflict","D. Clear consensus on all requirements"],"answer":"1. B. The correct answer is B. Business requirements are high-level, business-orientedrequirements that are rarely satisfied by meeting a single technical requirement. OptionA is incorrect because business sponsors rarely have sufficient understanding of technicalrequirements in order to provide a comprehensive list. Option C is incorrect, because busi-ness requirements constrain technical options but should not be in conflict. Option D isincorrect because there is rarely a clear consensus on all requirements. Part of an architect’sjob is to help stakeholders reach a consensus."},{"index":2,"questions":"2. You have been asked by stakeholders to suggest ways to reduce operational expenses as part of a cloud migration project. Which of the following would you recommend?","choices":["A. Managed services, preemptible machines, access controls","B. Managed services, preemptible machines, autoscaling","C. NoSQL databases, preemptible machines, autoscaling","D. NoSQL databases, preemptible machines, access controls"],"answer":"2. B. The correct answer is B. Managed services relieve DevOps work, preemptible machinescost significantly less than standard VMs, and autoscaling reduces the chances of runningunnecessary resources. Options A and D are incorrect because access controls will not helpreduce costs, but they should be used anyway. Options C and D are incorrect because thereis no indication that a NoSQL database should be used."},{"index":3,"questions":"3. Some executives are questioning your recommendation to employ continuous integration/ continuous deployment (CI/CD). What reasons would you give to justify your recommendation?","choices":["A. CI/CD supports small releases, which are easier to debug and enable faster feedback.","B. CI/CD is used only with preemptible machines and therefore saves money.","C. CI/CD fits well with waterfall methodology but not agile methodologies.","D. CI/CD limits the number of times code is released."],"answer":"3. A. The correct answer is A. CI/CD supports small releases, which are easier to debugand enable faster feedback. Option B is incorrect, as CI/CD does not only use preemptiblemachines. Option C is incorrect because CI/CD works well with agile methodologies. OptionD is incorrect, as there is no limit to the number of times new versions of code can be released."},{"index":4,"questions":"4. The finance director has asked your advice about complying with a document retention regulation. What kind of service-level objective (SLO) would you recommend to ensure that the finance director will be able to retrieve sensitive documents for at least the next seven years? When a document is needed, the finance director will have up to seven days to retrieve it. The total storage required will be approximately 100 GB.","choices":["A. High availability SLO","B. Durability SLO","C. Reliability SLO","D. Scalability SLO"],"answer":"4. B. The correct answer is B. The finance director needs to have access to documents forseven years. This requires durable storage. Option A is incorrect because the access doesnot have to be highly available; as long as the finance director can access the document in areasonable period of time, the requirement can be met. Option C is incorrect because reli-ability is a measure of being available to meet workload demands successfully. Option D isincorrect because the requirement does not specify the need for increasing and decreasingstorage to meet the requirement."},{"index":5,"questions":"5. You are facilitating a meeting of business and technical managers to solicit requirements for a cloud migration project. The term incident comes up several times. Some of the business managers are unfamiliar with this term in the context of IT. How would you describe an incident?","choices":["A. A disruption in the ability of a DevOps team to complete work on time","B. A disruption in the ability of the business managers to approve a project plan on schedule","C. A disruption that causes a service to be degraded or unavailable","D. A personnel problem on the DevOps team"],"answer":"5. C. The correct answer is C. An incident in the context of IT operations and service reliabil-ity is a disruption that degrades or stops a service from functioning. Options A and B areincorrect—incidents are not related to scheduling. Option D is incorrect; in this context,incidents are about IT services, not personnel."},{"index":6,"questions":"6. You have been asked to consult on a cloud migration project that includes moving private medical information to a storage system in the cloud. The project is for a company in the United States. What regulation would you suggest that the team review during the requirements-gathering stages?","choices":["A. General Data Protection Regulations (GDPR)","B. Sarbanes–Oxley (SOX)","C. Payment Card Industry Data Security Standard (PCI DSS)","D. Health Insurance Portability and Accountability Act (HIPAA)"],"answer":"6. D. The correct answer is D. HIPAA governs, among other things, privacy and data protec-tions for private medical information. Option A is incorrect, as GDPR is a European Unionregulation. Option B is incorrect, as SOX is a U.S. financial reporting regulation. Option Cis incorrect, as PCI DSS is a payment card industry regulation."},{"index":7,"questions":"7. You are in the early stages of gathering business and technical requirements. You have noticed several references about needing up-to-date and consistent information regarding product inventory. Inventory is managed on a global scale, and the warehouses storing inventory are located in North America, Africa, Europe, and India. Which managed database solution in Google Cloud would you include in your set of options for an inventory database?","choices":["A. Cloud Storage","B. BigQuery","C. Cloud Spanner","D. Microsoft SQL Server"],"answer":"7. C. The correct answer is C. Cloud Spanner is a globally consistent, horizontally scalablerelational database. Option A is incorrect. Cloud Storage is not a database; rather, it is anobject storage system. Option B is incorrect because BigQuery is an analytics database.Option D is incorrect, as Microsoft SQL Server is not a managed database in Google Cloud."},{"index":8,"questions":"8. A developer at Mountkirk Games is interested in how architects decide which database to use. The developer describes a use case that requires a document store. The developer would rather not manage database servers or have to run backups. What managed service would you suggest the developer consider?","choices":["A. Cloud Datastore","B. Cloud Spanner","C. Cloud Storage","D. BigQuery"],"answer":"8. A. The correct answer is A. Cloud Datastore is a managed document database and a goodfit for storing documents. Option B is incorrect because Cloud Spanner is a relationaldatabase and globally scalable. There is no indication that the developer needs a glob-ally scalable solution. Option C is incorrect, as Cloud Storage is an object storage system,not a managed database. Option D is incorrect because BigQuery is an analytic databasedesigned for data warehousing and similar applications."},{"index":9,"questions":"9. Members of your company’s legal team are concerned about using a public cloud service because other companies, organizations, and individuals will be running their systems in the same cloud. You assure them that your company’s resources will be isolated and not network-accessible to others because of what networking resource in Google Cloud?","choices":["A. CIDR blocks","B. Direct connections","C. Virtual private clouds","D. Cloud Pub/Sub"],"answer":"9. C. The correct answer is C. VPCs isolate cloud resources from resources in other VPCs,unless VPCs are intentionally linked. Option A is incorrect because a CIDR block hasto do with subnet IP addresses. Option B is incorrect, as direct connections are for trans-mitting data between a data center and Google Cloud—it does not protect resources inthe cloud. Option D is incorrect because Cloud Pub/Sub is a messaging service, not a net-working service."},{"index":10,"questions":"10. What two business drivers are behind Dress4Win’s interest in moving to the cloud?","choices":["A. Insufficient infrastructure capacity and desire to be more agile","B. Insufficient infrastructure and competitors moving to the cloud","C. Competitors moving to the cloud and desire to be more agile","D. Insufficient infrastructure and short-term cost savings"],"answer":"10. A. The correct answer is A. Dress4Win is at capacity with its existing infrastructure andwants to innovate faster. Options B and C are incorrect because the decision is not influ-enced by competitors moving to the cloud. Option D is incorrect because short-term costsavings are not a consideration."},{"index":11,"questions":"11. Dress4Win is considering replacing its self-managed MySQL database with a managed service. Which Google Cloud service would you recommend that they consider?","choices":["A. Cloud Dataproc","B. Cloud Dataflow","C. Cloud SQL","D. PostgreSQL"],"answer":"11. C. The correct answer is C. Cloud SQL offers a managed MySQL service. Options A andB are incorrect, as neither is a database. Cloud Dataproc is a managed Hadoop and Sparkservice. Cloud Dataflow is a stream and batch processing service. Option D is incorrect,because PostgreSQL is another relational database, but it is not a managed service. Post-greSQL is an option in Cloud SQL, however."},{"index":12,"questions":"12. Which of the following requirements from a customer makes you think the application should run in Compute Engine and not App Engine?","choices":["A. Dynamically scale up or down based on game activity","B. Connect to a database","C. Run a hardened Linux distro on a virtual machine","D. Don’t lose data"],"answer":"12. C. The correct answer is C. In Compute Engine, you create virtual machines and choosewhich operating system to run. All other requirements can be realized in App Engine."},{"index":13,"questions":"13. Consider the TerramEarth case study. What aspect of that case study prompts you to consider potentially significant changes to requirements in the future?","choices":["A. Dealers will want more reports about their customers.","B. Of 20 million pieces of equipment, only 200,000 have cellular connections; 19,800,000 additional pieces of equipment may someday transmit data in real time instead of downloading it in batches.","C. TerramEarth is in a competitive industry.","D. TerramEarth would like to partner with other companies to improve overall service to their customers."],"answer":"13. B. The correct answer is B. A significant increase in the use of streaming input willrequire changes to how data is ingested and require scalable ingestion services. Anincrease of almost two orders of magnitude in the number of pieces of equipmenttransmitting data will likely require architectural changes. Option A is incorrect, asadditional reporting is easily accommodated. Option C is incorrect because the initialdesign will take into account that TerramEarth is in a competitive industry. Option D isincorrect, as collaborating with other companies will not require significant changes insystems design."},{"index":14,"questions":"14. Mountkirk Games wants to store player game data in a time-series database. Which Google Cloud managed database would you recommend?","choices":["A. Bigtable","B. BigQuery","C. Cloud Storage","D. Cloud Dataproc"],"answer":"14. A. The correct answer is A. Cloud Bigtable is a scalable, wide-column database designedfor low-latency writes, making it a good choice for time-series data. Option B is incor-rect because BigQuery is an analytic database not designed for the high volume oflow-latency writes that will need to be supported. Options C and D are not manageddatabases."},{"index":15,"questions":"15. The game analytics platform for Mountkirk Games requires analysts to be able to query up to 10 TB of data. What is the best managed database solution for this requirement?","choices":["A. Cloud Spanner","B. BigQuery","C. Cloud Storage","D. Cloud Dataprep"],"answer":"15. B. The correct answer is B. This is a typical use case for BigQuery, and it fits well with itscapabilities as an analytic database. Option A is incorrect, as Cloud Spanner is best usedfor transaction processing on a global scale. Options C and D are not managed databases.Cloud Storage is an object storage service; Cloud Dataprep is a tool for preparing datafor analysis.Requirements"}],"2":[{"index":1,"questions":"1. In the Dress4Win case study, the volume of data and compute load will grow with respect to what factor?","choices":["A. The number of customers, designers, and retailers","B. The time the application is running","C. The type of storage used","D. Compliance with regulations"],"answer":"1. A. Option A is correct. Dress4Win is a consumer, e-commerce service that will growwith respect to the number of customers. Also, the number of designers and retailers willinfluence the growth in demand for compute and storage resources. Option B is incorrectbecause the length of run time is not relevant to compute or storage requirements. The typeof storage used does not influence the amount of data the application needs to manage, orthe amount of computing resources needed. Compliance and regulations may have someeffect on security controls and monitoring, but it will not influence compute and storageresources in a significant way."},{"index":2,"questions":"2. You have received complaints from customers about long wait times while loading application pages in their browsers, especially pages with several images. Your director has tasked you with reducing latency when accessing and transmitting data to a client device outside the cloud. Which of the following would you use? (Choose two.)","choices":["A. Multiregional storage","B. Coldline storage","C. CDN","D. Cloud Pub/Sub","E. Cloud Dataflow"],"answer":"2. A, C. Options A and C are correct. Both multiregional cloud storage and CDNs distributedata across a geographic area. Option B is incorrect because Coldline storage is used forarchiving. Option D is incorrect because Cloud Pub/Sub is a messaging queue, not a storagesystem. Option E is a managed service for batch and stream processing."},{"index":3,"questions":"3. Mountkirk Games will analyze game players’ usage patterns. This will require collecting time-series data including game state. What database would be a good option for doing this?","choices":["A. BigQuery","B. Bigtable","C. Cloud Spanner","D. Cloud Storage"],"answer":"3. B. Option B is correct. High volumes of time-series data need low-latency writes and scal-able storage. Time-series data is not updated after it is collected. This makes Bigtable, awide-column data store with low-latency writes, the best option. Option A is wrong becauseBigQuery is an analytic database designed for data warehousing. Option C is wrongbecause Cloud Spanner is a global relational database. Write times would not be as fast asthey would be using Bigtable, and the use case does not take advantage of Cloud Spanner’sstrong consistency in a horizontally scalable relational database. Option D is not a goodoption because it is an object store, and it is not designed for large volumes of individualtime-series data points."},{"index":4,"questions":"4. You have been hired to consult with a new data warehouse team. They are struggling to meet schedules because they repeatedly find problems with data quality and have to write preprocessing scripts to clean the data. What managed service would you recommend for addressing these problems?","choices":["A. Cloud Dataflow","B. Cloud Dataproc","C. Cloud Dataprep","D. Cloud Datastore"],"answer":"4. A. Option A is correct. Cloud Dataflow is a batch and stream processing service that can beused for transforming data before it is loaded into a data warehouse. Option C is incorrect,Cloud Dataprep is used to prepare data for analysis and machine learning. Option B, CloudDataproc, is a managed Hadoop and Spark service, not a data cleaning and preparing ser-vice. Option D, Cloud Datastore, is a document database, not a data processing service."},{"index":5,"questions":"5. You have deployed an application that receives data from sensors on TerramEarth equipment. Sometimes more data arrives than can be processed by the current set of Compute Engine instances. Business managers do not want to run additional VMs. What changes could you make to ensure that data is not lost because it cannot be processed as it is sent from the equipment? Assume that business managers want the lowest-cost solution.","choices":["A. Write data to local SSDs on the Compute Engine VMs.","B. Write data to Cloud Memorystore, and have the application read data from the cache.","C. Write data from the equipment to a Cloud Pub/Sub queue, and have the application read data from the queue.","D. Tune the application to run faster."],"answer":"5. C. The correct answer is C, write data to a Cloud Pub/Sub topic. The data can accumulatethere as the application processes the data. No data is lost because Pub/Sub will scale asneeded. Option A is not a good option because local storage does not scale. Option B is not agood choice because caches are used to provide low-latency access to data that is frequentlyaccessed. Cloud Memorystore does not scale as well as Cloud Pub/Sub, and it may run out ofspace. Option D is not a good choice because tuning will require developers to invest poten-tially significant amounts of time without any guarantee of solving the problem. Also, evenwith optimizations, even larger spikes in data ingestion could result in the same problem ofthe processing application not being able to keep up with the rate at which data is arriving."},{"index":6,"questions":"6. Your company uses Apache Spark for data science applications. Your manager has asked you to investigate running Spark in the cloud. Your manager’s goal is to lower the overall cost of running and managing Spark. What would you recommend?","choices":["A. Run Apache Spark in Compute Engine.","B. Use Cloud Dataproc with preemptible virtual machines.","C. Use Cloud Dataflow with preemptible virtual machines.","D. Use Cloud Memorystore with Apache Spark running in Compute Engine."],"answer":"6. B. Option B is correct. Using Cloud Dataproc will reduce the costs of managing the Sparkcluster, while using preemptible VMs will reduce the compute charges. Option A is notthe best option because you will have to manage the Spark cluster yourself, which willincrease the total cost of ownership. Option C is incorrect as Cloud Dataflow is not amanaged Spark service. Option D is incorrect because Cloud Memorystore does not reducethe cost of running Apache Spark and managing a cluster in Compute Engine is not themost cost-effective."},{"index":7,"questions":"7. You are working with a U.S. hospital to extract data from an electronic health record (EHR) system. The hospital has offered to provide business requirements, but there is little information about regulations in the documented business requirements. What regulations would you look to for more guidance on complying with relevant regulations?","choices":["A. GDPR","B. SOX","C. HIPAA","D. PCI DSS"],"answer":"7. C. The relevant health regulation is HIPAA, which regulates healthcare data in the UnitedStates. Option A is incorrect, as GDPR is a European Union privacy regulation. OptionB is incorrect, as SOX is a regulation that applies to the financial industry. Option D isincorrect, because the Payment Card Industry Data Security Standard does not apply tohealthcare data."},{"index":8,"questions":"8. What security control can be used to help detect changes to data?","choices":["A. Firewall rules","B. Message digests","C. Authentication","D. Authorization"],"answer":"8. B. Option B is correct. Message digests are used to detect changes in files. Option A isincorrect because firewall rules block network traffic and are not related to detectingchanges to data. Options C and D are important for controlling access to data, but they arenot directly related to detecting changes to data."},{"index":9,"questions":"9. Your company has a data classification scheme for categorizing data as secret, sensitive, private, and public. There are no confidentiality requirements for public data. All other data must be encrypted at rest. Secret data must be encrypted with keys that the company controls. Sensitive and private data can be encrypted with keys managed by a third party. Data will be stored in GCP. What would you recommend in order to meet these requirements while minimizing cost and administrative overhead?","choices":["A. Use Cloud KMS to manage keys for all data.","B. Use Cloud KMS for secret data and Google default encryption for other data.","C. Use Google default encryption for all data.","D. Use a custom encryption algorithm for all data."],"answer":"9. B. B is correct. Cloud KMS allows the customer to manage keys used to encrypt secretdata. The requirements for the other categories are met by GCP’s default encryption-at-restpractice. Public data does not need to be encrypted, but there is no additional cost or over-head for having it encrypted at rest. Option A would meet the security requirements, butit would involve managing keys for more data than is necessary, and that would increaseadministrative overhead. Option C does not meet the requirements of secret data. Option Dis a terrible choice. Encryption algorithms are difficult to develop and potentially vulnerableto cryptanalysis attacks. It would cost far more to develop a strong encryption algorithmthan to use Cloud KMS and default encryption."},{"index":10,"questions":"10. You manage a service with several databases. The queries to the relational database are increasing in latency. Reducing the amount of data in tables will improve performance and reduce latency. The application administrator has determined that approximately 60 percent of the data in the database is more than 90 days old and has never been queried and does not need to be in the database. You are required to keep the data for five years in case it is requested by auditors. What would you propose to decrease query latency without increasing costs—or at least keeping any cost increases to a minimum?","choices":["A. Horizontally scale the relational database.","B. Vertically scale the relational database.","C. Export data more than 90 days old, store it in Cloud Storage Coldline class storage, and delete that data from the relational database.","D. Export data more than 90 days old, store it in Cloud Storage multiregional class storage, and delete that data from the relational database."],"answer":"10. C. The correct answer is C. Data that is not queried does not need to be in the database tomeet business requirements. If the data is needed, it can be retrieved from other storage sys-tems, such as Cloud Storage. Exporting and deleting data will reduce the amount of data intables and improve performance. Since the data is rarely accessed, it is a good candidate forarchival, Coldline storage. Answers A and B are incorrect because scaling either verticallyor horizontally will increase costs more than the cost of storing the data in archival storage.Option D is incorrect because multiregional storage is more expensive than Coldline stor-age and multiregion access is not needed."},{"index":11,"questions":"11. Your company is running several custom applications that were written by developers who are no longer with the company. The applications frequently fail. The DevOps team is paged more for these applications than any others. You propose replacing those applications with several managed services in GCP. A manager who is reviewing your cost estimates for using managed services in GCP notes that the cost of the managed services will be more than what they pay for internal servers. What would you recommend as the next step for the manager?","choices":["A. Nothing. The manager is correct—the costs are higher. You should reconsider your recommendation.","B. Suggest that the manager calculate total cost of ownership, which includes the cost to support the applications as well as infrastructure costs.","C. Recommend running the custom applications in Compute Engine to lower costs.","D. Recommend rewriting the applications to improve reliability."],"answer":"11. B. Option B is correct. The manager does not have an accurate cost estimate of supportingthe applications if operational support costs are not considered. The manager should havean accurate estimate of TCO before proceeding. Option A is incorrect because the managerdoes not have an accurate estimate of all costs. Option C is incorrect because it does notaddress the reliability issues with the applications. Option D may be a reasonable option,but if managed services meet the requirements, using them will solve the reliability issuesfaster than developing new applications."},{"index":12,"questions":"12. A director at Mountkirk Games has asked for your recommendation on how to measure the success of the migration to GCP. The director is particularly interested in customer satisfaction. What KPIs would you recommend?","choices":["A. Average revenue per customer per month","B. Average time played per customer per week","C. Average time played per customer per year","D. Average revenue per customer per year"],"answer":"12. B. Option B is the best answer because it is a measure of how much customers are engagedin the game and playing. If average time played goes down, this is an indicator that cus-tomers are losing interest in the game. If the average time played goes up, they are moreengaged and interested in the game. Options A and D are incorrect because revenue doesnot necessarily correlate with customer satisfaction. Also, it may not correlate with howmuch customers played the game if revenue is based on monthly subscriptions, for example.Option C is wrong because a year is too long a time frame for detecting changes as rapidlyas one can with a weekly measure."},{"index":13,"questions":"13. Mountkirk Games is implementing a player analytics system. You have been asked to document requirements for a stream processing system that will ingest and preprocess data before writing it to the database. The preprocessing system will collect data about each player for one minute and then write a summary of statistics about that database. The project manager has provided the list of statistics to calculate and a rule for calculating values for missing data. What other business requirements would you ask of the project manager?","choices":["A. How long to store the data in the database?","B. What roles and permissions should be in place to control read access to data in the database?","C. How long to wait for late-arriving data?","D. A list of managed services that can be used in this project"],"answer":"13. C. Option C is correct. In stream processing applications that collect data for a time andthen produce summary or aggregated data, there needs to be a limit on how long the pro-cessor waits for late-arriving data before producing results. Options A and B are incorrectbecause you do not need to know requirements for data lifecycle management or accesscontrols to the database at this point, since your focus is on ingesting raw data and writingstatistics to the database. Option D is incorrect. An architect should provide that list to aproject manager, not the other way around."},{"index":14,"questions":"14. A new data warehouse project is about to start. The data warehouse will collect data from 14 different sources initially, but this will likely grow over the next 6 to 12 months. What managed GCP service would you recommend for managing metadata about the data warehouse sources?","choices":["A. Data Catalog","B. Cloud Dataprep","C. Cloud Dataproc","D. BigQuery"],"answer":"14. A. The correct option is A. Data Catalog is a managed service for metadata. Option Bis incorrect, as Dataprep is a tool for preparing data for analysis and machine learning.Option C is incorrect, as Dataproc is a managed Hadoop and Spark service. Option D isincorrect because BigQuery is a database service designed for analytic databases and datawarehousing."},{"index":15,"questions":"15. You are consulting for a multinational company that is moving its inventory system to GCP. The company wants to use a managed database service, and it requires SQL and strong consistency. The database should be able to scale to global levels. What service would you recommend?","choices":["A. Bigtable","B. Cloud Spanner","C. Cloud Datastore","D. BigQuery"],"answer":"15. B. The correct option is B. Cloud Spanner is a horizontally scalable relational database thatprovides strong consistency, SQL, and scales to a global level. Options A and C are incor-rect because they do not support SQL. Option D is incorrect because an inventory systemis a transaction processing system, and BigQuery is designed for analytic, not transactionprocessing systems."},{"index":16,"questions":"16. TerramEarth has interviewed dealers to better understand their needs regarding data. Dealers would like to have access to the latest data available, and they would like to minimize the amount of data they have to store in their databases and object storage systems. How would you recommend that TerramEarth provide data to their dealers?","choices":["A. Extract dealer data to a CSV file once per night during off-business hours and upload it to a Cloud Storage bucket accessible to the dealer.","B. Create an API that dealers can use to retrieve specific pieces of data on an as-needed basis.","C. Create a database dump using the database export tool so that dealers can use the database import tool to load the data into their databases.","D. Create a user account on the database for each dealer and have them log into the database to run their own queries."],"answer":"16. B. Option B is correct. An API would allow dealers to access up-to-date informationand allow them to query only for the data that they need. Dealers do not need to knowimplementation details of TerramEarth’s database. Options A and C are incorrect becausenightly extracts or exports would not give access to up-to-date data, which could changeduring the day. Option D is incorrect because it requires the dealers to understand how toquery a relational database. Also, it is not a good practice to grant direct access to impor-tant business databases to people or services outside the company."},{"index":17,"questions":"17. Your company has large volumes of unstructured data stored on several network-attached storage systems. The maintenance costs are increasing, and management would like to consider alternatives. What GCP storage system would you recommend?","choices":["A. Cloud SQL","B. Cloud Storage","C. Cloud Datastore","D. Bigtable"],"answer":"17. B. The correct option is B. Cloud Storage is an object storage system well suited to stor-ing unstructured data. Option A is incorrect because Cloud SQL provides relational data-bases that are used for structured data. Option C is incorrect because Cloud Datastore is aNoSQL document database used with flexible schema data. Option D is incorrect, as Big-table is a wide-column database that is not suitable for unstructured data."},{"index":18,"questions":"18. A customer-facing application is built using a microservices architecture. One of the services does not scale as fast as the service that sends it data. This causes the sending service to wait while the other service processes the data. You would like to change the integration to use asynchronous instead of synchronous calls. What is one way to do this?","choices":["A. Create a Cloud Pub/Sub topic, have the sending service write data to the topic, and have the receiving service read from the topic.","B. Create a Cloud Storage bucket, have the sending service write data to the topic, and have the receiving service read from the topic.","C. Have the sending service write data to local drives, and have the receiving service read from those drives.","D. Create a Bigtable database, have the sending service write data to the topic, and have the receiving service read from the topic."],"answer":"18. A. Option A is correct. Cloud Pub/Sub is designed to provide messaging services and fitsthis use case well. Options B and D are incorrect because, although you may be able toimplement asynchronous message exchange using those storage systems, it would be inef-ficient and require more code than using Cloud Pub/Sub. Option C is incorrect because thiswould require both the sending and receiving services to run on the same VM."},{"index":19,"questions":"19. A product manager at TerramEarth would like to use the data that TerramEarth collects to predict when equipment will break down. What managed services would you recommend TerramEarth to consider?","choices":["A. Bigtable","B. Cloud Dataflow","C. Cloud AutoML","D. Cloud Spanner"],"answer":"19. C. The correct answer is C. Cloud AutoML is a managed service for building machinelearning models. TerramEarth’s data could be used to build a predictive model usingAutoML. Options A and D are incorrect—they are databases and do not have the toolsfor building predictive models. Option B is wrong because Cloud Dataflow is a stream andbatch processing service.Requirements"}],"3":[{"index":1,"questions":"1. You are advising a customer on how to improve the availability of a data storage solution. Which of the following general strategies would you recommend?","choices":["A. Keeping redundant copies of the data","B. Lowering the network latency for disk writes","C. Using a NoSQL database","D. Using Cloud Spanner"],"answer":"1. A. The correct answer is A. Redundancy is a general strategy for improving availability.Option B is incorrect because lowering network latency will not improve availability ofthe data storage system. Options C and D are incorrect because there is no indication thateither a NoSQL or a relational database will meet the overall storage requirements of thesystem being discussed."},{"index":2,"questions":"2. A team of data scientists is analyzing archived data sets. The model building procedures run in batches. If the model building system is down for up to 30 minutes per day, it does not adversely impact the data scientists’ work. What is the minimal percentage availability among the following options that would meet this requirement?","choices":["A. 99.99 percent","B. 99.90 percent","C. 99.00 percent","D. 99.999 percent"],"answer":"2. C. The minimum percentage availability that meets the requirements is option C, whichallows for up to 14.4 minutes of downtime per day. All other options would allow for lessdowntime, but that is not called for by the requirements."},{"index":3,"questions":"3. Your development team has recently triggered three incidents that resulted in service disruptions. In one case, an engineer mistyped a number in a configuration file and in the other cases specified an incorrect disk configuration. What practices would you recommend to reduce the risk of these types of errors?","choices":["A. Continuous integration/continuous deployment","B. Code reviews of configuration files","C. Vulnerability scanning","D. Improved access controls"],"answer":"3. B. The correct answer is B. A code review is a software engineering practice that requiresan engineer to review code with another engineer before deploying it. Option A wouldnot solve the problem, as continuous integration reduces the amount of effort required todeploy new versions of software. Options C and D are both security controls, which wouldnot help identify misconfigurations."},{"index":4,"questions":"4. Your company is running multiple VM instances that have not had any downtime in the past several weeks. Recently, several of the physical servers suffered disk failures. The applications running on the servers did not have any apparent service disruptions. What feature of Compute Engine enabled that?","choices":["A. Preemptible VMs","B. Live migration","C. Canary deployments","D. Redundant array of inexpensive disks"],"answer":"4. B. The correct answer is B, Live Migration, which moves running VMs to differentphysical servers without interrupting the state of the VM. Option A is incorrect becausepreemptible VMs are low-cost VMs that may be taken back by Google at any time.Option C is incorrect, as canary deployments are a type of deployment—not a featureof Compute Engine. Option D is incorrect, as arrays of disks are not directly involved inpreserving the state of a VM and moving the VM to a functioning physical server."},{"index":5,"questions":"5. You have deployed an application on an instance group. The application is not functioning correctly. What is a possible outcome?","choices":["A. The application shuts down when the instance group time-to-live (TTL) threshold is reached.","B. The application shuts down when the health check fails.","C. The VM shuts down when the instance group TTL threshold is reached and a new VM is started.","D. The VM shuts down when the health check fails and a new VM is started."],"answer":"5. D. Option D is correct. When a health check fails, the failing VM is replaced by a new VMthat is created using the instance group template to configure the new VM. Options A andC are incorrect, as TTL is not used to detect problems with application functioning. OptionB is incorrect because the application is not shut down when a health check fails."},{"index":6,"questions":"6. Mountkirk Games is growing its user base in North America, Europe, and Asia. Executives are concerned that players in Europe and Asia will have a degraded experience if the game backend runs only in North America. What would you suggest as a way to improve latency and game experience for users in Europe and Asia?","choices":["A. Use Cloud Spanner to have a globally consistent, horizontally scalable relational database.","B. Create instance groups running the game backend in multiple regions across North America, Europe, and Asia. Use global load balancing to distribute the workload.","C. Use Standard Tier networking to ensure that data sent between regions is routed over the public Internet.","D. Use a Cloud Memorystore cache in front of the database to reduce database read latency."],"answer":"6. B. The correct answer is B. Creating instance groups in multiple regions and routingworkload to the closest region using global load balancing will provide the most consis-tent experience for users in different geographic regions. Option A is incorrect becauseCloud Spanner is a relational database and does not affect how game backend servicesare run except for database operations. Option C is incorrect, as routing traffic over thepublic Internet means traffic will experience the variance of public Internet routes betweenregions. Option D is incorrect. A cache will reduce the time needed to read data, but itwill not affect network latency when that data is transmitted from a game backend to theplayer’s device."},{"index":7,"questions":"7. What configuration changes are required to ensure high availability when using Cloud Storage or Cloud Filestore?","choices":["A. A sufficiently long TTL must be set.","B. A health check must be specified.","C. Both a TTL and health check must be specified.","D. Nothing. Both are managed services. GCP manages high availability."],"answer":"7. D. The correct answer is D. Users do not need to make any configuration changes whenusing Cloud Storage or Cloud Filestore. Both are fully managed services. Options A and Care incorrect because TTLs do not need to be set to ensure high availability. Options B andC are incorrect because users do not need to specify a health check for managed storageservices."},{"index":8,"questions":"8. The finance director in your company is frustrated with the poor availability of an on-premises finance data warehouse. The data warehouse uses a commercial relational database that only scales by buying larger and larger servers. The director asks for your advice about moving the data warehouse to the cloud and if the company can continue to use SQL to query the data warehouse. What GCP service would you recommend to replace the on-premises data warehouse?","choices":["A. Bigtable","B. BigQuery","C. Cloud Datastore","D. Cloud Storage"],"answer":"8. B. The best answer is B. BigQuery is a serverless, fully managed analytic database thatuses SQL for querying. Options A and C are incorrect because both Bigtable and CloudDatastore are NoSQL databases. Option D, Cloud Storage, is not a database, and it doesnot meet most of the requirements listed."},{"index":9,"questions":"9. TerramEarth has determined that it wants to use Cloud Bigtable to store equipment telemetry data transmitted over their cellular network. They have also concluded that they want two clusters in different regions. Both clusters should be able to respond to read and write requests. What kind of replication should be used?","choices":["A. Primary–hot primary","B. Primary–warm primary","C. Primary–primary","D. Primary read–primary write"],"answer":"9. C. The correct answer is C. Primary-primary replication keeps both clusters synchronizedwith write operations so that both clusters can respond to queries. Options A, B, and D arenot actual replication options."},{"index":10,"questions":"10. Your company is implementing a hybrid cloud computing model. Line-of-business owners are concerned that data stored in the cloud may not be available to on-premises applications. The current network connection is using a maximum of 40 percent of bandwidth. What would you suggest to mitigate the risk of that kind of service failure?","choices":["A. Configure firewall rules to improve availability.","B. Use redundant network connections between the on-premises data center and Google Cloud.","C. Increase the number of VMs allowed in Compute Engine instance groups.","D. Increase the bandwidth of the network connection between the data center and Google Cloud."],"answer":"10. B. Option B is correct. A redundant network connection would mitigate the risk of losingconnectivity if a single network connection went down. Option A is incorrect, as firewallrules are a security control and would not mitigate the risk of network connectivity failures.Option C may help with compute availability, but it does not improve network availability.Option D does not improve availability, and additional bandwidth is not needed."},{"index":11,"questions":"11. A team of architects in your company is defining standards to improve availability. In addition to recommending redundancy and code reviews for configuration changes, what would you recommend to include in the standards?","choices":["A. Use of access controls","B. Use of managed services for all compute requirements","C. Use of Stackdriver monitoring to alert on changes in application performance","D. Use of Bigtable to collect performance monitoring data"],"answer":"11. C. The correct answer is C. Stackdriver should be used to monitor applications and infra-structure to detect early warning signs of potential problems with applications or infra-structure. Option A is incorrect because access controls are a security control and notrelated to directly improving availability. Option B is incorrect because managed servicesmay not meet all requirements and so should not be required in a company’s standards.Option D is incorrect because collecting and storing performance monitoring data does notimprove availability."},{"index":12,"questions":"12. Why would you want to run long-running, compute-intensive backend computation in a different managed instance group than on web servers supporting a minimal user interface?","choices":["A. Managed instance groups can run only a single application.","B. Managed instance groups are optimized for either compute or HTTP connectivity.","C. Compute-intensive applications have different scaling characteristics from those of lightweight user interface applications.","D. There is no reason to run the applications in different managed instance groups."],"answer":"12. C. The correct answer is C. The two applications have different scaling requirements.The compute-intensive backend may benefit from VMs with a large number of CPUs thatwould not be needed for web serving. Also, the frontend may be able to reduce the num-ber of instances when users are not actively using the user interface, but long compute jobsmay still be running in the background. Options A and B are false statements. Option D isincorrect for the reasons explained in reference to Option C."},{"index":13,"questions":"13. An instance group is adding more VMs than necessary and then shutting them down. This pattern is happening repeatedly. What would you do to try to stabilize the addition and removal of VMs?","choices":["A. Increase the maximum number of VMs in the instance group.","B. Decrease the minimum number of VMs in the instance group.","C. Increase the time autoscalers consider when making decisions.","D. Decrease the time autoscalers consider when making decisions."],"answer":"13. C. The correct answer is C. The autoscaler may be adding VMs because it has not waitedlong enough for recently added VMs to start and begin to take on load. Options A and Bare incorrect because changing the minimum and maximum number of VMs in the groupdoes not affect the rate at which VMs are added or removed. Option D is incorrect becauseit reduces the time available for new instances to start taking on workload, so it may actu-ally make the problem worse."},{"index":14,"questions":"14. Dress4Win has just developed a new feature for its social networking service. Customers can upload images of their clothes, create montages from those images, and share them on social networking sites. Images are temporarily saved to locally attached drives as the customer works on the montage. When the montage is complete, the final version is copied to a Cloud Storage bucket. The services implementing this feature run in a managed instance group. Several users have noted that their final montages are not available even though they saved them in the application. No other problems have been reported with the service. What might be causing this problem?","choices":["A. The Cloud Storage bucket is out of storage.","B. The locally attached drive does not have a filesystem.","C. The users experiencing the problem were using a VM that was shut down by an autoscaler, and a cleanup script did not run to copy the latest version of the montage to Cloud Storage.","D. The network connectivity between the VMs and Cloud Storage has failed."],"answer":"14. C. The correct answer is C. If the server is shut down without a cleanup script, then datathat would otherwise be copied to Cloud Storage could be lost when the VM shuts down.Option A is incorrect because buckets do not have a fixed amount of storage. Option B isincorrect because, if it were true, the service would not function for all users—not just sev-eral of them. Option D is incorrect because if there was a connectivity failure between theVM and Cloud Storage, there would be more symptoms of such a failure."},{"index":15,"questions":"15. Kubernetes uses several abstractions to model and manage computation and applications. What is the progression of abstractions from the lowest to the highest level ?","choices":["A. Pods Deployments Services → →","B. Pods→ Service→ Deployments","C. Deployments→ Service→ Pods","D. Deployments→ Pods→ Services"],"answer":"15. A. The correct answer is A. Pods are the lowest level of the computation abstractions.Deployments are collections of pods running a version of an application. Services are setsof deployments running an application, possibly with multiple versions running in differentdeployments. Options B, C, and D are all incorrect in the order of progression from lowestto highest level of abstraction."},{"index":16,"questions":"16. Your development team has implemented a new application using a microservices architecture. You would like to minimize DevOps overhead by deploying the services in a way that will autoscale. You would also like to run each microservice in containers. What is a good option for implementing these requirements in Google Cloud Platform?","choices":["A. Run the containers in Cloud Functions.","B. Run the containers in Kubernetes Engine.","C. Run the containers in Cloud Dataproc.","D. Run the containers in Cloud Dataflow."],"answer":"16. B. The correct answer is B. The requirements are satisfied by the Kubernetes containerorchestration capabilities. Option A is incorrect, as Cloud Functions do not run contain-ers. Option C is incorrect because Cloud Dataproc is a managed service for Hadoop andSpark. Option D is incorrect, as Cloud Dataflow is a managed service for stream and batchprocessing using the Apache Beam model."},{"index":17,"questions":"17. TerramEarth is considering building an analytics database and making it available to equipment designers. The designers require the ability to query the data with SQL. The analytics database manager wants to minimize the cost of the service. What would you recommend?","choices":["A. Use BigQuery as the analytics database, and partition the data to minimize the amount of data scanned to answer queries.","B. Use Bigtable as the analytics database, and partition the data to minimize the amount of data scanned to answer queries.","C. Use BigQuery as the analytics database, and use data federation to minimize the amount of data scanned to answer queries.","D. Use Bigtable as the analytics database, and use data federation to minimize the amount of data scanned to answer queries."],"answer":"17. A. The correct answer is A. BigQuery should be used for an analytics database. Partitioningallows the query processor to limit scans to partitions that might have the data selected ina query. Options B and D are incorrect because Bigtable does not support SQL. Options Cand D are incorrect because federation is a way of making data from other sources availablewithin a database—it does not limit the data scanned in the way that partitioning does."},{"index":18,"questions":"18. Line-of-business owners have decided to move several applications to the cloud. They believe the cloud will be more reliable, but they want to collect data to test their hypothesis. What is a common measure of reliability that they can use?","choices":["A. Mean time to recovery","B. Mean time between failures","C. Mean time between deployments","D. Mean time between errors"],"answer":"18. B. The correct answer is B. Mean time between failures is a measure of reliability. Option Ais a measure of how long it takes to recover from a disruption. Options C and D are incor-rect because the time between deployments or errors is not directly related to reliability."},{"index":19,"questions":"19. A group of business executives and software engineers are discussing the level of risk that is acceptable for a new application. Business executives want to minimize the risk that the service is not available. Software engineers note that the more developer time dedicated to reducing risk of disruption, the less time they have to implement new features. How can you formalize the group’s tolerance for risk of disruption?","choices":["A. Request success rate","B. Uptime of service","C. Latency","D. Throughput"],"answer":"19. A. The correct answer is A. Request success rate is a measure of how many requests weresuccessfully satisfied. Option B is incorrect because at least some instances of an applicationmay be up at any time, so it does not reflect the capacity available. Options C and D are notrelevant measures of risk."},{"index":20,"questions":"20. Your DevOps team recently determined that it needed to increase the size of persistent disks used by VMs running a business-critical application. When scaling up the size of available persistent storage for a VM, what other step may be required?","choices":["A. Adjusting the filesystem size in the operating system","B. Backing up the persistent disk before changing its size","C. Changing the access controls on files on the disk","D. Update disk metadata, including labels"],"answer":"20. A. The correct answer is A. The persistent storage may be increased in size, but the operat-ing system may need to be configured to use that additional storage. Option B is incorrectbecause while backing up a disk before operating on it is a good practice, it is not required.Option C is incorrect because changing storage size does not change access control rules.Option D is incorrect because any disk metadata that needs to change when the sizechanges is updated by the resize process."}],"4":[{"index":1,"questions":"1. You are consulting for a client that is considering moving some on-premises workloads to the Google Cloud Platform. The workloads are currently running on VMs that use a specially hardened operating system. Application administrators will need root access to the operating system as well. The client wants to minimize changes to the existing configuration. Which GCP compute service would you recommend?","choices":["A. Compute Engine","B. Kubernetes Engine","C. App Engine Standard","D. App Engine Flexible"],"answer":"1. A. The correct answer is A. Compute Engine instances meet all of the requirements: theycan run VMs with minimal changes, and application administrators can have root access.Option B would require the VMs to be deployed as containers. Option C is incorrectbecause App Engine Standard is limited to applications that can execute in a language-specific runtime. Option D is incorrect, as App Engine Flexible runs containers, not VMs."},{"index":2,"questions":"2. You have just joined a startup that analyzes healthcare data and makes recommendations to healthcare providers to improve the quality of care while controlling costs. You have to comply with privacy regulations. A compliance consultant recommends that your startup control encryption keys used to encrypt data stored on cloud servers. You’d rather have GCP manage all encryption components to minimize your work and infrastructure management responsibilities. What would you recommend?","choices":["A. Use default encryption enabled on Compute Engine instances.","B. Use Google Cloud Key Management Service to store keys that you create and use them to encrypt storage used with Compute Engine instances.","C. Implement a trusted key store on premises, create the keys yourself, and use them to encrypt storage used with Compute Engine instances.","D. Use an encryption algorithm that does not use keys."],"answer":"2. B. The best option is B. It meets the requirement of creating and managing the keys with-out requiring your company to deploy and manage a secure key store. Option A is incorrectbecause it does not meet the requirements. Option C requires more setup and maintenancethan Option B. Option D does not exist, at least for any strong encryption algorithm."},{"index":3,"questions":"3. A colleague complains that the availability and reliability of GCP VMs is poor because their instances keep shutting down with them issuing shutdown commands. No instance has run for more than 24 hours without shutting down for some reason. What would you suggest your colleague check to understand why the instances may be shutting down?","choices":["A. Make sure that the Stackdriver agent is installed and collecting metrics.","B. Verify that sufficient persistent storage is attached to the instance.","C. Make sure that the instance availability is not set to preemptible.","D. Ensure that an external IP address has been assigned to the instance."],"answer":"3. C. Option C is correct. The description of symptoms matches the behavior of preemptibleinstances. Option A is wrong because collecting performance metrics will not prevent shut-downs. Option B is incorrect, because shutdowns are not triggered by insufficient storage.Option D is incorrect, as the presence or absence of an external IP address would not affectshutdown behavior."},{"index":4,"questions":"4. Your company is working on a government contract that requires all instances of VMs to have a virtual Trusted Platform Module. What Compute Engine configuration option would you enable or disable your instances?","choices":["A. Trusted Module Setting","B. Shielded VMs","C. Preemptible VMs","D. Disable live migration"],"answer":"4. B. Option B is correct. Shielded VMs include the vTPM along with Secure Boot and Integ-rity Monitoring. Option A is incorrect—there is no such option. Options C and D are notrelated to vTPM functionality."},{"index":5,"questions":"5. You are leading a lift-and-shift migration to the cloud. Your company has several load-balanced clusters that use VMs that are not identically configured. You want to make as few changes as possible when moving workloads to the cloud. What feature of GCP would you use to implement those clusters in the cloud?","choices":["A. Managed instance groups","B. Unmanaged instance groups","C. Flexible instance groups","D. Kubernetes clusters"],"answer":"5. B. The correct answer is B. Unmanaged instance groups can have nonidentical instances.Option A is incorrect, as all instances are the same in managed instance groups. Option Cis incorrect because there is no such thing as a flexible instance group. Option D is incorrectbecause Kubernetes clusters run containers and would require changes that are not requiredif the cluster is migrated to an unmanaged instance group."},{"index":6,"questions":"6. Your startup has a stateless web application written in Python 3.7. You are not sure what kind of load to expect on the application. You do not want to manage servers or containers if you can avoid it. What GCP service would you use?","choices":["A. Compute Engine","B. App Engine","C. Kubernetes Engine","D. Cloud Dataproc"],"answer":"6. B. The correct answer is B. The requirements call for a PaaS. Second-generation AppEngine Standard supports Python 3.7, and it does not require users to manage VMs orcontainers. Option A is incorrect because you would have to manage VMs if you usedCompute Engine. Option C is incorrect, as you would have to create containers to run inKubernetes Engine. Option D is incorrect because Cloud Dataproc is a managed Hadoopand Spark service, and it is not designed to run Python web applications."},{"index":7,"questions":"7. Your department provides audio transcription services for other departments in your company. Users upload audio files to a Cloud Storage bucket. Your application transcribes the audio and writes the transcript file back to the same bucket. Your process runs every day at midnight and transcribes all files in the bucket. Users are complaining that they are not notified if there is a problem with the audio file format until the next day. Your application has a program that can verify the quality of an audio file in less than two seconds. What changes would you make to the workflow to improve user satisfaction?","choices":["A. Include more documentation about what is required to transcribe an audio file successfully.","B. Use Cloud Functions to run the program to verify the quality of the audio file when the file is uploaded. If there is a problem, notify the user immediately.","C. Create a Compute Engine instance and set up a cron job that runs every hour to check the quality of files that have been uploaded into the bucket in the last hour. Send notices to all users who have uploaded files that do not pass the quality control check.","D. Use the App Engine Cron service to set up a cron job that runs every hour to check the quality of files that have been uploaded into the bucket in the last hour. Send notices to all users who have uploaded files that do not pass the quality control check."],"answer":"7. B. The correct answer is B. This solution notifies users immediately of any problem anddoes not require any servers. Option A does not solve the problem of reducing time tonotify users when there is a problem. Options C and D solve the problem but do not notifyusers immediately. Option C also requires you to manage a server."},{"index":8,"questions":"8. You have inherited a monolithic Ruby application that you need to keep running. There will be minimal changes, if any, to the code. The previous developer who worked with this application created a Dockerfile and image container with the application and needed libraries. You’d like to deploy this in a way that minimizes your effort to maintain it. How would you deploy this application?","choices":["A. Create an instance in Compute Engine, install Docker, install the Stackdriver agent, and then run the Docker image.","B. Create an instance in Compute Engine, but do not use the Docker image. Install the application, Ruby, and needed libraries. Install the Stackdriver agent. Run the application directly in the VM, not a container.","C. Use App Engine Flexible to run the container image. App Engine will monitor as needed.","D. Use App Engine Standard to run the container image. App Engine will monitor as needed."],"answer":"8. C. The correct answer is C. App Engine Flexible requires the least effort. App EngineFlexible will run the container and perform health checks and collect performance met-rics. Options A and B are incorrect because provisioning and managing Compute Engineinstances is more effort than using App Engine Flexible. Option D is incorrect because youcannot run a custom container in App Engine Standard."},{"index":9,"questions":"9. You have been asked to give a presentation on Kubernetes. How would you explain the difference between the cluster master and nodes?","choices":["A. Cluster masters manage the cluster and run core services such as the controller manager, API server, scheduler, and etcd. Nodes run workload jobs.","B. The cluster manager is an endpoint for API calls. All services needed to maintain a cluster are run on nodes.","C. The cluster manager is an endpoint for API calls. All services needed to maintain a cluster are run on nodes, and workloads are run on a third kind of server, a runner.","D. Cluster masters manage the cluster and run core services such as the controller manager, API server, scheduler, and etcd. Nodes monitor the cluster master and restart it if it fails."],"answer":"9. A. The correct answer is A. Cluster masters run core services for the cluster, and nodes runworkload. Options B and C are incorrect, as the cluster manager is not just an endpoint forAPIs. Also, there is no runner node type. Option D is incorrect because nodes do not moni-tor cluster masters."},{"index":10,"questions":"10. External services are not able to access services running in a Kubernetes cluster. You suspect a controller may be down. Which type of controller would you check?","choices":["A. Pod","B. Deployment","C. Ingress Controller","D. Service Controller"],"answer":"10. C. Option C is correct. Ingress Controllers are needed by Ingress objects, which are objectsthat control external access to services running in a Kubernetes cluster. Option A is incor-rect, as Pods are the lowest level of computational unit, and they run one or more contain-ers. Option B is incorrect, as Deployments are versions of a service that run in a cluster.Option D is incorrect, as Services do not control access from external services."},{"index":11,"questions":"11. You are planning to run stateful applications in Kubernetes Engine. What should you use to support stateful applications?","choices":["A. Pods","B. StatefulPods","C. StatefulSets","D. PersistentStorageSets"],"answer":"11. C. The correct answer is C. StatefulSets deploy pods with unique IDs, which allows Kuber-netes to support stateful applications by ensuring that clients can always use the same pod.Answer A is incorrect, as pods are always used for both stateful and stateless applications.Options B and D are incorrect because they are not actually components in Kubernetes."},{"index":12,"questions":"12. Every time a database administrator logs into a Firebase database, you would like a message sent to your mobile device. Which compute service could you use that would minimize your work in deploying and running the code that sends the message?","choices":["A. Compute Engine","B. Kubernetes Engine","C. Cloud Functions","D. Cloud Dataflow"],"answer":"12. C. Option C is correct because Cloud Functions can detect authentications to Firebaseand run code in response. Sending a message would require a small amount of code, andthis can run in Cloud Functions. Options A and B would require more work to set upa service to watch for a login and then send a message. Option D is incorrect, as CloudDataflow is a stream and batch processing platform not suitable for responding to eventsin Firebase."},{"index":13,"questions":"13. Your team has been tasked with deploying infrastructure for development, test, staging, and production environments in region us-west1. You will likely need to deploy the same set of environments in two additional regions. What service would allow you to use an Infrastructure as code (IaC) approach?","choices":["A. Cloud Dataflow","B. Deployment Manager","C. Identity and Access Manager","D. App Engine Flexible"],"answer":"13. B. The correct answer is B. Deployment Manager is Google Cloud’s IaaS manager. Option Ais incorrect because Cloud Dataflow is a stream and batch processing service. Option C,Identity and Access Management, is an authentication and authorization service. Option D,App Engine Flexible, is a PaaS offering that allows users to customize their own runtimesusing containers."},{"index":14,"questions":"14. An IoT startup collects streaming data from industrial sensors and evaluates the data for anomalies using a machine learning model. The model scales horizontally. The data collected is buffered in a server for 10 minutes. Which of the following is a true statement about the system?","choices":["A. It is stateful.","B. It is stateless.","C. It may be stateful or stateless, there is not enough information to determine.","D. It is neither stateful nor stateless."],"answer":"14. A. The correct answer is A. This application is stateful. It collects and maintains dataabout sensors in servers and evaluates that data. Option B is incorrect because the appli-cation stores data about a stream, so it is stateful. Option C is incorrect because there isenough information. Option D is incorrect because the application stores data about thestream, so it is stateful."},{"index":15,"questions":"15. Your team is designing a stream processing application that collects temperature and pressure measurements from industrial sensors. You estimate that for the initial release, the application will need 8 to 12 n1-highmem-32 instances. Someone on the team suggests using a Cloud Memorystore cache. What could that cache be used for?","choices":["A. A SQL database","B. As a memory cache to store state data outside of instances","C. An extraction, transformation, and load service","D. A persistent object storage system"],"answer":"15. B. The correct answer is B. Of the four options, a cache is most likely used to store statedata. If instances are lost, state information is not lost as well. Option A is incorrect;Memorystore is not a SQL database. Option C is incorrect because Memorystore doesnot provide extraction, transformation, and load services. Option D is incorrect becauseMemorystore is not a persistent object store."},{"index":16,"questions":"16. A distributed application is not performing as well as expected during peak load periods. The application uses three microservices. The first of the microservices has the ability to send more data to the second service than the second service can process and keep up with. This causes the first microservice to wait while the second service processes data. What can be done to decouple the first service from the second service?","choices":["A. Run the microservices on separate instances.","B. Run the microservices in a Kubernetes cluster.","C. Write data from the first service to a Cloud Pub/Sub topic and have the second service read the data from the topic.","D. Scale both services together using MIGs."],"answer":"16. C. Option C is the correct answer. Using a queue between the services allows the first ser-vice to write data as fast as needed, while the second service reads data as fast as it can. Thesecond service can catch up after peak load subsides. Options A, B, and D do not decouplethe services."},{"index":17,"questions":"17. A colleague has suggested that you use the Apache Beam framework for implementing a highly scalable workflow. Which Google Cloud service would you use?","choices":["A. Cloud Dataproc","B. Cloud Dataflow","C. Cloud Dataprep","D. Cloud Memorystore"],"answer":"17. B. Option B is the correct answer. Cloud Dataflow is Google Cloud’s implementation onApache Beam. Option A, Cloud Dataproc, is a managed Hadoop and Spark service. Option C,Cloud Dataprep, is a data preparation tool for analysis and machine learning. Option D,Cloud Memorystore, is a managed cache service."},{"index":18,"questions":"18. Your manager wants more data on the performance of applications running in Compute Engine, specifically, data on CPU and memory utilization. What Google Cloud service would you use to collect that data?","choices":["A. Cloud Dataprep","B. Stackdriver","C. Cloud Dataproc","D. Cloud Memorystore"],"answer":"18. B. Option B is the correct answer. Stackdriver is Google Cloud’s monitoring and loggingservice. Option A, Cloud Dataprep, is data preperation tool for analysis and machine learn-ing. Option C, Cloud Dataproc, is a managed Hadoop and Spark service. Option D, CloudMemorystore, is a managed cache service."},{"index":19,"questions":"19. You are receiving alerts that CPU utilization is high on several Compute Engine instances. The instances are all running a custom C++ application. When you receive these alerts, you deploy an additional instance running the application. A load balancer automatically distributes the workload across all of the instances. What is the best option to avoid having to add servers manually when CPU utilization is high?","choices":["A. Always run more servers than needed to avoid high CPU utilization.","B. Deploy the instances in a MIG, and use autoscaling to add and remove instances as needed.","C. Run the application in App Engine Standard.","D. Whenever you receive an alert, add two instances instead of one."],"answer":"19. B. The correct answer is B. Managed instances groups can autoscale, so this option wouldautomatically add or remove instances as needed. Options A and D are not as cost efficientas Option B. Option C is incorrect because App Engine Standard does not provide a C++runtime."},{"index":20,"questions":"20. A retailer has sales data streaming into a Cloud Pub/Sub topic from stores across the country. Each time a sale is made, data is sent from the point of sale to Google Cloud. The data needs to be transformed and aggregated before it is written to BigQuery. What service would you use to perform that processing and write data to BigQuery?","choices":["A. Firebase","B. Cloud Dataflow","C. Cloud Memorystore","D. Cloud Datastore"],"answer":"20. B. Option B is correct. Cloud Dataflow is designed to support stream and batch process-ing, and it can write data to BigQuery. Options A is incorrect, as Firebase is GCP’s mobiledevelopment platform. Option D is incorrect, Datastore is a NoSQL database. Option C isincorrect because Cloud Memorystore is a managed cache service."}],"5":[{"index":1,"questions":"1. You need to store a set of files for an extended period of time. Anytime the data in the files needs to be accessed, it will be copied to a server first, and then the data will be accessed. Files will not be accessed more than once a year. The set of files will all have the same access controls. What storage solution would you use to store these files?","choices":["A. Cloud Storage Coldline","B. Cloud Storage Nearline","C. Cloud Filestore","D. Bigtable"],"answer":"1. A. The correct answer is A. The Cloud Storage Coldline service is designed for long-termstorage of infrequently accessed objects. Option B is not the best answer because Nearlineshould be used with objects that are not accessed up to once a month. Coldline storage ismore cost effective and still meets the requirements. Option C is incorrect. Cloud Filestoreis a network filesystem, and it is used to store data that is actively used by applications run-ning on Compute Engine VM and Kubernetes Engine clusters."},{"index":2,"questions":"2. You are uploading files in parallel to Cloud Storage and want to optimize load performance. What could you do to avoid creating hotspots when writing files to Cloud Storage?","choices":["A. Use sequential names or timestamps for files.","B. Do not use sequential names or timestamps for files.","C. Configure retention policies to ensure that files are not deleted prematurely.","D. Configure lifecycle policies to ensure that files are always using the most appropriate storage class."],"answer":"2. B. The correct answer is B. Do not use sequential names or timestamps if uploading filesin parallel. Files with sequentially close names will likely be assigned to the same server.This can create a hotspot when writing files to Cloud Storage. Option A is incorrect, as thiscould cause hotspots. Options C and D affect the lifecycle of files once they are written anddo not impact upload efficiency."},{"index":3,"questions":"3. As a consultant on a cloud migration project, you have been asked to recommend a strategy for storing files that must be highly available even in the event of a regional failure. What would you recommend?","choices":["A. BigQuery","B. Cloud Datastore","C. Multiregional Cloud Storage","D. Regional Cloud Storage"],"answer":"3. C. The correct answer is C. Multiregional Cloud Storage replicates data to multipleregions. In the event of a failure in one region, the data could be retrieved from anotherregion. Options A and B are incorrect because those are databases, not file storage systems.Option D is incorrect because it does not meet the requirement of providing availability inthe event of a single region failure."},{"index":4,"questions":"4. As part of a migration to Google Cloud Platform, your department will run a collaboration and document management application on Compute Engine virtual machines. The application requires a filesystem that can be mounted using operating system commands. All documents should be accessible from any instance. What storage solution would you recommend?","choices":["A. Cloud Storage","B. Cloud Filestore","C. A document database","D. A relational database"],"answer":"4. B. The correct answer is B. Cloud Filestore is a network-attached storage service that pro-vides a filesystem that is accessible from Compute Engine. Filesystems in Cloud Filestorecan be mounted using standard operating system commands. Option A, Cloud Storage, isincorrect because it does not provide a filesystem. Options C and D are incorrect becausedatabases do not provide filesystems."},{"index":5,"questions":"5. Your team currently supports seven MySQL databases for transaction processing applications. Management wants to reduce the amount of staff time spent on database administration. What GCP service would you recommend to help reduce the database administration load on your teams?","choices":["A. Bigtable","B. BigQuery","C. Cloud SQL","D. Cloud Filestore"],"answer":"5. C. The correct answer is C. Cloud SQL is a managed database service that supportsMySQL and PostgreSQL. Option A is incorrect because Bigtable is a wide-column NoSQLdatabase, and it is not a suitable substitute for MySQL. Option B is incorrect becauseBigQuery is optimized for data warehouse and analytic databases, not transactionaldatabases. Option D is incorrect, as Cloud Filestore is not a database."},{"index":6,"questions":"6. Your company is developing a new service that will have a global customer base. The service will generate large volumes of structured data and require the support of a transaction processing database. All users, regardless of where they are on the globe, must have a consistent view of data. What storage system will meet these requirements?","choices":["A. Cloud Spanner","B. Cloud SQL","C. Cloud Storage","D. BigQuery"],"answer":"6. A. The correct answer is A. Cloud Spanner is a managed database service that supportshorizontal scalability across regions. It supports strong consistency so that there is no riskof data anomalies caused by eventual consistency. Option B is incorrect because Cloud SQLcannot scale globally. Option C is incorrect, as Cloud Storage does not meet the databaserequirements. Option D is incorrect because BigQuery is not designed for transaction pro-cessing systems."},{"index":7,"questions":"7. Your company is required to comply with several government and industry regulations, which include encrypting data at rest. What GCP storage services can be used for applications subject to these regulations?","choices":["A. Bigtable and BigQuery only","B. Bigtable and Cloud Storage only","C. Any of the managed databases, but no other storage services","D. Any GCP storage service"],"answer":"7. D. The correct answer is D. All data in GCP is encrypted when at rest. The other optionsare incorrect because they do not include all GCP storage services."},{"index":8,"questions":"8. As part of your role as a data warehouse administrator, you occasionally need to export data from the data warehouse, which is implemented in BigQuery. What command-line tool would you use for that task?","choices":["A. gsutil","B. gcloud","C. bq","D. cbt"],"answer":"8. C. The correct answer is C. The bqcommand-line tool is used to work with BigQuery.Option A, gsutil , is the command-line tool for working with Cloud Storage, and OptionD, cbt, is the command-line tool for working with Bigtable. Option B, gcloud , is thecommand-line tool for most other GCP services."},{"index":9,"questions":"9. Another task that you perform as data warehouse administrator is granting authorizations to perform tasks with the BigQuery data warehouse. A user has requested permission to view table data but not change it. What role would you grant to this user to provide the needed permissions but nothing more?","choices":["A. dataViewer","B. admin","C. metadataViewer","D. dataOwner"],"answer":"9. A. The correct answer is A. dataViewer allows a user to list projects and tables and gettable data and metadata. Options B and D would enable the user to view data but wouldgrant more permissions than needed. Option C does not grant permission to view data intables."},{"index":10,"questions":"10. A developer is creating a set of reports and is trying to minimize the amount of data each query returns while still meeting all requirements. What bqcommand-line option will help you understand the amount of data returned by a query without actually executing the query?","choices":["A. --no-data","B. --estimate-size","C. --dry-run","D. --size"],"answer":"10. C. The correct answer is C. --dry-runreturns an estimate of the number of bytes thatwould be returned if the query were executed. The other choices are not actually bqcommand-line options."},{"index":11,"questions":"11. A team of developers is choosing between using NoSQL or a relational database. What is a feature of NoSQL databases that is not available in relational databases?","choices":["A. Fixed schemas","B. ACID transactions","C. Indexes","D. Flexible schemas"],"answer":"11. D. The correct answer is D. NoSQL data has flexible schemas. The other options specifyfeatures that are found in relational databases. ACID transactions and indexes are found insome NoSQL databases as well."},{"index":12,"questions":"12. A group of venture capital investors have hired you to review the technical design of a service that will be developed by a startup company seeking funding. The startup plans to collect data from sensors attached to vehicles. The data will be used to predict when a vehicle needs maintenance and before the vehicle breaks down. Thirty sensors will be on each vehicle. Each sensor will send up to 5K of data every second. The startup expects to start with hundreds of vehicles, but it plans to reach 1 million vehicles globally within 18 months. The data will be used to develop machine learning models to predict the need for maintenance. The startup is planning to use a self-managed relational database to store the time-series data. What would you recommend for a time-series database?","choices":["A. Continue to plan to use a self-managed relational database.","B. Use a Cloud SQL.","C. Use Cloud Spanner.","D. Use Bigtable."],"answer":"12. D. The correct answer is D. Bigtable is the best option for storing streaming data becauseit provides low-latency writes and can store petabytes of data. The database would need tostore petabytes of data if the number of users scales as planned. Option A is a poor choicebecause a managed database would meet requirements and require less administration sup-port. Option B will not scale to the volume of data expected. Option C, Cloud Spanner,could scale to store the volumes of data, but it is not optimized for low-latency writes ofstreaming data."},{"index":13,"questions":"13. A Bigtable instance increasingly needs to support simultaneous read and write operations. You’d like to separate the workload so that some nodes respond to read requests and others respond to write requests. How would you implement this to minimize the workload on developers and database administrators?","choices":["A. Create two instances, and separate the workload at the application level.","B. Create multiple clusters in the Bigtable instance, and use Bigtable replication to keep the clusters synchronized.","C. Create multiple clusters in the Bigtable instance, and use your own replication program to keep the clusters synchronized.","D. It is not possible to accomplish the partitioning of the workload as described."],"answer":"13. B. The correct answer is B—create multiple clusters in the instance and use Bigtable rep-lication. Options A and C are not correct, as they require developing custom applicationsto partition data or keep replicas synchronized. Option D is incorrect because the require-ments can be met."},{"index":14,"questions":"14. As a database architect, you’ve been asked to recommend a database service to support an application that will make extensive use of JSON documents. What would you recommend to minimize database administration overhead while minimizing the work required for developers to store JSON data in the database?","choices":["A. Cloud Storage","B. Cloud Datastore","C. Cloud Spanner","D. Cloud SQL"],"answer":"14. B. The correct answer is B. Cloud Datastore is a managed document database, whichis a kind of NoSQL database that uses a flexible JSON-like data structure. Option A isincorrect—it is not a database. Options C and D are not good fits because the JSON datawould have to be mapped to relational structures to take advantage of the full range ofrelational features. There is no indication that additional relational features are required."},{"index":15,"questions":"15. Your Cloud SQL database is close to maximizing the number of read operations that it can perform. You could vertically scale the database to use a larger instance, but you do not need additional write capacity. What else could you try to reduce the number of reads performed by the database?","choices":["A. Switch to Cloud Spanner.","B. Use Cloud Bigtable instead.","C. Use Cloud Memorystore to create a database cache that stores the results of database queries. Before a query is sent to the database, the cache is checked for the answer to the query.","D. There is no other option—you must vertically scale."],"answer":"15. C. The correct answer is C. You could try to cache results to reduce the number of reads onthe database. Option A is not a good choice because it does not reduce the number of reads,and there is no indication that the scale of Cloud Spanner is needed. Option B is not a goodchoice because Bigtable is a NoSQL database and may not meet the database needs of theapplication. Option D is incorrect because caching is an option."},{"index":16,"questions":"16. You would like to move objects stored in Cloud Storage automatically from regional storage to Nearline storage when the object is 6 months old. What feature of Cloud Storage would you use?","choices":["A. Retention policies","B. Lifecycle policies","C. Bucket locks","D. Multiregion replication"],"answer":"16. B. Option B is correct. Lifecycle policies allow you to specify an action, like changing stor-age class, after an object reaches a specified age. Option A is incorrect, as retention policiesprevent premature deleting of an object. Option C is incorrect. This is a feature used toimplement retention policies."},{"index":17,"questions":"17. A customer has asked for help with a web application. Static data served from a data center in Chicago in the United States loads slowly for users located in Australia, South Africa, and Southeast Asia. What would you recommend to reduce latency?","choices":["A. Distribute data using Cloud CDN.","B. Use Premium Network from the server in Chicago to client devices.","C. Scale up the size of the web server.","D. Move the server to a location closer to users."],"answer":"17. A. The correct answer is A. Cloud CDN distributes copies of static data to points of pres-ence around the globe so that it can be closer to users. Option B is incorrect. Premium Net-work routes data over the internal Google network, but it does not extend to client devices.Option C will not help with latency. Option D is incorrect because moving the location ofthe server might reduce the latency for some users, but it would likely increase latency forother users, as they could be located anywhere around the globe."}],"6":[{"index":1,"questions":"1. Your team has deployed a VPC with default subnets in all regions. The lead network architect at your company is concerned about possible overlap in the use of private addresses. How would you explain how you are dealing with the potential problem?","choices":["A. You inform the network architect that you are not using private addresses at all.","B. When default subnets are created for a VPC, each region is assigned a different IP address range.","C. You have increased the size of the subnet mask in the CIDR block specification of the set of IP addresses.","D. You agree to assign new IP address ranges on all subnets."],"answer":"1. B. The correct answer is B. Default subnets are each assigned a distinct, nonoverlapping IPaddress range. Option A is incorrect, as default subnets use private addresses. Option C isincorrect because increasing the size of the subnet mask does not necessarily prevent over-laps. Option D is an option that would also ensure nonoverlapping addresses, but it is notnecessary given the stated requirements."},{"index":2,"questions":"2. A data warehouse service running in GCP has all of its resources in a single project. The e-commerce application has resources in another project, including a database with transaction data that will be loaded into the data warehouse. The data warehousing team would like to read data directly from the database using extraction, transformation, and load processes that run on Compute Engine instances in the data warehouse project. Which of the following network constructs could help with this?","choices":["A. Shared VPC","B. Regional load balancing","C. Direct peering","D. Cloud VPN"],"answer":"2. A. The correct answer is A. A Shared VPC allows resources in one project to access theresources in another project. Option B is incorrect, as load balancing does not help withnetwork access. Options C and D are incorrect because those are mechanisms for hybridcloud computing. In this case, all resources are in GCP, so hybrid networking is not needed."},{"index":3,"questions":"3. An intern working with your team has changed some firewall rules. Prior to the change, all Compute Engine instances on the network could connect to all other instances on the network. After the change, some nodes cannot reach other nodes. What might have been the change that causes this behavior?","choices":["A. One or more implied rules were deleted.","B. The default-allow-interna rlle was deleted.","C. The default-all-icmrpule was deleted.","D. The priority of a rule was set higher than 65535."],"answer":"3. B. The correct answer is B. The default-allow-interna rlle allows ingress connectionsfor all protocols and ports among instances in the network. Option A is incorrect becauseimplied rules cannot be deleted, and the implied rules alone would not be enough to enableall instances to connect to all other instances. Option C is incorrect because that rule gov-erns the ICMP protocol for management services, like ping. Option D is incorrect because65535 is the largest number/lowest priority allowed for firewall rules."},{"index":4,"questions":"4. The network administrator at your company has asked that you configure a firewall rule that will always take precedence over any other firewall rule. What priority would you assign?","choices":["A. 0","B. 1","C. 65534","D. 65535"],"answer":"4. A. The correct answer is A. 0 is the highest priority for firewall rules. All the other optionsare incorrect because they have priorities that are not guaranteed to enable the rule to takeprecedence."},{"index":5,"questions":"5. During a review of a GCP network configuration, a developer asks you to explain CIDR notation. Specifically, what does the 8 mean in the CIDR block 172.16.10.2/8?","choices":["A. 8 is the number of bits used to specify a host address.","B. 8 is the number of bits used to specify the subnet mask.","C. 8 is the number of octets used to specify a host address.","D. 8 is the number of octets used to specify the subnet mask."],"answer":"5. B. The correct answer is B. 8 is the number of bits used to specify the subnet mask. OptionA is wrong because 24 is the number of bits available to specify a host address. Options Cand D are wrong, as the integer does not indicate an octet."},{"index":6,"questions":"6. Several new firewall rules have been added to a VPC. Several users are reporting unusual problems with applications that did not occur before the firewall rule changes. You’d like to debug the firewall rules while causing the least impact on the network and doing so as quickly as possible. Which of the following options is best?","choices":["A. Set all new firewall priorities to 0 so that they all take precedence over other rules.","B. Set all new firewall priorities to 65535 so that all other rules take precedence over these rules.","C. Disable one rule at a time to see whether that eliminates the problems. If needed, disable combinations of rules until the problems are eliminated.","D. Remove all firewall rules and add them back one at a time until the problems occur and then remove the latest rule added back."],"answer":"6. C. The correct answer is C. Disabling a firewall rule allows you to turn off the effect of arule quickly without deleting it. Option A is incorrect because it does not help isolate therule or rules causing the problem, and it may introduce new problems because the new rulesmay take precedence in cases they did not before. Option B is not helpful because alone itwould not help isolate the problematic rule or rules. Option D is incorrect because it willleave the VPC with only implied rules. Adding back all rules could be time-consuming, andhaving no rules could cause additional problems."},{"index":7,"questions":"7. An executive wants to understand what changes in the current cloud architecture are required to run compute-intensive machine learning workloads in the cloud and have the models run in production using on-premises servers. The models are updated daily. There is no network connectivity between the cloud and on-premises networks. What would you tell the executive?","choices":["A. Implement additional firewall rules","B. Use global load balancing","C. Use hybrid-cloud networking","D. Use regional load balancing"],"answer":"7. C. The correct answer is C. Hybrid networking is needed to enable the transfer of data tothe cloud to build models and then transfer models back to the on-premises servers. OptionA is incorrect because firewall rules restrict or allow traffic on a network—they do not linknetworks. Options B and D are incorrect because load balancing does not link networks."},{"index":8,"questions":"8. To comply with regulations, you need to deploy a disaster recovery site that has the same design and configuration as your production environment. You want to implement the disaster recovery site in the cloud. Which topology would you use?","choices":["A. Gated ingress topology","B. Gated egress topology","C. Handover topology","D. Mirrored topology"],"answer":"8. D. The correct answer is D. With mirrored topology, public cloud and private on-premiseenvironments mirror each other. Options A and B are not correct because gated topologiesare used to allow access to APIs in other networks without exposing them to the publicInternet. Option C is incorrect because that topology is used to exchange data and have dif-ferent processing done in different environments."},{"index":9,"questions":"9. Network engineers have determined that the best option for linking the on-premises network to GCP resources is by using an IPsec VPN. Which GCP service would you use in the cloud?","choices":["A. Cloud IPsec","B. Cloud VPN","C. Cloud Interconnect IPsec","D. Cloud VPN IKE"],"answer":"9. B. The correct answer is B. Cloud VPN implements IPsec VPNs. All other options areincorrect because they are not names of actual services available in GCP."},{"index":10,"questions":"10. Network engineers have determined that a link between the on-premises network and GCP will require an 8 Gbps connection. Which option would you recommend?","choices":["A. Cloud VPN","B. Partner Interconnect","C. Direct Interconnect","D. Hybrid Interconnect"],"answer":"10. B. The correct answer is B. Partner Interconnect provides between 50 Mbps and 10 Gbpsconnections. Option A, Cloud VPN, provides up to 3 Gbps connections. Option C, DirectInterconnect, provides 10 or 100 Gbps connections. Option D is not an actual GCP servicename."},{"index":11,"questions":"11. Network engineers have determined that a link between the on-premises network and GCP will require a connection between 60 Gbps and 80 Gbps. Which hybrid-cloud networking services would best meet this requirement?","choices":["A. Cloud VPN","B. Cloud VPN and Direct Interconnect","C. Direct Interconnect and Partner Interconnect","D. Cloud VPN, Direct Interconnect, and Partner Interconnect"],"answer":"11. C. The correct answer is C. Both direct interconnect and partner interconnect can be con-figured to support between 60 Gbps and 80 Gbps. All other options are wrong becauseCloud VPN supports a maximum of 3 Gbps."},{"index":12,"questions":"12. The director of network engineering has determined that any links to networks outside of the company data center will be implemented at the level of BGP routing exchanges. What hybrid-cloud networking option should you use?","choices":["A. Direct peering","B. Indirect peering","C. Global load balancing","D. Cloud IKE"],"answer":"12. A. The correct answer is A. Direct peering allows customers to connect their networks to aGoogle network point of access and exchange Border Gateway Protocol (BGP) routes, whichdefine paths for transmitting data between networks. Options B and D are not the names ofGCP services. Option C is not correct because global load balancing does not link networks."},{"index":13,"questions":"13. A startup is designing a social site dedicated to discussing global political, social, and environmental issues. The site will include news and opinion pieces in text and video. The startup expects that some stories will be exceedingly popular, and others won’t be, but they want to ensure that all users have a similar experience with regard to latency, so they plan to replicate content across regions. What load balancer should they use?","choices":["A. HTTP(S)","B. SSL Proxy","C. Internal TCP/UDP","D. TCP Proxy"],"answer":"13. A. The correct answer is A. HTTP(S) load balancers are global and will route HTTP trafficto the region closest to the user making a request. Option B is incorrect, as SSL Proxy isused for non-HTTPS SSL traffic. Option C is incorrect because it does not support externaltraffic from the public Internet. Option D is incorrect, as TCP Proxy is used fornon-HTTP(S) traffic."},{"index":14,"questions":"14. As a developer, you foresee the need to have a load balancer that can distribute load using only private RFC 1918 addresses. Which load balancer would you use?","choices":["A. Internal TCP/UDP","B. HTTP(S)","C. SSL Proxy","D. TCP Proxy"],"answer":"14. A. The correct answer is A. Only Internal TCP/UDP supports load balancing using privateIP addressing. The other options are all incorrect because they cannot load balance usingprivate IP addresses."},{"index":15,"questions":"15. After a thorough review of the options, a team of developers and network engineers have determined that the SSL Proxy load balancer is the best option for their needs. What other GCP service must they have to use the SSL Proxy load balancer?","choices":["A. Cloud Storage","B. Cloud VPN","C. Premium Tier networking","D. TCP Proxy Load Balancing"],"answer":"15. C. The correct answer is C. All global load balancers require the Premium Tier network,which routes all data over the Google global network and not the public Internet. OptionA is incorrect, as object storage is not needed. Option C is incorrect because a VPN is notrequired. Option D is incorrect, as that is another kind of global load balancer that wouldrequire Premium Tier networking.and Legal Compliance"}],"7":[{"index":1,"questions":"1. A company is migrating an enterprise application to Google Cloud. When running onpremises, application administrators created user accounts that were used to run background jobs. There was no actual user associated with the account, but the administrators needed an identity with which to associate permissions. What kind of identity would you recommend using when running that application in GCP?","choices":["A. Google-associated account","B. Cloud Identity account","C. Service account","D. Batch account"],"answer":"1. C. Option C, a service account, is the best choice for an account that will be associatedwith an application or resource, such as a VM. Both options A and B should be used withactual users. Option D is not a valid type of identity in GCP."},{"index":2,"questions":"2. You are tasked with managing the roles and privileges granted to groups of developers, quality assurance testers, and site reliability engineers. Individuals frequently move between groups. Each group requires a different set of permissions. What is the best way to grant access to resources that each group needs?","choices":["A. Create a group in Google Groups for each of the three groups: developers, quality assurance testers, and site reliability engineers. Add the identities of each user to their respective group. Assign predefined roles to each group.","B. Create a group in Google Groups for each of the three groups: developers, quality assurance testers, and site reliability engineers. Assign permissions to each user and then add the identities to their respective group.","C. Assign each user a Cloud Identity, and grant permissions directly to those identities.","D. Create a G Suite group for each of the three groups: developers, quality assurance testers, and site reliability engineers. Assign permissions to each user and then add the identities to their respective group."],"answer":"2. A. The correct answer is A. The identities should be assigned to groups and predefinedroles assigned to those groups. Assigning roles to groups eases administrative overheadbecause users receive permissions when they are added to a group. Removing a user froma group removes permissions from the user, unless the user receives that permission inanother way. Options B, C, and D are incorrect because you cannot assign permissionsdirectly to a user."},{"index":3,"questions":"3. You are making a presentation on Google Cloud security to a team of managers in your company. Someone mentions that to comply with regulations, the organization will have to follow several security best practices, including least privilege. They would like to know how GCP supports using least privilege. What would you say?","choices":["A. GCP provides a set of three broad roles: owner, editor, and viewer. Most users will be assigned viewer unless they need to change configurations, in which case they will receive the editor role, or if they need to perform administrative functions, in which case they will be assigned owner.","B. GCP provides a set of fine-grained permissions and predefined roles that are assigned those permissions. The roles are based on commonly grouped responsibilities. Users will be assigned only the predefined roles needed for them to perform their duties.","C. GCP provides several types of identities. Users will be assigned a type of identity most suitable for their role in the organization.","D. GCP provides a set of fine-grained permissions and custom roles that are created and managed by cloud users. Users will be assigned a custom role designed specifically for that user’s responsibilities."],"answer":"3. B. The correct answer is option B. Fine-grained permission and predefined roles help imple-ment least privilege because each predefined role has only the permissions needed to carryout a specific set of responsibilities. Option A is incorrect. Primitive roles are coarse grainedand grant more permissions than often needed. Option C is incorrect. Simply creating aparticular type of identity does not by itself associate permissions with users. Option D isnot the best option because it requires more administrative overhead than Option B, and itis a best practice to use predefined roles as much as possible and only create custom roleswhen a suitable predefined role does not exist."},{"index":4,"questions":"4. An online application consists of a front-end service, a back-end business logic service, and a relational database. The front-end service is stateless and runs in an instance group that scales between two and five servers. The back-end business logic runs in a Kubernetes Engine cluster. The database is implemented using Cloud SQL PostgreSQL. How many trust domains should be used for this application?","choices":["A. 1.","B. 2.","C. 3.","D. None. These services do not need trust domains."],"answer":"4. C. The correct option is C—three trust domains. The frontend, backend, and database areall logically separated. They run on three different platforms. Each should be in its owntrust domain. Options A and B are incorrect, as they are too few. Option D is incorrectbecause all services should be considered within a trust domain."},{"index":5,"questions":"5. In the interest of separating duties, one member of your team will have permission to perform all actions on logs. You will also rotate the duty every 90 days. How would you grant the necessary permissions?","choices":["A. Create a Google Group, assign roles/logging.admitn o the group, add the identity of the person who is administering the logs at the start of the 90-day period, and remove the identity of the person who administered logs during the previous 90 days.","B. Assign roles/logging.admitn o the identity of the person who is administering the logs at the start of the 90-day period, and revoke the role from the identity of the person who administered logs during the previous 90 days.","C. Create a Google Group, assign roles/logging.privateLogViewte othe group, add the identity of the person who is administering the logs at the start of the 90-day period, and remove the identity of the person who administered logs during the previous 90 days.","D. Assign roles/logging.privateLogViewte orthe identity of the person who is administering the logs at the start of the 90-day period, and revoke the role from the identity of the person who administered logs during the previous 90 days."],"answer":"5. A. The correct answer is A. A group should be created for administrators and granted thenecessary roles, which in this case is roles/logging.admi .The identity of the personresponsible for a period should be added at the start of the period, and the person who waspreviously responsible should be removed from the group. Option B is not the best optionbecause it assigns roles to an identity, which is allowed but not recommended. If the teamchanges strategy and wants to have three administrators at a time, roles would have to begranted and revoked to multiple identities rather than a single group. Options C and D areincorrect because roles/logging.privateLogViewde oes not grant administrative access."},{"index":6,"questions":"6. Your company is subject to several government and industry regulations that require all personal healthcare data to be encrypted when persistently stored. What must you do to ensure that applications processing protected data encrypts it when it is stored on disk or SSD?","choices":["A. Configure a database to use database encryption.","B. Configure persistent disks to use disk encryption.","C. Configure the application to use application encryption.","D. Nothing. Data is encrypted at rest by default."],"answer":"6. D. The correct answer is D. You do not need to configure any settings to have data encryptedat rest in GCP. Options B, C, and D are all incorrect because no configuration is required."},{"index":7,"questions":"7. Data can be encrypted at multiple levels, such as at the platform, infrastructure, and device levels. Data may be encrypted multiple times before it is written to persistent storage. At the device level, how is data encrypted in GCP?","choices":["A. AES256 or AES128 encryption","B. Elliptic curve cryptography","C. Data Encryption Standard (DES)","D. Blowfish"],"answer":"7. A. The correct answer is A. Option B is incorrect, but it is a strong encryption algorithmand could be used to encrypt data. Option C is incorrect. DES is a weak encryption algo-rithm that is easily broken by today’s methods. Option D is incorrect. Blowfish is a strongencryption algorithm designed as a replacement for DES and other weak encryption algo-rithms but it is not used in GCP."},{"index":8,"questions":"8. In GCP, each data chunk written to a storage system is encrypted with a data encryption key. The key is kept close to the data that it encrypts to ensure low latency when retrieving the key. How does GCP protect the data encryption key so that an attacker who gained access to the storage system storing the key could not use it to decrypt the data chunk?","choices":["A. Writes the data encryption key to a hidden location on disk","B. Encrypts the data encryption key with a key encryption key","C. Stores the data encryption key in a secure Cloud SQL database","D. Applies an elliptic curve encryption algorithm for each data encryption key"],"answer":"8. B. The correct answer is B. The data encryption key is encrypted using a key encryptionkey. Option A is incorrect. There are no hidden locations on disk that are inaccessible froma hardware perspective. Option C is incorrect. Keys are not stored in a relational database.Option D is incorrect. An elliptic curve encryption algorithm is not used."},{"index":9,"questions":"9. Data can be encrypted at different layers of the OSI network stack. Google Cloud may encrypt network data at multiple levels. What protocol is used at layer 7?","choices":["A. IPSec","B. TLS","C. ALTS","D. ARP"],"answer":"9. C. The correct answer is C. Layer 7 is the application layer, and Google uses ALTS at thatlevel. Options A and B are incorrect. IPSec and TLS are used by Google but not at layer 7.Option D is incorrect. ARP is an address resolution protocol, not a security protocol."},{"index":10,"questions":"10. After reviewing security requirements with compliance specialists at your company, you determine that your company will need to manage its own encryption keys. Keys may be stored in the cloud. What GCP service would you recommend for storing keys?","choices":["A. Cloud Datastore","B. Cloud Firestore","C. Cloud KMS","D. Bigtable"],"answer":"10. C. The correct answer is C. Cloud KMS is the key management service in GCP. It isdesigned specifically to store keys securely and manage the lifecycle of keys. Options A andC are incorrect. They are both document databases and are not suitable for low-latency,highly secure key storage. Option D is incorrect. Bigtable is designed for low-latency, high-write volume operations over variable structured data. It is not designed for secure keymanagement."},{"index":11,"questions":"11. The finance department of your company has notified you that logs generated by any finance application will need to be stored for five years. It is not likely to be accessed, but it has to be available if needed. If it were needed, you would have up to three days to retrieve the data. How would you recommend storing that data?","choices":["A. Keep it in Stackdriver Logging.","B. Export it to Cloud Storage and store it in Coldline class storage.","C. Export it to BigQuery and partition it by year.","D. Export it to Cloud Pub/Sub using a different topic for each year."],"answer":"11. B. The correct answer is B. Cloud Storage is the best option for maintaining archived datasuch as log data. Also, since the data is not likely to be accessed, Coldline storage would bethe most cost-effective option. Option A is incorrect because Stackdriver does not retain logdata for five years. Option C is not the best option since the data does not need to be que-ried, and it is likely not structured sufficiently to be stored efficiently in BigQuery. Option Dis incorrect. Cloud Pub/Sub is a messaging service, not a long-term data store."},{"index":12,"questions":"12. The legal department in your company notified software development teams that if a developer can deploy to production, then that developer cannot be allowed to perform the final code review before deploying to production. This is an example of which security best practice?","choices":["A. Defense in depth","B. Separation of duties","C. Least privilege","D. Encryption at rest"],"answer":"12. B. The correct answer is B. The duties of the development team are separated so that noone person can both approve a deployment and execute a deployment. Option A is incor-rect. Defense in depth is the use of multiple security controls to mitigate the same risk.Option C is incorrect because least privilege applies to a set of permissions granted for asingle task, such as deploying to production. Option D is incorrect. Encryption at rest is notrelated to the scenario described in the question."},{"index":13,"questions":"13. A startup has hired you to advise on security and compliance related to their new online game for children ages 10 to 14. Players will register to play the game, which includes collecting the name, age, and address of the player. Initially, the company will target customers in the United States. With which regulation would you advise them to comply?","choices":["A. HIPAA/HITECH","B. SOX","C. COPPA","D. GDPR"],"answer":"13. C. The correct answer is C. The service will collect personal information of children under13 in the United States, so COPPA applies. Option A is incorrect because HIPAA andHITECH apply to protected healthcare data. Option B is incorrect because SOX appliesto financial data. Option D is incorrect because GDPR applies to citizens of the EuropeanUnion, not the United States."},{"index":14,"questions":"14. The company for which you work is expanding from North America to set up operations in Europe, starting with Germany and the Netherlands. The company offers online services that collect data on users. With what regulation must your company comply?","choices":["A. HIPAA/HITECH","B. SOX","C. COPPA","D. GDPR"],"answer":"14. D. The correct answer is D. The service will collect personal information from citizens ofthe European Union, so GDPR applies. Option A is incorrect because HIPAA and HITECHapply to protected healthcare data. Option B is incorrect because SOX applies to financialdata. Option C is incorrect, as it applies to children in the United States."},{"index":15,"questions":"15. Enterprise Self-Storage Systems is a company that recently acquired a startup software company that provides applications for small and midsize self-storage companies. The company is concerned that the business strategy of the acquiring company is not aligned with the software development plans of the software development teams of the acquired company. What IT framework would you recommend the company follow to better align business strategy with software development?","choices":["A. ITIL","B. TOGAF","C. Porters Five Forces Model","D. Ansoff Matrix"],"answer":"15. A. The correct answer is A. ITIL is a framework for aligning business and IT strategies andpractices. Option B is incorrect because TOGAF is an enterprise architecture framework.Option C is incorrect because the Porters Five Forces Model is used to assess competitiveness.Option D is incorrect because the Ansoff Matrix is used to summarize growth strategies."}],"8":[{"index":1,"questions":"1. As an SRE, you are assigned to support several applications. In the past, these applications have had significant reliability problems. You would like to understand the performance characteristics of the applications, so you create a set of dashboards. What kind of data would you display on those dashboards?","choices":["A. Metrics and time-series data measuring key performance attributes, such as CPU utilization","B. Detailed log data from syslog","C. Error messages output from each application","D. Results from the latest acceptance tests"],"answer":"1. A. The correct answer is A. If the goal is to understand performance characteristics, thenmetrics, particularly time-series data, will show the values of key measurements associ-ated with performance, such as utilization of key resources. Option B is incorrect becausedetailed log data describes significant events but does not necessarily convey resource utili-zation or other performance-related data. Option C is incorrect because errors are types ofevents that indicate a problem but are not helpful for understanding normal, baseline opera-tions. Option D is incorrect because acceptance tests measure how well a system meetsbusiness requirements but does not provide point-in-time performance information."},{"index":2,"questions":"2. After determining the optimal combination of CPU and memory resources for nodes in a Kubernetes cluster, you want to be notified whenever CPU utilization exceeds 85 percent for 5 minutes or when memory utilization exceeds 90 percent for 1 minute. What would you have to specify to receive such notifications?","choices":["A. An alerting condition","B. An alerting policy","C. A logging message specification","D. An acceptance test"],"answer":"2. B. The correct answer is B. Alerting policies are sets of conditions, notification specifica-tions, and selection criteria for determining resources to monitor. Option A is incorrectbecause one or more conditions are necessary but not sufficient. Option C is incorrectbecause a log message specification describes the content written to a log when an eventoccurs. Option D is incorrect because acceptance tests are used to assess how well a systemmeets business requirements; it is not related to alerting."},{"index":3,"questions":"3. A compliance review team is seeking information about how your team handles high-risk administration operations, such as granting operating system users root privileges. Where could you find data that shows your team tracks changes to user privileges?","choices":["A. In metric time-series data","B. In alerting conditions","C. In audit logs","D. In ad hoc notes kept by system administrators"],"answer":"3. C. The correct answer is C. Audit logs would contain information about changes to userprivileges, especially privilege escalations such as granting root or administrative access.Option A and Option B are incorrect, as neither records detailed information about accesscontrol changes. Option D may have some information about user privilege changes, butnotes may be changed and otherwise tampered with, so on their own they are insufficientsources of information for compliance review purposes."},{"index":4,"questions":"4. Release management practices contribute to improving reliability by which one of the following?","choices":["A. Advocating for object-oriented programming practices","B. Enforcing waterfall methodologies","C. Improving the speed and reducing the cost of deploying code","D. Reducing the use of stateful services"],"answer":"4. C. The correct option is C. Release management practices reduce manual effort todeploy code. This allows developers to roll out code more frequently and in smallerunits and, if necessary, quickly roll back problematic releases. Option A is incorrectbecause release management is not related to programming paradigms. Option B isincorrect because release management does not require waterfall methodologies. OptionD is incorrect. Release management does not influence the use of stateful or statelessservices."},{"index":5,"questions":"5. A team of software engineers is using release management practices. They want developers to check code into the central team code repository several times during the day. The team also wants to make sure that the code that is checked in is functioning as expected before building the entire application. What kind of tests should the team run before attempting to build the application?","choices":["A. Unit tests","B. Stress tests","C. Acceptance tests","D. Compliance tests"],"answer":"5. A. The correct answer is A. These are tests that check the smallest testable unit of code.These tests should be run before any attempt to build a new version of an application.Option B is incorrect because a stress test could be run on the unit of code, but it is morethan what is necessary to test if the application should be built. Option C is incorrectbecause acceptance tests are used to confirm that business requirements are met; a buildthat only partially meets business requirements is still useful for developers to create.Option D is incorrect because compliance tests is a fictitious term and not an actual class oftests used in release management."},{"index":6,"questions":"6. Developers have just deployed a code change to production. They are not routing any traffic to the new deployment yet, but they are about to send a small amount of traffic to servers running the new version of code. What kind of deployment are they using?","choices":["A. Blue/Green deployment","B. Before/After deployment","C. Canary deployment","D. Stress deployment"],"answer":"6. C. The correct answer is C. This is a canary deployment. Option A is incorrect becauseBlue/Green deployment uses two fully functional environments and all traffic is routed toone of those environments at a time. Option B and Option D are incorrect because they arenot actual names of deployment types."},{"index":7,"questions":"7. You have been hired to consult with an enterprise software development that is starting to adopt agile and DevOps practices. The developers would like advice on tools that they can use to help them collaborate on software development in the Google Cloud. What version control software might you recommend?","choices":["A. Jenkins and Cloud Source Repositories","B. Syslog and Cloud Build","C. GitHub and Cloud Build","D. GitHub and Cloud Source Repositories"],"answer":"7. D. The correct answer is D. GitHub and Cloud Source Repositories are version control sys-tems. Option A is incorrect because Jenkins is a CI/CD tool, not a version control system.Option B is incorrect because neither Syslog nor Cloud Build is a version control system.Option C is incorrect because Cloud Build is not a version control system."},{"index":8,"questions":"8. A startup offers a software-as-a-service solution for enterprise customers. Many of the components of the service are stateful, and the system has not been designed to allow incremental rollout of new code. The entire environment has to be running the same version of the deployed code. What deployment strategy should they use?","choices":["A. Rolling deployment","B. Canary deployment","C. Stress deployment","D. Blue/Green deployment"],"answer":"8. D. The correct answer is D. A Blue/Green deployment is the kind of deployment that allowsdevelopers to deploy new code to an entire environment before switching traffic to it.Option A and Option B are incorrect because they are incremental deployment strategies.Option C is not an actual deployment strategy."},{"index":9,"questions":"9. A service is experiencing unexpectedly high volumes of traffic. Some components of the system are able to keep up with the workload, but others are unable to process the volume of requests. These services are returning a large number of internal server errors. Developers need to release a patch as soon as possible that provides some relief for an overloaded relational database service. Both memory and CPU utilization are near 100 percent. Horizontally scaling the relational database is not an option, and vertically scaling the database would require too much downtime. What strategy would be the fastest to implement?","choices":["A. Shed load","B. Increase connection pool size in the database","C. Partition the workload","D. Store data in a Pub/Sub topic"],"answer":"9. A. The correct option is A. The developers should create a patch to shed load. Option Bwould not solve the problem, since more connections would allow more clients to con-nect to the database, but CPU and memory are saturated, so no additional work can bedone. Option C could be part of a long-term architecture change, but it could not beimplemented quickly. Option D could also be part of a longer-term solution to allowa database to buffer requests and process them at a rate allowed by available databaseresources."},{"index":10,"questions":"10. A service has detected that a downstream process is returning a large number of errors. The service automatically slows down the number of messages it sends to the downstream process. This is an example of what kind of strategy?","choices":["A. Load shedding","B. Upstream throttling","C. Rebalancing","D. Partitioning"],"answer":"10. B. The correct answer is B. This is an example of upstream or client throttling. Option Ais incorrect because load is not shed; rather, it is just delayed. Option C is incorrect. Thereis no rebalancing of load, such as might be done on a Kafka topic. Option D is incorrect.There is no mention of partitioning data.Technical Processes"}],"9":[{"index":1,"questions":"1. A team of early career software engineers has been paired with an architect to work on a new software development project. The engineers are anxious to get started coding, but the architect objects to that course of action because there has been insufficient work prior to development. What steps should be completed before beginning development according to SDLC?","choices":["A. Business continuity planning","B. Analysis and design","C. Analysis and testing","D. Analysis and documentation"],"answer":"1. B. The correct answer is B. Analysis defines the scope of the problem and assessingoptions for solving the problem. Design produces high-level and detailed plans thatguide development. Option A is incorrect, as business continuity planning is not requiredbefore development, though it can occur alongside development. Option C is incorrectbecause testing occurs after software is developed. Similarly, option D is incorrect becausedocumentation comes after development as well."},{"index":2,"questions":"2. In an analysis meeting, a business executive asks about research into COTS. What is this executive asking about?","choices":["A. Research related to deciding to build versus buying a solution","B. Research about a Java object relational mapper","C. A disaster planning protocol","D. Research related to continuous operations through storms (COTS), a business continuity practice"],"answer":"2. A. The correct answer is A. COTS stands for commercial off-the-shelf software, so thequestion is about research related to the question of buy versus build. Option B is incorrect,as COTS is not an ORM. Options C and D are both incorrect. COTS is not about businesscontinuity or disaster recovery."},{"index":3,"questions":"3. Business decision-makers have created a budget for software development over the next three months. There are more projects proposed than can be funded. What measure might the decision-makers use to choose projects to fund?","choices":["A. Mean time between failures (MTBF)","B. Recovery time objectives (RTO)","C. Return on investment (ROI)","D. Marginal cost displacement"],"answer":"3. C. Option C is correct. ROI is a measure used to compare the relative value of differentinvestments. Option A is a measure of reliability and availability. Option B is a requirementrelated to disaster recovery. Option D is a fictitious measure."},{"index":4,"questions":"4. A team of developers is working on a backend service to implement a new business process. They are debating whether to use arrays, lists, or hash maps. In what stage of the SDLC are these developers at present?","choices":["A. Analysis","B. High-level design","C. Detailed design","D. Maintenance"],"answer":"4. C. The correct answer is C because questions of data structure are not usually addresseduntil the detail design stage. Option A is incorrect, as analysis is about scoping a problemand choosing a solution approach. Option B is incorrect because high-level design is dedi-cated to identifying subcomponents and how they function together. Option D is incorrectbecause the maintenance phase is about keeping software functioning."},{"index":5,"questions":"5. An engineer is on call for any service-related issues with a service. In the middle of the night, the engineer receives a notification that a set of APIs is returning HTTP 500 error codes to most requests. What kind of documentation would the engineer turn to first?","choices":["A. Design documentation","B. User documentation","C. Operations documentation","D. Developer documentation"],"answer":"5. C. The correct answer is C. In the middle of the night the primary goal is to get the servicefunctioning properly. Operations documentation, like runbooks, provide guidance on howto start services and correct problems. Option A is incorrect because design documentationmay describe why design decisions were made—it does not contain distilled informationabout running the service. Option B is incorrect, as user documentation is for customers ofthe service. Option D is incorrect because, although developer documentation may eventu-ally help the engineer understand the reason why the service failed, it is not the best optionfor finding specific guidance on getting the service to function normally."},{"index":6,"questions":"6. As a developer, you write code in your local environment, and after testing it, you commit it or write it to a version control system. From there it is automatically incorporated with the baseline version of code in the repository. What is the process called?","choices":["A. Software continuity planning","B. Continuous integration (CI)","C. Continuous development (CD)","D. Software development lifecycle (SDLC)"],"answer":"6. B. The correct answer is B. This is an example of continuous integration because code isautomatically merged with the baseline application code. Option A is not an actual process.Option C is not an actual process, and it should not be confused with continual deploy-ment. Option D is incorrect because the software development lifecycle includes continuousintegration and much more."},{"index":7,"questions":"7. As a consulting architect, you have been asked to help improve the reliability of a distributed system with a large number of custom microservices and dependencies on third-party APIs running in a hybrid cloud architecture. You have decided that at this level of complexity, you can learn more by experimenting with the system than by studying documents and code listings. So, you start by randomly shutting down servers and simulating network partitions. This is an example of what practice?","choices":["A. Irresponsible behavior","B. Integration testing","C. Load testing","D. Chaos engineering"],"answer":"7. D. The correct answer is D. This is an example of chaos engineering. Netflix’s SimianArmy is a collection of tools that support chaos engineering. Option A is incorrect becausethis is a reasonable approach to improving reliability, assuming that the practice is transpar-ent and coordinated with others responsible for the system. Option B is incorrect. This isnot a test to ensure that components work together. It is an experiment to see what happenswhen some components do not work. Option C is incorrect. This does test the ability of thesystem to process increasingly demanding workloads."},{"index":8,"questions":"8. There has been a security breach at your company. A malicious actor outside of your company has gained access to one of your services and was able to capture data that was passed into the service from clients. Analysis of the incident finds that a developer included a private key in a configuration file that was uploaded to a version control repository. The repository is protected by several defensive measures, including role-based access controls and network-level controls that require VPN access to reach the repository. As part of backup procedures, the repository is backed up to a cloud storage service. The folder that stores the backup was mistakenly granted public access privileges for up to three weeks before the error was detected and corrected. During the post-mortem analysis of this incident, one of the objectives should be to","choices":["A. Identify the developer who uploaded the private key to a version control repository. They are responsible for this incident.","B. Identify the system administrator who backed up the repository to an unsecured storage service. They are responsible for this incident.","C. Identify the system administrator who misconfigured the storage system. They are responsible for this incident.","D. Identify ways to better scan code checked into the repository for sensitive information and perform checks on cloud storage systems to identify weak access controls."],"answer":"8. D. The correct answer is D. The goal of the post-mortem is to learn how to prevent thiskind of incident again. Options A, B, and C are all wrong because they focus on blaming asingle individual for an incident that occurred because of multiple factors. Also, laying blamedoes not contribute to finding a solution. In cases where an individual’s negligence or lack ofknowledge is a significant contributing factor, then other management processes should beused to address the problem. Post-mortems exist to learn and to correct technical processes."},{"index":9,"questions":"9. You have just been hired as a cloud architect for a large financial institution with global reach. The company is highly regulated, but it has a reputation for being able to manage IT projects well. What practices would you expect to find in use at the enterprise level that you might not find at a startup?","choices":["A. Agile methodologies","B. SDLC","C. ITIL","D. Business continuity planning"],"answer":"9. C. The correct answer is C. ITIL is a set of enterprise IT practices for managing the fullrange of IT processes, from planning and development to security and support. Options Aand B are likely to be found in all well-run software development teams. Option D may notbe used at many startups, but it should be."},{"index":10,"questions":"10. A software engineer asks for an explanation of the difference between business continuity planning and DR planning. What would you say is the difference?","choices":["A. There is no difference; the terms are synonymous.","B. They are two unrelated practices.","C. DR is a part of business continuity planning, which includes other practices for continuing business operations in the event of an enterprise-level disruption of services.","D. Business continuity planning is a subset of disaster recovery."],"answer":"10. C. The correct answer is C. Disaster recovery is a part of business continuity planning.Options A and B are wrong. They are neither the same nor are they unrelated. Option D isincorrect because it has the relationship backward."},{"index":11,"questions":"11. In addition to ITIL, there are other enterprise IT process management frameworks. Which other standard might you reference when working on enterprise IT management issues?","choices":["A. ISO/ICE 20000","B. Java Coding Standards","C. PEP-8","D. ISO/IEC 27002"],"answer":"11. A. The correct answer is A. ISO/IEC 20000 is a service management standard. OptionsB and C are incorrect. They are programming language–specific standards for Java andPython, respectively. Option D is incorrect. ISO/IEC 27002 is a security standard, althoughyou may reference it for security-related practices."},{"index":12,"questions":"12. A minor problem repeatedly occurs with several instances of an application that causes a slight increase in the rate of errors returned. Users who retry the operation usually succeed on the second or third attempt. By your company’s standards, this is considered a minor incident. Should you investigate this problem?","choices":["A. No. The problem is usually resolved when users retry.","B. No. New feature requests are more important.","C. Yes. But only investigate if the engineering manager insists.","D. Yes. Since it is a recurring problem, there may be an underlying bug in code or weakness in the design that should be corrected."],"answer":"12. D. The correct answer is D. There may be an underlying bug in code or weakness inthe design that should be corrected. Options A and B are incorrect because it should beaddressed, since it adversely impacts customers. Option C is incorrect because softwareengineers and architects can recognize a customer-impacting flaw and correct it."},{"index":13,"questions":"13. A CTO of a midsize company hires you to consult on the company’s IT practices. During preliminary interviews, you realize that the company does not have a business continuity plan. What would you recommend they develop first with regards to business continuity?","choices":["A. Recovery time objectives (RTO)","B. An insurance plan","C. A disaster plan","D. A service management plan"],"answer":"13. C. The correct answer is C. A disaster plan documents a strategy for responding to a disas-ter. It includes information such as where operations will be established, which servicesare the highest priority, what personnel are considered vital to recovery operations, as wellas plans for dealing with insurance carriers and maintaining relations with suppliers andcustomers. Option A is incorrect. Recovery time objectives cannot be set until the detailsof the recovery plan are determined. Option B is incorrect because you cannot decide whatrisk to transfer to an insurance company before understanding what the risks and recoveryobjectives are. Option D is incorrect. A service management plan is part of an enterprise ITprocess structure."},{"index":14,"questions":"14. A developer codes a new algorithm and tests it locally. They then check the code into the team’s version control repository. This triggers an automatic set of unit and integration tests. The code passes, and it is integrated into the baseline code and included in the next build. The build is released and runs as expected for 30 minutes. A sudden spike in traffic causes the new code to generate a large number of errors. What might the team decide to do after the post-mortem analysis of this incident?","choices":["A. Fire the developer who wrote the algorithm","B. Have at least two engineers review all of the code before it is released","C. Perform stress tests on changes to code that may be sensitive to changes in load","D. Ask the engineering manager to provide additional training to the engineer who revised the algorithm"],"answer":"14. C. The correct answer is C. Option A is not correct because blaming engineers and imme-diately imposing severe consequences is counterproductive. It will tend to foster an environ-ment that is not compatible with agile development practices. Option B is incorrect becausethis could be highly costly in terms of engineers’ time, and it is unlikely to find subtle bugsrelated to the complex interaction of multiple components in a distributed system. OptionD is incorrect because, while additional training may be part of the solution, that is for themanager to decide. Post-mortems should be blameless, and suggesting that someone be spe-cifically targeted for additional training in a post-mortem implies some level of blame."},{"index":15,"questions":"15. Your company’s services are experiencing a high level of errors. Data ingest rates are dropping rapidly. Your data center is located in an area prone to hurricanes, and these events are occurring during peak hurricane season. What criteria do you use to decide to invoke your disaster recovery plan?","choices":["A. When your engineering manager says to invoke the disaster recovery plan","B. When the business owner of the service says to invoke the disaster recovery plan","C. When the disaster plan criteria for invoking the disaster recovery plan are met","D. When the engineer on call says to invoke the disaster recovery plan"],"answer":"15. C. The correct answer is C. The criteria for determining when to invoke the disaster recov-ery plan should be defined before a team might have to deal with a disaster. Options A, B,and C are all incorrect because the decision should not be left to the sole discretion of anindividual manager, service owner, or engineer. A company policy should be in place fordetermining when to invoke a DR plan.Business Processes"}],"10":[{"index":1,"questions":"1. You have been asked to help with a new project kickoff. The project manager has invited engineers and managers from teams directly working on the project. They have also invited members of teams that might use the service to be built by the project. What is the motivation of the project manager for inviting these various participants?","choices":["A. To communicate with stakeholders","B. To meet compliance requirements","C. To practice good cost control measures","D. To solicit advice on building team skills"],"answer":"1. A. The correct answer is A. Each of the individuals invited to the meeting have an interestin the project. Option B is incorrect since there is no mention of compliance requirementsand regulations do not typically dictate meeting structures. Options C and D are incorrect,as there is no discussion of cost or skill building."},{"index":2,"questions":"2. A junior engineer asks you to explain some terms often used in meetings. In particular, the engineer wants to know the difference between a project and a program. How would you explain the difference?","choices":["A. There is no difference; the two terms are used interchangeably.","B. A project is part of a program, and programs span multiple departments; both exist to execute organizational strategy.","C. A program is part of a project, and projects span multiple departments; both exist to execute organizational strategy.","D. A project is used only to describe software development efforts, while a program can refer to any company initiative."],"answer":"2. B. Option B is correct. A project is part of a program, and programs span multiple depart-ments; both exist to execute organizational strategy. Option A is incorrect because the wordsdo mean different things. Option C is incorrect because programs are not part of projects.Option D is incorrect because projects do not refer only to software engineering efforts."},{"index":3,"questions":"3. An architect writes a post for an internal blog describing the pros and cons of two approaches to improving the reliability of a widely used service. This is an example of what stage of stakeholder management?","choices":["A. Identifying stakeholders","B. Determining their roles and scope of interests","C. Developing a communications plan","D. Communicating with and influencing stakeholders"],"answer":"3. D. The correct answer is D. This is an example of communicating with stakeholders andinfluencing their opinions about options. Option A is incorrect, as the stakeholders are notidentified here. Option B is incorrect because there is no discussion of individuals’ roles andscope of interest. Option C is incorrect because the architect did not publish a plan."},{"index":4,"questions":"4. Your company provides a SaaS product used by mobile app developers to capture and analyze log messages from mobile devices in real time. Another company begins to offer a similar service but includes alerting based on metrics as well as log messages. This prompts the executives to change strategy from developing additional log analysis features to developing alerting features. This is an example of a change prompted by which one of the following?","choices":["A. Individual choice","B. Competition","C. Skills gap","D. Unexpected economic factors"],"answer":"4. B. The correct answer is B. This is a change because of the introduction of a competi-tive product with more features. Option A is incorrect. This is not a change prompted bythe actions of an individual, such as someone leaving the company. Option C is incorrectbecause a skills gap did not trigger the change, although there may be a skills gap on theteam that now has to implement alerting. Option D is incorrect. There is no mention of eco-nomic factors, such as a recession."},{"index":5,"questions":"5. In May 2018, the EU began enforcement of a new privacy regulation known as the GDPR. This required many companies to change how they manage personal information about citizens of the EU. This is an example of what kind of change?","choices":["A. Individual choice","B. Competition","C. Skills gap","D. Regulation"],"answer":"5. D. The correct answer is D. The changes were prompted by a new regulation. Option A isincorrect. This is not a change prompted by the actions of an individual, such as someoneleaving the company. Option B is incorrect, as there is no mention of competitive pressures.Option C is incorrect. A skills gap did not trigger the change, although there may be a skillsgap on the team that now has to implement alerting."},{"index":6,"questions":"6. A program manager asks for your advice on managing change in projects. The program manager is concerned that there are multiple changes underway simultaneously, and it is difficult to understand the impact of these changes. What would you suggest as an approach to managing this change?","choices":["A. Stop making changes until the program manager can understand their potential impacts.","B. Communicate more frequently with stakeholders.","C. Implement a Plan-Do-Study-Act methodology.","D. Implement cost control measures to limit the impact of simultaneous changes."],"answer":"6. C. The correct option is C. The program manager should use a change management methodol-ogy to control and better understand changes. Option A is incorrect. A program manager maynot be able to stop some changes, such as changes due to regulatory changes, without adverseconsequences. Option B is incorrect because it does not solve the problem presented but may bepart of a solution that includes using a change management strategy. Option D is incorrect, ascost controls will not help the program manager understand the impact of changes."},{"index":7,"questions":"7. A company for whom you consult is concerned about the potential for startups to disrupt its industry. The company has asked for your help implementing new services using IoT, cloud computing, and AI. There is a high risk that this initiative will fail. This is an example of which one of the following?","choices":["A. Typical change management issues","B. A digital transformation initiative","C. A project in response to a competitor’s product","D. A cost management initiative"],"answer":"7. B. The correct answer is B. This is an example of a digital transformation initiative that isattempting fundamental changes in the way that the company delivers value to its custom-ers. Option A is incorrect. This is not a typical change management issue because it involvesthe entire enterprise introducing multiple new technologies. Option C is incorrect. Thescope of this initiative is in response to more than a single competitor. Option D is incor-rect. This is not a cost management initiative."},{"index":8,"questions":"8. You and another architect in your company are evaluating the skills possessed by members of several software development teams. This exercise was prompted by a new program to expand the ways that customers can interact with the company. This will require a significant amount of mobile development. This kind of evaluation is an example of which part of team skill management?","choices":["A. Defining skills needed to execute programs and projects defined by organizational strategy","B. Identifying skill gaps on a team or in an organization","C. Working with managers to develop plans to develop skills of individual contributors","D. Helping recruit and retain people with the skills needed by the team"],"answer":"8. B. The correct answer is B. This exercise is an attempt to identify a skills gap—in this casemobile development skills. Option A is incorrect. This is not about defining skills needed,as that has already been done. Option C is incorrect because it is premature to develop aplan until the gaps are understood. Option D is incorrect because there is no mention ofhiring additional engineers."},{"index":9,"questions":"9. You and an engineering manager in your company are creating a schedule of training courses for engineers to learn mobile development skills. This kind of planning is an example of which part of team skill management?","choices":["A. Defining skills needed to execute programs and projects defined by organizational strategy","B. Identifying skill gaps on a team or in an organization","C. Working with managers to develop plans to develop skills of individual contributors","D. Helping recruit and retain people with the skills needed by the team"],"answer":"9. C. The correct answer is C. This is an example of developing the skills of individual con-tributors. Option A is incorrect. This is not about defining skills needed. Option B is incor-rect. This is not about identifying skills gaps, as that has already been done. Option D isincorrect because it does not entail recruiting."},{"index":10,"questions":"10. After training engineers on the latest mobile development tools and techniques, managers determine that the teams do not have a sufficient number of engineers to complete software development projects in the time planned. The managers ask for your assistance in writing job advertisements reaching out to your social network. These activities are an example of which part of team skill management?","choices":["A. Defining skills needed to execute programs and projects defined by organization strategy","B. Identifying skill gaps on a team or in an organization","C. Working with managers to develop plans to develop skills of individual contributors","D. Helping recruit and retain people with the skills needed by the team"],"answer":"10. D. The correct answer is D. This is an example of recruiting. Option A is incorrect, as thisis not about defining skills needed. Option B is incorrect. This is not about identifying skillsgaps, as that has already been done. Option C is incorrect because it does not entail plan-ning training and skill development."},{"index":11,"questions":"11. A team of consultants from your company is working with a customer to deploy a new offering that uses several services that your company provides. They are making design decisions about how to implement authentication and authorization and want to discuss options with an architect. This is an example of which aspect of customer success management?","choices":["A. Customer acquisition","B. Marketing and sales","C. Professional services","D. Training and support"],"answer":"11. C. The correct answer is C. This is an example of professional services because it involvescustom support and development for customers. Option A is incorrect because the customeris already acquired. Option B is incorrect because there is no marketing or sales involved.Option D is incorrect because this is a consulting engagement and not a training activity."},{"index":12,"questions":"12. Customers are noticing delays in receiving messages from an alerting service that your company provides. They call your company and provide details that are logged into a central database and reviewed by engineers who are troubleshooting the problem. This is an example of which aspect of customer success management?","choices":["A. Customer acquisition","B. Marketing and sales","C. Professional services","D. Training and support"],"answer":"12. D. The correct answer is D. This is an example of training and support because those aresupport activities. Option A is incorrect because the customer is already acquired. OptionB is incorrect because there is no marketing or sales involved. Option C is incorrect becausethis is not a consulting engagement."},{"index":13,"questions":"13. As an architect, you have been invited to attend a trade conference in your field of expertise. In addition to presenting at the conference, you will spend time at your company’s booth in the exhibit hall, where you will discuss your company’s products with conference attendees. This is an example of what aspect of customer success management?","choices":["A. Customer acquisition","B. Marketing and sales","C. Professional services","D. Training and support"],"answer":"13. A. The correct answer is A. This is an example of acquiring customers. Option B is incor-rect because there is no marketing or sales involved. Option C is incorrect because this isnot a consulting engagement. Option D is incorrect because this does not involve trainingand support activities."},{"index":14,"questions":"14. A group of executives has invited you to a meeting to represent architects in a discussion about identifying projects and programs that require funding and prioritizing those efforts based on the company’s strategy and needs. This is an example of what aspect of cost management?","choices":["A. Resource planning","B. Cost estimating","C. Cost budgeting","D. Cost control"],"answer":"14. A. The correct answer is A. This is an example of resource planning because it involvesprioritizing projects and programs. Options B and C are incorrect because there is no costestimating or budgeting done in the meeting. Option D is incorrect because it does notinvolve expenditure approvals or reporting."},{"index":15,"questions":"15. An engineer has been tasked with creating reports to help managers track spending. This is an example of what aspect of cost management?","choices":["A. Resource planning","B. Cost estimating","C. Cost budgeting","D. Cost control"],"answer":"15. D. The correct answer is D. This effort involves reporting on expenditures. Option A isincorrect because there is no review of proposed projects or discussion of priorities. OptionsB and C are incorrect because there is no cost estimating or budgeting done in the meeting.Operations"}],"11":[{"index":1,"questions":"1. A team of developers is tasked with developing an enterprise application. They have interviewed stakeholders and collected requirements. They are now designing the system and plan to begin implementation next. After implementation, they will verify that the application meets specifications. They will not revise the design once coding starts. What application development methodology is this team using?","choices":["A. Extreme programming","B. Agile methodology","C. Waterfall methodology","D. Spiral methodology"],"answer":"1. C. The correct answer is C. This is an example of waterfall methodology because eachstage of the software development lifecycle is performed once and never revisited. OptionA is incorrect. Extreme programming is a type of agile methodology. Option B is incorrectbecause there is no tight collaboration, rapid development and deployment, and frequenttesting. Option D is incorrect because the steps of the software development lifecycle arenot repeated with each iteration focused on defining a subset of work and identifyingrisks."},{"index":2,"questions":"2. A team of developers is tasked with developing an enterprise application. They have interviewed stakeholders and set a scope of work that will deliver a subset of the functionality needed. Developers and stakeholders have identified risks and ways of mitigating them. They then proceed to gather requirements for the subset of functionalities to be implemented. That is followed by design, implementation, and testing. There is no collaboration between developers and stakeholders until after testing, when developers review results with stakeholders and plan the next iteration of development. What application development methodology is this team using?","choices":["A. Extreme programming","B. Agile methodology","C. Waterfall methodology","D. Spiral methodology"],"answer":"2. D. The correct answer is D. This is an example of spiral methodology because each stageof the software development lifecycle is repeated in a cyclical manner, and each iterationbegins with scoping work and identifying risks. Option A is incorrect. Extreme program-ming is a type of agile methodology. Option B is incorrect because there is no tight col-laboration, rapid development and deployment, and frequent testing. Option C is incorrectbecause the steps of the software development lifecycle are repeated."},{"index":3,"questions":"3. A team of developers is tasked with developing an enterprise application. They meet daily with stakeholders to discuss the state of the project. The developers and stakeholders have identified a set of functionalities to be implemented over the next two weeks. After some design work, coding begins. A new requirement is discovered, and developers and stakeholders agree to prioritize implementing a feature to address this newly discovered requirement. As developers complete small functional units of code, they test it. If the code passes the tests, the code unit is integrated with the version-controlled codebase. What application development methodology is this team using?","choices":["A. Continuous integration","B. Agile methodology","C. Waterfall methodology","D. Spiral methodology"],"answer":"3. B. The correct answer is B. This is an example of an agile methodology because develop-ers and stakeholders work closely together, development is done in small units of work thatinclude frequent testing and release, and the team is able to adapt to changes in require-ments without following a rigid linear or cyclical process. Option A is incorrect. Continu-ous integration is not an application development methodology. Option D is incorrectbecause the steps of the software development lifecycle are not repeated with each iterationfocused on defining a subset of work and identifying risks."},{"index":4,"questions":"4. You are a developer at a startup company that is planning to release its first version of a new mobile service. You have discovered a design flaw that generates and sends more data to mobile devices than is needed. This is increasing the latency of messages between mobile devices and backend services running in the cloud. Correcting the design flaw will delay the release of the service by at least two weeks. You decide to address the long latency problem by coding a workaround that does not send the unnecessary data. The design flaw is still there and is generating unnecessary data, but the service can ship under these conditions. This is an example of what?","choices":["A. Incurring technical debt","B. Paying down technical debt","C. Shifting risk","D. Improving security"],"answer":"4. A. The correct answer is A. You are incurring technical debt by making a suboptimaldesign and coding choice in order to meet other requirements or constraints. The code willneed to be refactored in the future. Option B is incorrect. This is not an example of refac-toring suboptimal code. Option C is incorrect, as there is no shifting or transferring of risk.Option D is incorrect. There is no mention that this change would improve the confidential-ity, integrity, or availability of the service."},{"index":5,"questions":"5. You are a developer at a startup company that has just released a new service. During development, you made suboptimal coding choices to keep the project on schedule. You are now planning your next two weeks of work, which you decide will include implementing a feature the product manager wanted in the initial release but was postponed to a release occurring soon after the initial release. You also include time to refactor code that was introduced to correct a bug found immediately before the planned release date. That code blocks the worst impact of the bug, but it does not correct the flaw. Revising that suboptimal code is an example of what?","choices":["A. Incurring technical debt","B. Paying down technical debt","C. Shifting risk","D. Improving security"],"answer":"5. B. The correct answer is B. You are paying down technical debt by changing suboptimalcode that was intentionally used to mitigate but not correct a bug. Option A is incorrect.This is not an example of incurring technical debt because you are not introducing subop-timal code in order to meet other requirements or constraints. Option C is incorrect. Thereis no shifting or transferring of risk. Option D is incorrect. There is no mention that thischange would improve the confidentiality, integrity, or availability of the service."},{"index":6,"questions":"6. As a developer of a backend service for managing inventory, your manager has asked you to include a basic API for the inventory service. You plan to follow best practice recommendations. What is the minimal set of API functions that you would include?","choices":["A. Create, read, update, and delete","B. List, get, create, update, and delete","C. Create, delete, and list","D. Create and delete"],"answer":"6. B. The correct answer is B. The standard API operations are list, get, create, update, anddelete. Options A, C, and D are incorrect because they are all missing at least one of thestandard functions."},{"index":7,"questions":"7. A junior developer asks your advice about handling errors in API functions. The developer wants to know what kind of data and information should be in an API error message. What would you recommend?","choices":["A. Return HTTP status 200 with additional error details in the payload.","B. Return a status code form with the standard 400s and 500s HTTP status codes along with additional error details in the payload.","C. Return error details in the payload, and do not return a code.","D. Define your own set of application-specific error codes."],"answer":"7. B. The correct answer is B. The API should return a standard status code used for errors,in other words, from the 400s or 500s, and include additional details in the payload.Option A is incorrect. 200 is the standard HTTP success code. Option C is incorrectbecause it does not return a standard error code. Option D is incorrect because HTTP APIsshould follow broadly accepted conventions so that users of the API can process standarderror messages and not have to learn application-specific error messages."},{"index":8,"questions":"8. A junior developer asks your advice about performing authentication in API functions. The developer wants to know how they can allow users of the API to make assertions about what they are authorized to do. What would you recommend?","choices":["A. Use JSON Web Tokens (JWTs)","B. Use API keys","C. Use encryption","D. Use HTTPS instead of HTTP"],"answer":"8. A. The correct answer is A. JWTs are a standard way to make authentication assertionssecurely. Option B is incorrect. API keys can be used for authentication, but they do not carryauthentication assertions. Option C is incorrect. Encryption does not specify authenticationinformation. Option D is incorrect. HTTPS does not provide authentication assertions."},{"index":9,"questions":"9. Your startup has released a new online game that includes features that allow users to accumulate points by playing the game. Points can be used to make in-game purchases. You have discovered that some users are using bots to play the game programmatically much faster than humans can play the game. The use of bots is unauthorized in the game. You modify the game API to prevent more than 10 function calls per user, per minute. This is an example of what practice?","choices":["A. Encryption","B. Defense in depth","C. Least privileges","D. Resource limiting"],"answer":"9. D. The correct answer is D. This is an example of rate limiting because it is putting a capon the number of function calls allowed by a user during a specified period of time. OptionA is incorrect. This is not encryption. Option B is incorrect because defense in depthrequires at least two distinct security controls. Option C is incorrect. The solution does notlimit privileges based on a user’s role. In this case, most users are players. They continue tohave the same privileges that they had before resource limiting was put in place."},{"index":10,"questions":"10. A team of developers is creating a set of tests for a new service. The tests are defined using a set of conditions or input values and expected output values. The tests are then executed by reading the test data source, and for each test the software being tested is executed and the output is compared to the expected value. What kind of testing framework is this?","choices":["A. Data-driven testing","B. Hybrid testing","C. Keyword-driven testing","D. Model-based testing"],"answer":"10. A. The correct answer is A. This is an example of data-driven testing because the inputdata and expected output data are stated as part of the test. Option B is incorrect becausethis testing approach does not include two or more frameworks. Option C is incorrectbecause it does not include a set of detailed instructions for executing the test. Option D isincorrect. No simulator is used to generate inputs and expected outputs."},{"index":11,"questions":"11. Your company is moving an enterprise application to Google Cloud. The application runs on a cluster of virtual machines, and workloads are distributed by a load balancer. Your team considered revising the application to use containers and the Kubernetes Engine, but they decide not to make any unnecessary changes before moving the application to the cloud. This is an example of what migration strategy?","choices":["A. Lift and shift","B. Move and improve","C. Rebuild in the cloud","D. End of life"],"answer":"11. A. The correct answer is A. This is a lift-and-shift migration because only requiredchanges are made to move the application to the cloud. Option B and Option C are incor-rect because there is no new development in this migration. Option D is not a valid type ofmigration strategy."},{"index":12,"questions":"12. As a consultant to an insurance company migrating to the Google Cloud, you have been asked to lead the effort to migrate data from AWS S3 to Cloud Storage. Which transfer method would you consider first?","choices":["A. Google Transfer Service","B. gsutilcommand line","C. Google Transfer Appliance","D. Cloud Dataproc"],"answer":"12. A. The correct answer is the Google Transfer Service, which executes jobs that specifysource and target locations. It is the recommended method for transferring data from otherclouds. Option B could be used, but it is not the recommended practice, so it should not bethe first option considered. Option C is incorrect. The Google Transfer Service has to beinstalled in your data center, so it is not an option for migrating data from a public cloud.Option D is incorrect. Cloud Dataproc is a managed Hadoop and Spark service. It is notused for data migrations."},{"index":13,"questions":"13. You are a consultant to an insurance company migrating to GCP. Five petabytes of business-sensitive data need to be transferred from the on-premises data center to Cloud Storage. You have a 10 GB network between the on-premises data center and Google Cloud. What transfer option would you recommend?","choices":["A. gsutil","B. gcloud","C. Cloud Transfer Appliance","D. Cloud Transfer Service"],"answer":"13. C. The correct answer is C. The Cloud Transfer Appliance should be used. Sending 5 PBover a 10 GB network would take approximately two months to transfer. Option A andOption D are not correct because they would use the 10 GB network, and that would taketoo long to transfer and consume network resources. Option B is incorrect. gcloudis usedto manage many GCP services; it is not used to transfer data from on-premises data centersto Cloud Storage."},{"index":14,"questions":"14. You are migrating a data warehouse from an on-premises database to BigQuery. You would like to write a script to perform some of the migration steps. What component of the GCP SDK will you likely need to use to create the new data warehouse in BigQuery?","choices":["A. cbt","B. bq","C. gsutil","D. kubectl"],"answer":"14. B. The correct answer is B. bqis the GCP SDK component used to manage BigQuery.Option A is incorrect. cbtis used to manage Bigtable. Option C is incorrect. gsutilis usedto work with Cloud Storage. Option D is incorrect. kubectis used to work with Kubernetes."},{"index":15,"questions":"15. You are setting up a new laptop that is configured with a standard set of tools for developers and architects, including some GCP SDK components. You will be working extensively with the GCP SDK and want to know specifically which components are installed and up to date. What command would you run on the laptop?","choices":["A. gsutil component list","B. cbt component list","C. gcloud component list","D. bq component list"],"answer":"15. C. The correct answer is C. gcloudis the utility that manages SDK components. OptionA is incorrect. gsutilis for working with Cloud Storage. Option B is incorrect. cbtis forworking with Bigtable. Option D is incorrect. bqis used for working with BigQuery."}],"12":[{"index":1,"questions":"1. Your midsize company has decided to assess the possibility of moving some or all of its enterprise applications to the cloud. As the CTO, you have been tasked with determining how much it would cost and what the benefits of a cloud migration would be. What would you do first?","choices":["A. Take inventory of applications and infrastructure, document dependencies, and identify compliance and licensing issues.","B. Create a request for proposal from cloud vendors.","C. Discuss cloud licensing issues with enterprise software vendors.","D. Interview department leaders to identify their top business pain points."],"answer":"1. A. The correct answer is A. Before migrating to the cloud, one of the first steps is under-standing your own infrastructure, dependencies, compliance issues, and licensing structure.Option B is incorrect. Without an understanding of what you want from a cloud vendor,it is not possible to create a request for proposal. Option C is incorrect. It is too early todiscuss licensing if you don’t understand your current licensing situation and what licens-ing you want to have in the cloud. Option D is incorrect. It is a reasonable thing to do as aCTO, but it is too broad of a topic, and instead discussions should be focused on IT-relatedpain points."},{"index":2,"questions":"2. You are working with a colleague on a cloud migration plan. Your colleague would like to start migrating data. You have completed an assessment but no other preparation work. What would you recommend before migrating data?","choices":["A. Migrating applications","B. Conducting a pilot project","C. Migrating all identities and access controls","D. Redesigning relational data models for optimal performance"],"answer":"2. B. The correct answer is B. Conducting a pilot project will provide an opportunity to learnabout the cloud environment. Option A is incorrect, as applications should be migratedafter data. Option C is incorrect. There is no need to migrate all identities and access con-trols until you understand which identities will need particular roles in the cloud. Option Dis incorrect. There is no reason given that would warrant redesigning a relational databaseas part of the migration."},{"index":3,"questions":"3. As the CTO of your company, you are responsible for approving a cloud migration plan for services that include a wide range of data. You are reviewing a proposed plan than includes an assessment, pilot project, data migration, application migration, and optimization. What should you look for as part of the data migration plan?","choices":["A. Database reconfiguration data","B. Firewall rules to protect databases","C. An assessment of data classification and regulations relevant to the data to be migrated","D. A detailed description of current backup operations"],"answer":"3. C. The correct answer is C. You should be looking for a recognition that data classifica-tion and regulation needs to be considered and addressed. Option A is incorrect. Databaseand network administrators will manage database configuration details when additionalinformation on database implementations are known. Option B is incorrect. It is not neces-sary to specify firewall rules at this stage, since the plan has not been approved. Option D isincorrect. Current backup operations are not relevant to the migration plan any more thanany other routine operational procedures."},{"index":4,"questions":"4. A client of yours is prioritizing applications to move to the cloud. One system written in Java is a Tier 1 production system that must be available 24/7; it depends on three Tier 2 services that are running on-premises, and two other Tier 1 applications depend on it. Which of these factors is least important from a risk assessment perspective?","choices":["A. The application is written in Java.","B. The application must be available 24/7.","C. The application depends on three Tier 2 services.","D. Two other Tier 1 applications depend on it."],"answer":"4. A. The correct answer is A. Java is a widely used, widely supported language for develop-ing a range of applications, including enterprise applications. There is little risk moving aJava application from an on-premises platform to the cloud. All other options are consider-able factors in assessing the risk of moving the application."},{"index":5,"questions":"5. As part of a cloud migration, you will be migrating a relational database to the cloud. The database has strict SLAs, and it should not be down for more than a few seconds a month. The data stores approximately 500 GB of data, and your network has 100 Gbps bandwidth. What method would you consider first to migrate this database to the cloud?","choices":["A. Use a third-party backup and restore application.","B. Use the MySQL data export program, and copy the export file to the cloud.","C. Set up a replica of the database in the cloud, synchronize the data, and then switch traffic to the instance in the cloud.","D. Transfer the data using the Google Transfer Appliance."],"answer":"5. C. The correct answer is C. Because of the strict SLAs, the database should not be downas long as would be required if a MySQL export were used. Option A and Option B wouldleave the database unavailable longer than allowed or needed. Option D is not neededbecause of the small data volume, and it would require the database to be down longer thanallowed by the SLA."},{"index":6,"questions":"6. Your company is running several third-party enterprise applications. You are reviewing the licenses and find that they are transferrable to the cloud, so you plan to take advantage of that option. This form of licensing is known as which one of the following?","choices":["A. Compliant licensing","B. Bring-your-own license","C. Pay-as-you-go license","D. Metered pricing"],"answer":"6. B. The correct answer is B. This is an example of bring your own license. Option A is afictitious term. Options C and D both refer to pay based on usage in the cloud."},{"index":7,"questions":"7. Your company is running several third-party enterprise applications. You are reviewing the licenses and find that they are not transferrable to the cloud. You research your options and see that the vendor offers an option to pay a licensing fee based on how long you use the application in the cloud. What is this option called?","choices":["A. Compliant licensing","B. Bring-your-own license","C. Pay-as-you-go license","D. Incremental payment licensing"],"answer":"7. C. The correct answer is C. This is an example of pay-as-you-go licensing. Options A andD are fictitious terms. Option B is incorrect. You are not using a license that you own inthis scenario."},{"index":8,"questions":"8. You have been asked to brief executives on the networking aspects of the cloud migration. You want to begin at the highest level of abstraction and then drill down into lower-level components. What topic would you start with?","choices":["A. Routes","B. Firewalls","C. VPCs","D. VPNs"],"answer":"8. C. The correct answer is C. VPCs are the highest networking abstraction and constitute acollection of network components. Options A, B, and C are wrong because they are lower-level components within a VPC."},{"index":9,"questions":"9. You have created a VPC in Google Cloud, and subnets were created automatically. What range of IP addresses would you not expect to see in use with the subnets?","choices":["A. 10.0.0.0 to 10.255.255.255","B. 72.16.0.0 to 172.31.255.255","C. 192.168.0.0 to 192.168.255.255","D. 201.1.1.0 to 201.2.1.0"],"answer":"9. D. The correct answer is D. It is not an RFC 1918 private address, which is within theaddress ranges used with subnets. Options A, B, and C are all incorrect because they areprivate address ranges and may be used with subnets."},{"index":10,"questions":"10. A network engineer is helping you plan connectivity between your on-premises network and Google Cloud. The engineer estimates that you will need 6 Gbps of bandwidth in total between the on-premises data center and Google Cloud. The traffic may be split between multiple connections. How many VPN endpoints will you need?","choices":["A. 1","B. 2","C. 3","D. 6"],"answer":"10. B. The correct answer is B because each VPN endpoint supports up to 3 Gbps, so two willbe sufficient. Option A is incorrect. That would provide only half of the needed bandwidth.Options C and D are incorrect because, although they would have sufficient bandwidth,they would cost more and there is no business justification for the additional cost."},{"index":11,"questions":"11. During migration planning, you learn that traffic to the subnet containing a set of databases must be restricted. What mechanism would you plan to use to control the flow of traffic to a subnet?","choices":["A. IAM roles","B. Firewall rules","C. VPNs","D. VPCs"],"answer":"11. B. The correct answer is B. Firewall rules are used to control the flow of traffic. Option Ais incorrect because IAM roles are used to assign permissions to identities, such as users orservice accounts. Option C is incorrect. A VPN is a network link between Google Cloudand on-premises networks. Option D is incorrect. VPCs are high-level abstractions group-ing lower-level network components."},{"index":12,"questions":"12. During migration planning, you learn that some members of the network management team will need the ability to manage all network components, but others on the team will only need read access to the state of the network. What mechanism would you plan to use to control the user access?","choices":["A. IAM roles","B. Firewall rules","C. VPNs","D. VPCs"],"answer":"12. A. The correct answer is A. IAM roles are used to assign permissions to identities, suchas users or service accounts. These permissions are assigned to roles which are assigned tousers. Option B is incorrect. Firewall rules are used to control the flow of traffic betweensubnets. Option C is incorrect. A VPN is a network link between the Google Cloud and on-premises networks. Option D is incorrect. VPCs are high-level abstractions grouping lower-level network components."},{"index":13,"questions":"13. Executives in your company have decided that the company should not route its GCP-only traffic over public internet networks. What Google Cloud service would you plan to use to distribute the workload of an enterprise application?","choices":["A. Global load balancing","B. Simple network management protocol","C. Content delivery network","D. VPNs"],"answer":"13. A. The correct answer is A. Global load balancing is the service that would route traffic tothe nearest healthy instance using Premium Network Tier. Option B is incorrect. SNMP isa management protocol, and it does not enable global routing. Options C and D are wrongbecause they are network services but do not enable global routing."},{"index":14,"questions":"14. Executives in your company have decided to expand operations from just North America to Europe as well. Applications will be run in several regions. All users should be routed to the nearest healthy server running the application they need. What Google Cloud service would you plan to use to meet this requirement?","choices":["A. Global load balancing","B. Cloud Interconnect","C. Content delivery network","D. VPNs"],"answer":"14. A. The correct answer is A, global load balancing will route traffic to the nearest healthyinstance. Option B is incorrect, Cloud Interconnect is a way to implement hybrid comput-ing. Option C is incorrect. Content delivery networks are used to distribute content inorder to reduce latency when delivering that content. Option D is incorrect. VPNs link on-premises data centers to the Google Cloud."},{"index":15,"questions":"15. Executives in your company have decided that the company should expand its service offerings to a global market. You company distributes education content online. Maintaining low latency is a top concern. What type of network service would you expect to use to ensure low-latency access to content from around the globe?","choices":["A. Routes","B. Firewall rules","C. Content delivery network"],"answer":"15. C. The correct answer is C. A content delivery network would be used to distribute videocontent globally to reduce network latency. Option A is incorrect. Routes are used to con-trol traffic flow and are not directly related to reducing latency of content delivery, althougha poorly configured set of routes could cause unnecessarily long latencies. Option B isincorrect. Firewalls will not reduce latency. Option D is incorrect because VPNs are used tolink on-premises data centers to the Google Cloud."}]}