{"1":[{"index":1,"questions":"1. What is the fundamental unit of computing in cloud computing?","choices":["A. Physical server","B. VM","C. Block","D. Subnet"],"answer":"1. B. The basic unit for purchasing computing resources is the virtual machine (VM). Aphysical server underlies VMs, but the resources of a physical server are allocated to VMs.Blocks and subnets are not relevant to the fundamental unit of computing."},{"index":2,"questions":"2. If you use a cluster that is managed by a cloud provider, which of these will be managed for you by the cloud provider?","choices":["A. Monitoring","B. Networking","C. Some security management tasks","D. All of the above"],"answer":"2. D. When using managed clusters, the cloud provider will monitor the health of nodes in thecluster, set up networking between nodes in the cluster, and configure firewall and othersecurity controls."},{"index":3,"questions":"3. You need serverless computing for file processing and running the backend of a website; which two products can you choose from Google Cloud Platform?","choices":["A. Kubernetes Engine and Compute Engine","B. App Engine and Cloud Functions","C. Cloud Functions and Compute Engine","D. Cloud Functions and Kubernetes Engine"],"answer":"3. B. App Engine is a serverless platform for running applications, while Cloud Functions is aservice for executing short-running functions in response to events. Kubernetes Engine is amanaged cluster service, and both Kubernetes Engine and Compute Engine require you toconfigure servers."},{"index":4,"questions":"4. You have been asked to design a storage system for a web application that allows users to upload large data files to be analyzed by a business intelligence workflow. The files should be stored in a high-availability storage system. File system functionality is not required. Which storage system in Google Cloud Platform should be used?","choices":["A. Block storage","B. Object storage","C. Cache","D. Network File System"],"answer":"4. B. Object storage, like Cloud Storage, provides redundantly stored objects without lim-its on the amount of data you can store, which makes option B correct. Since file systemfunctionality is not required, option D is not a good option. Block storage could be used,but you would have to manage your own replication to ensure high availability. Caches aretransient, in-memory storage and are not high-availability, persistent storage systems."},{"index":5,"questions":"5. All block storage systems use what block size?","choices":["A. 4KB","B. 8KB","C. 16KB","D. Block size can vary.12 Chapter 1 ■ Overview of Google Cloud Platform"],"answer":"5. D. Block sizes in a block storage system can vary; therefore, option D is the correct answer.Block size is established when a file system is created. 4KB block sizes are commonly usedin Linux."},{"index":6,"questions":"6. You have been asked to set up network security in a virtual private cloud. Your company wants to have multiple subnetworks and limit traffic between the subnetworks. Which net- work security control would you use to control the flow of traffic between subnets?","choices":["A. Identity access management","B. Router","C. Firewall","D. IP address table"],"answer":"6. C. Firewalls in Google Cloud Platform (GCP) are software-defined network controls thatlimit the flow of traffic into and out of a network or subnetwork, so option C is the correctanswer. Routers are used to move traffic to appropriate destinations on the network. Iden-tity access management is used for authenticating and authorizing users; it is not relevant tonetwork controls between subnetworks. IP address tables are not a security control."},{"index":7,"questions":"7. When you create a machine learning service to identify text in an image, what type of serv- ers should you choose to manage compute resources?","choices":["A. VMs","B. Clusters of VMs","C. No servers; specialized services are serverless","D. VMs running Linux only"],"answer":"7. C. Option C is correct because specialized services in GCP are serverless. Google managesthe compute resources used by the services. There is no need for a user to allocate ormonitor VMs."},{"index":8,"questions":"8. Investing in servers for extended periods of time, such as committing to use servers for three to five years, works well when?","choices":["A. A company is just starting up","B. A company can accurately predict server need for an extended period of time","C. A company has a fixed IT budget","D. A company has a variable IT budget"],"answer":"8. B. Option B is correct; investing in servers works well when an organization can accuratelypredict the number of servers and other equipment it will need for an extended period andcan utilize that equipment consistently. Startups are not established businesses with his-tories that can guide expected needs in three to five years. It does not matter if a budget isfixed or variable; investing in servers should be based on demand for server capacity."},{"index":9,"questions":"9. Your company is based in X and will be running a virtual server for Y. What factor deter- mines the unit per minute cost?","choices":["A. The time of day the VM is run","B. The characteristics of the server","C. The application you run","D. None of the above"],"answer":"9. B. The characteristics of the server, such as the number of virtual servers, the amount ofmemory, and the region where you run the VM, influence the cost, so option B is correct.Time of day is not a factor, nor is the type of application you run on the VM."},{"index":10,"questions":"10. You plan to use Cloud Vision to analyze images and extract text seen in the image. You plan to process between 1,000 and 2,500 images per hour. How many VMs should you allocate to meet peak demand?","choices":["A. 1","B. 10","C. 25","D. None; Cloud Vision is a serverless service."],"answer":"10. D. Cloud Vision is one of GCP’s specialized services. Users of the service do not need toconfigure any VMs to use the service. Chapter 1: Overview of Google Cloud Platform 465"},{"index":11,"questions":"11. You have to run a number of services to support an application. Which of the following is a good deployment model?","choices":["A. Run on a large, single VM","B. Use containers in a managed cluster Review Questions 13","C. Use two large VMs, making one of them read only","D. Use a small VM for all services and increase the size of the VM when CPU utilization exceeds 90 percent"],"answer":"11. B. Containers give the most flexibility for using the resources of a cluster efficiently andorchestration platforms reduce the operations overhead, which makes option B correct.Running in a single cluster is not recommended because if the server fails, all services willbe down. Using two VMs with one read-only is not useful. Read-only servers are sometimesused with databases, but there was no mention of databases in the question. Using a smallVM and upgrading when it is no longer able to keep up with the workload delivers poor-quality service to users and should be avoided."},{"index":12,"questions":"12. You have created a VM. Which of the following system administration operations are you allowed to perform on it?","choices":["A. Configure the file system","B. Patch operating system software","C. Change file and directory permissions","D. All of the above"],"answer":"12. D. All of the operations are available to a system administrator after creating a VM,so option D is correct."},{"index":13,"questions":"13. Cloud Filestore is based on what file system technology?","choices":["A. Network File System (NFS)","B. XFS","C. EXT4","D. ReiserFS"],"answer":"13. A. Option A is correct; Cloud Filestore is based on Network Filesystem (NSF), which is adistributed file management system. The other options are file systems supported by Linuxbut are not the foundation of Cloud Filestore."},{"index":14,"questions":"14. When setting up a network in GCP, your network the resources in it are treated as what?","choices":["A. Virtual private cloud","B. Subdomain","C. Cluster","D. None of the above"],"answer":"14. A. When you create a network, it is treated as a virtual private cloud, which makes optionA correct. Resources are added to the VPC and are not accessible outside the VPC unlessyou explicitly configure them to be. A subdomain is related to web domains and not relatedto GPC network configuration. Clusters, such as Kubernetes clusters, may be in your net-work, but are not a characteristic of the network."},{"index":15,"questions":"15. You need to store data for X and therefore you are using a cache for Y. How will the cache affect data retrieval?","choices":["A. A cache improves the execution of client-side JavaScript.","B. A cache will continue to store data even if power is lost, improving availability.","C. Caches can get out of sync with the system of truth.","D. Using a cache will reduce latency, since retrieving from a cache is faster than retrieving from SSDs or HDDs."],"answer":"15. D. Caches use memory, and that makes them the fastest storage type for reading data, sooption D is right. Caches are data stores on the backend of distributed systems, not the cli-ents. A cache would have no effect on client-side JavaScript execution. Caches do not storedata in a cache if power is lost; the data would have to be reloaded. Caches can get out ofsync with the system of truth because the system of truth could be updated, but the cachemay not be updated. Caches have faster read times than SSDs and HDDs."},{"index":16,"questions":"16. Why can cloud providers offer elastic resource allocation?","choices":["A. Cloud providers can take resources from lower-priority customers and give them to higher-priority customers.","B. Extensive resources and the ability to quickly shift resources between customers enables public cloud providers to offer elastic resource allocation more efficiently than can be done in smaller data centers.","C. They charge more the more resources you use.","D. They don’t.14 Chapter 1 ■ Overview of Google Cloud Platform"],"answer":"16. B. Option B is correct; cloud providers have large capacity and can quickly allocatethose resources to different customers. With a mix of customers and workloads, they canoptimize the allocation of resources. Option A is incorrect; cloud providers do not takeresources from one customer to give them to another, with the exception of preemptibleinstances. Option C is incorrect; cloud providers usually offer discounts for increased use."},{"index":17,"questions":"17. What is not a characteristic of specialized services in Google Cloud Platform?","choices":["A. They are serverless; you do not need to configure servers or clusters.","B. They provide a specific function, such as translating text or analyzing images.","C. They require monitoring by the user.","D. They provide an API to access the functionality of the service."],"answer":"17. C. Specialized services are monitored by Google so users do not have to monitor them;therefore, option C is correct. Specialized services provide a specific compute functionalitybut do not require the user to configure any resources. They also provide APIs."},{"index":18,"questions":"18. Your client’s transactions must access a drive attached to a VM that allows for random access to parts of files. What kind of storage does the attached drive provide?","choices":["A. Object storage","B. Block storage","C. NoSQL storage","D. Only SSD storage"],"answer":"18. B. Attached drives are block storage devices. Cloud Storage is the object storage serviceand does not attach directly to a VM. NoSQL is a type of database, not a storage system.Attached drives may be either SSDs or hard drives."},{"index":19,"questions":"19. You are deploying a new relational database to support a web application. Which type of storage system would you use to store data files of the database?","choices":["A. Object storage","B. Data storage","C. Block storage","D. Cache"],"answer":"19. C. Databases require persistent storage on block devices. Object storage does not providedata block or file system storage, making option C the correct answer. Data storage is not atype of storage system. Caches are often used with databases to improve read performance,but they are volatile and are not suitable for persistently storing data files."},{"index":20,"questions":"20. A user prefers services that require minimal setup; why would you recommend Cloud Storage, App Engine, and Cloud Functions?","choices":["A. They are charged only by time.","B. They are serverless.","C. They require a user to configure VMs.","D. They can only run applications written in Go. ■ 34 Chapter 2 Google Cloud Computing Services Review Questions You can find the answers in the Appendix."],"answer":"20. B. All three services are serverless, so the user does not need to configure VMs; therefore,option B is correct. Cloud Storage is charged based on time and size of data stored. AppEngine Standard and Cloud Functions are not restricted to just the Go language.466 Appendix ■ Answers to Review QuestionsChapter 2: Google Cloud ComputingServices"}],"2":[{"index":1,"questions":"1. You are planning to deploy a SaaS application for customers in North America, Europe, and Asia. To maintain scalability, you will need to distribute workload across servers in multiple regions. Which GCP service would you use to implement the workload distribution?","choices":["A. Cloud DNS","B. Cloud Spanner","C. Cloud Load Balancing","D. Cloud CDN"],"answer":"1. C. Cloud Load Balancing distributes workloads within and across regions, provides healthchecks, and implements autoscaling. Cloud DNS provides domain name services, such astranslating a URL like www.example.cotmo an IP address. Cloud Spanner is a distributedrelational database but does not implement workload distribution. Cloud CDN distributescontent across regions to reduce latency when delivering content to users across the globe."},{"index":2,"questions":"2. You have decided to deploy a set of microservices using containers. You could install and manage Docker on Compute Engine instances, but you’d rather have GCP provide some container management services. Which two GCP services allow you to run containers in a managed service?","choices":["A. App Engine standard environment and App Engine flexible environment","B. Kubernetes Engine and App Engine standard environment","C. Kubernetes Engine and App Engine flexible environment","D. App Engine standard environment and Cloud Functions"],"answer":"2. C. App Engine flexible environments allow you to run containers on the App Engine PaaS.Kubernetes Engine is an orchestration platform for running containers. Both provide con-tainer management services. The App Engine standard environment runs applications inlanguage-specific sandboxes and is not a general container management system. CloudFunctions is a serverless service for running code in response to events. It does not providecontainer services."},{"index":3,"questions":"3. Why would an API developer want to use the Apigee API platform?","choices":["A. To get the benefits of routing and rate-limiting","B. Authentication services","C. Version control of code","D. A and B","E. All of the above"],"answer":"3. D. Options A and B are both correct answers. The Apigee API platform provides policy-based rate-limiting and routing services to help accommodate spikes in traffic. It alsoprovides OAuth 2.0 and SAML authentication. It does not provide version control; CloudSource Repositories is the service user for version control."},{"index":4,"questions":"4. You are deploying an API to the public Internet and are concerned that your service will be subject to DDoS attacks. Which GCP service should you consider to protect your API?","choices":["A. Cloud Armor","B. Cloud CDN","C. Cloud IAM","D. VPCs Review Questions 35"],"answer":"4. A. Cloud Armor builds on GCP’s load balancing services to provide the ability to allow orrestrict access based on IP address, deploy rules to counter cross-site scripting attacks, andprovide countermeasures to SQL injection attacks. Cloud CDN is a content distributionservice, not a security service. Identity Access Management is a security service, but it is forauthentication and authorization, not denial-of-service mitigation. Virtual private cloudsare used to restrict network access to an organization’s resources, but it does not have fea-tures to mitigate denial-of-service attacks. Also, Cloud CDN acts as a first line of defense inthe case of DDoS attacks."},{"index":5,"questions":"5. You have an application that uses a Pub/Sub message queue to maintain a list of tasks that are to be processed by another application. The application that consumes messages from the Pub/Sub queue removes the message only after completing the task. It takes approxi- mately 10 seconds to complete a task. It is not a problem if two or more VMs perform the same task. What is a cost-effective configuration for processing this workload?","choices":["A. Use preemptible VMs","B. Use standard VMs","C. Use DataProc","D. Use Spanner"],"answer":"5. A. This is a good use case for preemptible VMs because they could reduce the cost of run-ning the second application without the risk of losing work. Since tasks are deleted from thequeue only after they are completed if a preemptible VM is shut down before completingthe task, another VM can perform the task. Also, there is no harm in running a task morethan once, so if two VMs do the same task, it will not adversely affect the output of theapplication. DataProc and Spanner are not appropriate products for this task."},{"index":6,"questions":"6. Your department is deploying an application that has a database backend. You are con- cerned about the read load on the database server and want to have data available in mem- ory to reduce the time to respond to queries and to reduce the load on the database server. Which GCP service would you use to keep data in memory?","choices":["A. Cloud SQL","B. Cloud Memorystore","C. Cloud Spanner","D. Cloud Datastore"],"answer":"6. B. Cloud Memorystore is the only GCP designed to cache data in memory. Cloud SQL isa relational database service and might be a good option for the backend database. CloudSpanner is a global relational database and is a good option when you need a globally con-sistent database. Cloud Datastore is a document database suitable for product catalogs, userprofiles, and other semistructured data."},{"index":7,"questions":"7. The Cloud SDK can be used to configure and manage resources in which of the following services?","choices":["A. Compute Engine","B. Cloud Storage","C. Network firewalls","D. All of the above"],"answer":"7. D. All three of the services listed, Compute Engine, Cloud Storage, and network firewalls,can be managed and configured using Cloud SDK."},{"index":8,"questions":"8. What server configuration is required to use Cloud Functions?","choices":["A. VM configuration","B. Cluster configuration","C. Pub/Sub configuration","D. None"],"answer":"8. D. Cloud Functions is a serverless product, no configuration is required. Chapter 2: Google Cloud Computing Services 467"},{"index":9,"questions":"9. You have been assigned the task of consolidating log data generated by each instance of an application. Which of the Stackdriver management tools would you use?","choices":["A. Monitoring","B. Trace","C. Debugger","D. Logging36 Chapter 2 ■ Google Cloud Computing Services"],"answer":"9. D. The Stackdriver Logging product is used to consolidate and manage logs generated byapplications and servers."},{"index":10,"questions":"10. Which specialized services are most likely to be used to build a data warehousing platform that requires complex extraction, transformation, and loading operations on batch data as well as processing streaming data?","choices":["A. Apigee API platform","B. Data analytics","C. AI and machine learning","D. Cloud SDK"],"answer":"10. B. The data analytics set of specialized services includes products that help with extraction,transformation, and loading (ETL) and work with both batch and streaming data. The Api-gee API platform is used for managing APIs and does not meet the needs described. AI andmachine learning might be useful for analyzing data in the data warehouse, but the servicesin that set are not always helpful for ETL operations. Cloud SDK is used to control servicesbut by itself is not directly able to perform the operations needed."},{"index":11,"questions":"11. Your company has deployed 100,000 Internet of Things (IoT) sensors to collect data on the state of equipment in several factories. Each sensor will collect and send data to a data store every 5 seconds. Sensors will run continuously. Daily reports will produce data on the maximum, minimum, and average value for each metric collected on each sensor. There is no need to support transactions in this application. Which database product would you recommend?","choices":["A. Cloud Spanner","B. Cloud Bigtable","C. Cloud SQL MySQL","D. Cloud SQL PostgreSQL"],"answer":"11. B. Bigtable is designed to accept billions of rows of data. Collecting data from100,000 sensors every 5 seconds will generate 6,000,000 data points every minute, or8,640,000,000 data points per day. Spanner is a relational database and supports transac-tions, but they are not needed. Cloud SQL MySQL and Cloud SQL PostgreSQL would bedifficult to scale to this level of read and write performance."},{"index":12,"questions":"12. You are the lead developer on a medical application that uses patients’ smartphones to capture biometric data. The app is required to collect data and store it on the smartphone when data cannot be reliably transmitted to the backend application. You want to minimize the amount of development you have to do to keep data synchronized between smartphones and backend data stores. Which data store option should you recommend?","choices":["A. Cloud Firestore","B. Cloud Spanner","C. Cloud Datastore","D. Cloud SQL"],"answer":"12. A. Cloud Firestore is a mobile database service that can synchronize data between mobiledevices and centralized storage. Spanner is a global relational database for large-scaleapplications that require transaction support in highly scaled databases. Datastore andCloud SQL could be used but would require more custom development to synchronize databetween mobile devices and the centralized data store."},{"index":13,"questions":"13. A software engineer comes to you for a recommendation. She has implemented a machine learning algorithm to identify cancerous cells in medical images. The algorithm is compu- tationally intensive, makes many mathematical calculations, requires immediate access to large amounts of data, and cannot be easily distributed over multiple servers. What kind of Compute Engine configuration would you recommend?","choices":["A. High memory, high CPU","B. High memory, high CPU, GPU","C. Mid-level memory, high CPU","D. High CPU, GPU Review Questions 37"],"answer":"13. B. A computationally intensive application obviously requires high CPUs, but the fact thatthere are many mathematical calculations indicates that a GPU should be used. You mightconsider running this in a cluster, but the work is not easily distributed over multiple serv-ers, so you will need to have a single server capable of handling the load. Immediate accessto large amounts of data indicates that a high-memory machine should be recommended."},{"index":14,"questions":"14. You are tasked with mapping the authentication and authorization policies of your on-premises applications to GPC’s authentication and authorization mechanisms. The GCP documentation states that an identity must be authenticated in order to grant privileges to that identity. What does the term identity refer to?","choices":["A. VM ID","B. User","C. Role","D. Set of privileges"],"answer":"14. B. Identities are abstractions of users. They can also represent characteristics of processesthat run on behalf of a human user or a VM in the GCP. Identities are not related to VMIDs. Roles are collections of privileges that can be granted to identities. Option D issynonymous with option C."},{"index":15,"questions":"15. A client is developing an application that will need to analyze large volumes of text information. The client is not expert in text mining or working with language. What GCP service would you recommend they use?","choices":["A. Cloud Vision","B. Cloud ML","C. Cloud Natural Language Processing","D. Cloud Text Miner"],"answer":"15. C. Cloud Natural Language Processing provides functionality for analyzing text. CloudText Miner does not exist. Cloud ML is a general-purpose machine learning service thatcould be applied to text analysis but would require knowledge of language processing,which the client does not have. Cloud Vision is for image processing."},{"index":16,"questions":"16. Data scientists in your company want to use a machine learning library available only in Apache Spark. They want to minimize the amount of administration and DevOps work. How would you recommend they proceed?","choices":["A. Use Cloud Spark","B. Use Cloud Dataproc","C. Use Bigquery","D. Install Apache Spark on a cluster of VMs"],"answer":"16. B. Both options B and D would meet the need of running Spark, which would give the datascientists access to the machine library they need. However, option D requires that theymanage and monitor the cluster of servers, which would require more DevOps and admin-istration work than if they used the Dataproc service. Option C, BigQuery, is a scalabledatabase, not a platform for running Spark. Cloud Spark is a fictitious product and doesnot exist in the GCP."},{"index":17,"questions":"17. Database designers at your company are debating the best way to move a database to GCP. The database supports an application with a global user base. Users expect support for transactions and the ability to query data using commonly used query tools. The database designers decide that any database service they choose will need to support ANSI 2011 and global transactions. Which database service would you recommend?","choices":["A. Cloud SQL","B. Cloud Spanner","C. Cloud Datastore","D. Cloud Bigtable"],"answer":"17. B. Option B is correct. Spanner supports ANSI 2011 standard SQL and global transac-tions. Cloud SQL supports standard SQL but does not have global transaction. Datastoreand Bigtable are NoSQL databases.468 Appendix ■ Answers to Review Questions"},{"index":18,"questions":"18. Which specialized service supports both batch and stream processing workflows?","choices":["A. Cloud Dataproc","B. Bigquery","C. Cloud Datastore","D. AutoML38 Chapter 2 ■Google Cloud Computing Services"],"answer":"18. A. Dataproc is designed to execute workflows in both batch and streaming modes, whichmakes option A correct. BigQuery is a data warehouse service. Datastore is a documentdatabase. AutoML is a machine learning service."},{"index":19,"questions":"19. You have a Python application you’d like to run in a scalable environment with the least amount of management overhead. Which GCP product would you select?","choices":["A. App Engine flexible environment","B. Cloud Engine","C. App Engine standard environment","D. Kubernetes Engine"],"answer":"19. C. App Engine standard environment provides a serverless Python sandbox that scalesautomatically, so option C is correct. App Engine flexible environment runs containers andrequires more configuration. Cloud Engine and Kubernetes Engine both require significantmanagement and monitoring."},{"index":20,"questions":"20. A product manager at your company reports that customers are complaining about the reliability of one of your applications. The application is crashing periodically, but developers have not found a common pattern that triggers the crashes. They are concerned that they do not have good insight into the behavior of the application and want to perform a detailed review of all crash data. Which Stackdriver tool would you use to view consolidated crash information?","choices":["A. DataProc","B. Monitoring","C. Logging","D. Error Reporting Review Questions 61 Review Questions You can find the answers in the Appendix."],"answer":"20. D. Error reporting consolidates crash information, which makes Error Reporting the rightanswer. Monitoring collects metrics on application and server performance. Logging is alog management service. Dataproc is not part of Stackdriver; it is a managed Hadoop andSpark service.Chapter 3: Projects, Service Accounts,and Billing"}],"3":[{"index":1,"questions":"1. You are designing cloud applications for a healthcare provider. The records management application will manage medical information for patients. Access to this data is limited to a small number of employees. The billing department application will have insurance and payment information. Another group of employees will have access billing information. In addition, the billing system will have two components: a private insurance billing system and a government payer billing system. Government regulations require that software used to bill the government must be isolated from other software systems. Which of the follow- ing resource hierarchies would meet these requirements and provide the most flexibility to adapt to changing requirements?","choices":["A. One organization, with folders for records management and billing. The billing folder would have private insurer and government payer folders within it. Common constraints would be specified in organization-level policies. Other policies would be defined at the appropriate folder.","B. One folder for records management, one for billing, and no organization. Policies defined at the folder level.","C. One organization, with folders for records management, private insurer, and govern- ment payer below the organization. All constraints would be specified in organization- level policies. All folders would have the same policy constraints.","D. None of the above."],"answer":"1. A. Option A, the correct answer, separates the two main applications into their own fold-ers and further allows separating private insurance from government payer, but usingfolders for each. This satisfies the regulatory need to keep the government payer softwareisolated from other software. Option B does not include an organization, which is the rootof the resource hierarchy. Option C is not flexible with regard to differences in constraintson different applications. Option D is false because option A does meet the requirements."},{"index":2,"questions":"2. When you create a hierarchy, you can have more than one of which structure?","choices":["A. Organization only","B. Folder only","C. Folder and project","D. Project only"],"answer":"2. C. Resource hierarchies have a single organization at the root, which makes option C cor-rect. Below that, there are folders that can contain other folders or projects. Folders cancontain multiple folders and multiple projects."},{"index":3,"questions":"3. You are designing an application that uses a series of services to transform data from its original form into a format suitable for use in a data warehouse. Your transformation appli- cation will write to the message queue as it processes each input file. You don’t want to give users permission to write to the message queue. You could allow the application to write to the message queue by using which of the following?","choices":["A. Billing account","B. Service account","C. Messaging account","D. Folder62 Chapter 3 ■ Projects, Service Accounts, and Billing"],"answer":"3. B. Service accounts are designed to give applications or VMs permission to perform tasks.Billing accounts are for associating charges with a payment method. Folders are part ofresource hierarchies and have nothing to do with enabling an application to perform a task.Messaging accounts are a fictitious option."},{"index":4,"questions":"4. Your company has a number of policies that need to be enforced for all projects. You decide to apply policies to the resource hierarchy. Not long after you apply the policies, an engineer finds that an application that had worked prior to implementing policies is no lon- ger working. The engineer would like you to create an exception for the application. How can you override a policy inherited from another entity in the resource hierarchy?","choices":["A. Inherited policies can be overridden by defining a policy at a folder or project level.","B. Inherited policies cannot be overridden.","C. Policies can be overridden by linking them to service accounts.","D. Policies can be overridden by linking them to billing accounts."],"answer":"4. B. Inherited policies can be overridden by defining a policy at a folder or project level.Service accounts and billing accounts are not part of the resource hierarchy and are notinvolved in overriding policies."},{"index":5,"questions":"5. Constraints are used in resource hierarchy policies. Which of the following are types of constraints allowed?","choices":["A. Allow a specific set of values","B. Deny a specific set of values","C. Deny a value and all its child values","D. Allow all allowed values","E. All of the above"],"answer":"5. E. All of the listed types of constraints are supported in policies."},{"index":6,"questions":"6. A team with four members needs you to set up a project that needs only general permissions for all resources. You are granting each person a primitive role for different levels of access, depending on their responsibilities in the project. Which of the following are not included as primitive roles in Google Cloud Platform?","choices":["A. Owner","B. Publisher","C. Editor","D. Viewer"],"answer":"6. B. Option B is the correct answer because Publisher is not a primitive role. Owner, Editor,and Viewer are the three primitive privileges in GCP."},{"index":7,"questions":"7. You are deploying a new custom application and want to delegate some administration tasks to DevOps engineers. They do not need all the privileges of a full application admin- istrator, but they do need a subset of those privileges. What kind of role should you use to grant those privileges?","choices":["A. Primitive","B. Predefined","C. Advanced","D. Custom"],"answer":"7. D. Primitive roles only include the Owner, Editor, and View permissions. Predefined rolesare designed for GCP products and services, like App Engine and BigQuery. For a customapplication, you can create sets of privileges that give the user with that role as much per-mission as needed but not more. Chapter 3: Projects, Service Accounts, and Billing 469"},{"index":8,"questions":"8. An app for a finance company needs access to a database and a Cloud Storage bucket. There is no predefined role that grants all the needed permissions without granting some permissions that are not needed. You decide to create a custom role. When defining custom roles, you should follow which of the following principles?","choices":["A. Rotation of duties","B. Least principle Review Questions 63","C. Defense in depth","D. Least privilege"],"answer":"8. D. Users should have only the privileges that are needed to carry out their duties. This isthe principle of least privilege. Rotation of duties is another security principle related tohaving different people perform a task at a different times. Defense in depth is the practiceof using multiple security controls to protect the same asset. Option B is not a real securityprincipal."},{"index":9,"questions":"9. How many organizations can you create in a resource hierarchy?","choices":["A. 1","B. 2","C. 3","D. Unlimited"],"answer":"9. A. A resource hierarchy has only one organization, which makes option A correct. Youcan, however, create multiple folders and projects within a resource hierarchy."},{"index":10,"questions":"10. You are contacted by the finance department of your company for advice on how to auto- mate payments for GCP services. What kind of account would you recommend setting up?","choices":["A. Service account","B. Billing account","C. Resource account","D. Credit account"],"answer":"10. B. In option B, the correct answer, the billing account is used to specify payment infor-mation and should be used to set up automatic payments. Service accounts are used togrant privileges to a VM and are not related to billing and payments. Resource accountsand credit accounts do not exist."},{"index":11,"questions":"11. You are experimenting with GCP for your company. You do not have permission to incur costs. How can you experiment with GCP without incurring charges?","choices":["A. You can’t; all services incur charges.","B. You can use a personal credit card to pay for charges.","C. You can use only free services in GCP.","D. You can use only serverless products, which are free to use."],"answer":"11. C. GCP offers a free service level for many products, which makes option C the correctanswer. You can use these services without having to set up a billing account. Googlecharges for serverless products, such as Cloud Functions and App Engine, when customersexceed the amount allowed under the free tier."},{"index":12,"questions":"12. Your DevOps team has decided to use Stackdriver monitoring and logging. You have been asked to set up Stackdriver workspaces. When you set up a Stackdriver workspace, what kind of resource is it associated with?","choices":["A. A Compute Engine instance only","B. A Compute Engine instance or Kubernetes Engine cluster only","C. A Compute Engine instance, Kubernetes Engine cluster, or App Engine app","D. A project"],"answer":"12. D. Stackdriver Workspaces are linked to projects, not individual resources like VMinstances, clusters, or App Engine apps, so option D is correct. Options A, B, and C allincorrectly indicate that Workspaces are associated with individual compute resources."},{"index":13,"questions":"13. A large enterprise is planning to use GCP across a number of subdivisions. Each subdivision is managed independently and has its own budget. Most subdivisions plan to spend tens of thousands of dollars per month. How would you recommend they set up their billing account(s)?","choices":["A. Use a single self-service billing account.","B. Use multiple self-service billing accounts.","C. Use a single invoiced billing account.","D. Use multiple invoiced billing accounts.64 Chapter 3 ■ Projects, Service Accounts, and Billing"],"answer":"13. D. Large enterprises should use invoicing when incurring large charges, which makesoption D the right answer. A self-service account is appropriate only for amounts that arewithin the credit limits of credit cards. Since the subdivisions are independently managedand have their own budgets, each should have its own billing accounts."},{"index":14,"questions":"14. An application administrator is responsible for managing all resources in a project. She wants to delegate responsibility for several service accounts to another administrator. If additional service accounts are created, the other administrator should manage those as well. What is the best way to delegate privileges needed to manage the service accounts?","choices":["A. Grant iam.serviceAccountUse trthe administrator at the project level.","B. Grant iam.serviceAccountUse trthe administrator at the service account level.","C. Grant iam.serviceProjectAccountUste orthe administrator at the project level.","D. Grant iam.serviceProjectAccountUste orthe administrator at the service account level."],"answer":"14. A. When a user is granted iam.serviceAccountUse at the project level, that user canmanage all service accounts in the project, so option A is correct. If a new service accountis created, they will automatically have privilege to manage that service account. Youcould grant iam.serviceAccountUse trthe administrator at the service account level,but that would require setting the role for all service accounts. If a new service account iscreated, the application administrator would have to grant iam.serviceAccountUse trthe other administrator on the new service account. iam.serviceProjectAccountUsie sra fictional role."},{"index":15,"questions":"15. You work for a retailer with a large number of brick and mortar stores. Every night the stores upload daily sales data. You have been tasked with creating a service that verifies the uploads every night. You decide to use a service account. Your manager questions the security of your proposed solution, particularly about authenticating the service account. You explain the authentication mechanism used by service accounts. What authentication mechanism is used?","choices":["A. Username and password","B. Two-factor authentication","C. Encrypted keys","D. Biometrics"],"answer":"15. C. When a service account is created, Google generates encrypted keys for authentication,making option C correct. Usernames and passwords are not an option for service accounts.Two-factor authentication is an authentication practice that requires two forms of authen-tication, such as a username password pair and a code from an authentication device. Bio-metrics cannot be used by services and is not an option."},{"index":16,"questions":"16. What objects in GCP are sometimes treated as resources and sometimes as identities?","choices":["A. Billing accounts","B. Service accounts","C. Projects","D. Roles"],"answer":"16. B. Service accounts are resources that are managed by administrators, but they also func-tion as identities that can be assigned roles, which makes option B the correct answer.Billing accounts are not related to identities. Projects are not identities; they cannot takeon roles. Roles are resources but not identities. They can take on privileges, but those privi-leges are used only when they are attached to an identity.470 Appendix ■ Answers to Review Questions"},{"index":17,"questions":"17. You plan to develop a web application using products from the GCP that already include established roles for managing permissions such as read-only access or the ability to delete old versions. Which of the following roles offers these capabilities?","choices":["A. Primitive roles","B. Predefined roles","C. Custom roles","D. Application roles"],"answer":"17. B. Predefined roles are defined for a particular product, such as App Services or ComputeEngine, so option B is the right answer. They bundle privileges often needed together whenmanaging or using a service. Primitive roles are building blocks for other roles. Customroles are created by users to meet their particular needs; Application roles is a fictitious role."},{"index":18,"questions":"18. You are reviewing a new GCP account created for use by the finance department. An auditor has questions about who can create projects by default. You explain who has privileges to create projects by default. Who is included?","choices":["A. Only project administrators","B. All users","C. Only users without the role resourcemanager.projects.create","D. Only billing account users Review Questions 65"],"answer":"18. B. By default all users in an organization can create projects, which makes option B cor-rect. The role resourcemanager.projects.crea isttehe role that allows users to createprojects. The billing account is not associated with creating projects."},{"index":19,"questions":"19. How many projects can be created in an account?","choices":["A. 10","B. 25","C. There is no limit.","D. Each account has a limit determined by Google."],"answer":"19. D. The maximum number of organizations is determined on a per-account basis byGoogle, so option D is the correct answer. If you need additional organizations, you cancontact Google and ask for an increase in your limit."},{"index":20,"questions":"20. You are planning how to grant privileges to users of your company’s GCP account. You need to document what each user will be able to do. Auditors are most concerned about a role called Organization IAM roles. You explain that users with that role can perform a number of tasks, which include all of the following except which one?","choices":["A. Defining the structure of the resource hierarchy","B. Determining what privileges a user should be assigned","C. Defining IAM policies over the resource hierarchy","D. Delegating other management roles to other users Review Questions 87 Review Questions You can find the answers in the Appendix."],"answer":"20. B. Users with the Organization IAM role are not necessarily responsible for determiningwhat privileges should be assigned to users. That is determined based on the person’s rolein the organization and the security policies established within the organization, whichmakes option B correct.Chapter 4: Introduction to Computing inGoogle Cloud"}],"4":[{"index":1,"questions":"1. You are deploying a Python web application to GCP. The application uses only custom code and basic Python libraries. You expect to have sporadic use of the application for the foreseeable future and want to minimize both the cost of running the application and the DevOps overhead of managing the application. Which computing service is the best option for running the application?","choices":["A. Compute Engine","B. App Engine standard environment","C. App Engine flexible environment","D. Kubernetes Engine"],"answer":"1. B. The App Engine standard environment can run Python applications, which can autoscaledown to no instances when there is no load and thereby minimize costs. Compute Engineand the App Engine flexible environment both require more configuration management thanthe App Engine standard environment. Kubernetes Engine is used when a cluster of servers isneeded to support large or multiple applications using the same computing resources."},{"index":2,"questions":"2. Your manager is concerned about the rate at which the department is spending on cloud services. You suggest that your team use preemptible VMs for all of the following except which one?","choices":["A. Database server","B. Batch processing with no fixed time requirement to complete","C. High-performance computing cluster","D. None of the above"],"answer":"2. A. Database servers require high availability to respond to queries from users or applica-tions. Preemptible machines are guaranteed to shut down in at most 24 hours. A batchprocessing job with no fixed time requirements could use preemptible machines as long asthe VM is restarted. High-performance computing clusters can use preemptible machinesbecause work on a preemptible machine can be automatically rescheduled for another nodeon the cluster when a server is preempted. D is incorrect because there is a correct answer inthe set of options."},{"index":3,"questions":"3. What parameters need to be specified when creating a VM in Compute Engine?","choices":["A. Project and zone","B. Username and admin role","C. Billing account","D. Cloud Storage bucket"],"answer":"3. A. VMs are created in projects, which are part of the resource hierarchy. They are alsolocated in geographic regions and data centers, so a zone is specified as well. Usernamesand admin roles are not specified during creation. The billing account is tied to a projectand so does not have to be specified when the VM is created. Cloud storage buckets arecreated independently of VMs. Not all VMs will make use of storage buckets."},{"index":4,"questions":"4. Your company has licensed a third-party software package that runs on Linux. You will run multiple instances of the software in a Docker container. Which of the following GCP services could you use to deploy this software package?","choices":["A. Compute Engine only","B. Kubernetes Engine only","C. Compute Engine, Kubernetes Engine, and the App Engine flexible environment only","D. Compute Engine, Kubernetes Engine, the App Engine flexible environment, or the App Engine standard environment"],"answer":"4. C. Compute Engine can run Docker containers if you install Docker on the VM.Kubernetes and the App Engine flexible environment support Docker containers. The AppEngine standard environment provides language-specific runtime environments and doesnot allow customers to specify custom Docker images for use. Chapter 4: Introduction to Computing in Google Cloud 471"},{"index":5,"questions":"5. You can specify packages to install into a Docker container by including commands in which file?","choices":["A. Docker.cfg","B. Dockerfile","C. Config.dck","D. install.cfg88 Chapter 4 ■ Introduction to Computing in Google Cloud"],"answer":"5. B. The name of the file that is used to build and configure a Docker container is Dockerfil.e"},{"index":6,"questions":"6. How much memory of a node does Kubernetes require as overhead?","choices":["A. 10GB to 20GB","B. 1GB to 2GB","C. 1.5GB","D. A scaled amount starting at 25 percent of memory and decreasing to 2 percent of marginal memory as the total amount of memory increases."],"answer":"6. D. Kubernetes uses 25 percent of memory up to 4GB and then slightly less for the next4GB, and it continues to reduce the percentage of additional memory down to 2 percent ofmemory over 128GB."},{"index":7,"questions":"7. Your manager is making a presentation to executives in your company advocating that you start using Kubernetes Engine. You suggest that the manager highlight all the features Kubernetes provides to reduce the workload on DevOps engineers. You describe several features, including all of the following except which one?","choices":["A. Load balancing across Compute Engine VMs that are deployed in a Kubernetes cluster","B. Security scanning for vulnerabilities","C. Automatic scaling of nodes in the cluster","D. Automatic upgrading of cluster software as needed"],"answer":"7. B. Kubernetes provides load balancing, scaling, and automatic upgrading of software.It does not provide vulnerability scanning. GCP does have a Cloud Security Scannerproduct, but that is designed to work with App Engine to identify common applicationvulnerabilities."},{"index":8,"questions":"8. Your company is about to release a new online service that builds on a new user interface experience driven by a set of services that will run on your servers. There is a separate set of services that manage authentication and authorization. A data store set of services keeps track of account information. All three sets of services must be highly reliable and scale to meet demand. Which of the GCP services is the best option for deploying this?","choices":["A. App Engine standard environment","B. Compute Engine","C. Cloud Functions","D. Kubernetes Engine"],"answer":"8. D. The scenario described is a good fit for Kubernetes. Each of the groups of services canbe structured in pods and deployed using Kubernetes deployment. Kubernetes Enginemanages node health, load balancing, and scaling. App Engine Standard Edition haslanguage-specific sandboxes and is not a good fit for this use case. Cloud Functions isdesigned for short-running event processing and is not the kind of continuous processingneeded in this scenario. Compute Engine could meet the requirements of this use case,but it would require more effort on the part of application administrators and DevOpsprofessionals to configure load balancers, monitor health, and manage softwaredeployments."},{"index":9,"questions":"9. A mobile application uploads images for analysis, including identifying objects in the image and extracting text that may be embedded in the image. A third party has created the mobile application, and you have developed the image analysis service. You both agree to use Cloud Storage to store images. You want to keep the two services completely decoupled, but you need a way to invoke the image analysis as soon as an image is uploaded. How should this be done?","choices":["A. Change the mobile app to start a VM running the image analysis service and have that VM copy the file from storage into local storage on the VM. Have the image service run on the VM.","B. Write a function in Python that is invoked by Cloud Functions when a new image file is written to the Cloud Storage bucket that receives new images. The function should submit the URL of the uploaded file to the image analysis service. The image analysis service will then load the image from Cloud Storage, perform analysis, and generate results, which can be saved to Cloud Storage.","C. Have a Kubernetes cluster running continuously, with one pod dedicated to listing the contents of the upload bucket and detecting new files in Cloud Storage and another pod dedicated to running the image analysis software. Review Questions 89","D. Have a Compute Engine VM running and continuously listing the contents of the upload bucket in Cloud Storage to detect new files. Another VM should be continually running the image analysis software."],"answer":"9. B. This is an ideal use case for Cloud Functions. The cloud function is triggered by a fileupload event. The cloud function calls the image processing service. With this setup, thetwo services are independent. No additional servers are required. Option A violates therequirement to keep the services independent. Options C and D incur more managementoverhead and will probably cost more to operate than option B."},{"index":10,"questions":"10. Your team is developing a new pipeline to analyze a stream of data from sensors on manufacturing devices. The old pipeline occasionally corrupted data because parallel threads overwrote data written by other threads. You decide to use Cloud Functions as part of the pipeline. As a developer of a Cloud Function, what do you have to do to prevent multiple invocations of the function from interfering with each other?","choices":["A. Include a check in the code to ensure another invocation is not running at the same time.","B. Schedule each invocation to run in a separate process.","C. Schedule each invocation to run in a separate thread.","D. Nothing. GCP ensures that function invocations do not interfere with each other."],"answer":"10. D. Each invocation of a cloud function runs in a secure, isolated runtime environment.There is no need to check whether other invocations are running. With the Cloud Functionsservice, there is no way for a developer to control code execution at the process or threadlevel."},{"index":11,"questions":"11. A client of yours processes personal and health information for hospitals. All health information needs to be protected according to government regulations. Your client wants to move their application to Google Cloud but wants to use the encryption library that they have used in the past. You suggest that all VMs running the application have the encryption library installed. Which kind of image would you use for that?","choices":["A. Custom image","B. Public image","C. CentOS 6 or 7"],"answer":"11. A. You would create a custom image after you installed the custom code, in this case theencryption library. A public image does not contain custom code, but it could be used asthe base that you add custom code to. Both CentOS and Ubuntu are Linux distributions.You could use either as the base image that you add custom code to, but on their own, theydo not have custom code."},{"index":12,"questions":"12. What is the lowest level of the resource hierarchy?","choices":["A. Folder","B. Project","C. File","D. VM instance"],"answer":"12. B. Projects are the lowest level of the resource hierarchy. The organization is at the top ofthe hierarchy, and folders are between the organization and projects. VM instances are notpart of the resource hierarchy."},{"index":13,"questions":"13. Your company is seeing a marked increase in the rate of customer growth in Europe. Latency is becoming an issue because your application is running in us-central1. You suggest deploying your services to a region in Europe. You have several choices. You should consider all of the following factors except which one?","choices":["A. Cost","B. Latency","C. Regulations","D. Reliability"],"answer":"13. D. All Google regions have the same level of service level agreement, so reliability is thesame. Costs may differ between regions. Regulations may require that data stay within ageographic area, such as the European Union. Latency is a consideration when you want aregion that is close to end users or data you will need is already stored in a particular region."},{"index":14,"questions":"14. What role gives users full control over Compute Engine instances?","choices":["A. Compute Manager role","B. Compute Admin role","C. Compute Manager role","D. Compute Security Admin90 Chapter 4 ■ Introduction to Computing in Google Cloud"],"answer":"14. B. Compute Engine Admin Role is the role that gives users complete control over instances.Options A and C are fictitious roles. Compute Engine Security Admin gives users the privi-leges to create, modify, and delete SSL certificates and firewall rules.472 Appendix ■ Answers to Review Questions"},{"index":15,"questions":"15. Which of the following are limitations of a preemptible VM?","choices":["A. Will be terminated within 24 hours.","B. May not always be available. Availability may vary across zones and regions.","C. Cannot migrate to a regular VM.","D. All of the above"],"answer":"15. D. Preemptible VMs will be terminated after 24 hours. Google does not guarantee thatpreemptible VMs will be available. Once an instance is started as a preemptible machine, itcannot migrate to a regular VM. You could, however, save a snapshot and use that to createa new regular instance."},{"index":16,"questions":"16. Custom VMs can have up to how many vCPUs?","choices":["A. 16","B. 32","C. 64","D. 128"],"answer":"16. C. Custom VMs can have up to 64 CPUs and up to 6.5GB of memory per vCPU."},{"index":17,"questions":"17. When using the App Engine standard environment, which of the following language’s runtime is not supported?","choices":["A. Java","B. Python","C. C","D. Go"],"answer":"17. C. The C programming language is not supported in the App Engine standard environ-ment. If you need to run a C application, it can be compiled and run in a container runningin the App Engine flexible environment."},{"index":18,"questions":"18. Kubernetes reserves CPU resources in percentage of cores available. The percentage is what range?","choices":["A. 1 percent to 10 percent","B. 0.25 percent to 6 percent","C. 0.25 percent to 2 percent","D. 10 percent to 12 percent"],"answer":"18. B. Kubernetes reserves CPU capacity according to the following schedule:1. 6 percent of the first core2. 1 percent of the next core (up to two cores)3. 0.5 percent of the next two cores (up to four cores)4. 0.25 percent of any cores above four cores"},{"index":19,"questions":"19. Kubernetes deployments can be in what states?","choices":["A. Progressing, stalled, completed","B. Progressing, completed, failed","C. Progressing, stalled, failed, completed","D. Progressing, stalled, running, failed, completed"],"answer":"19. B. The only states a Kubernetes deployment can be in are progressing, completed, andfailed."},{"index":20,"questions":"20. A client has brought you in to help reduce their DevOps overhead. Engineers are spending too much time patching servers and optimizing server utilization. They want to move to serverless platforms as much as possible. Your client has heard of Cloud Functions and wants to use them as much as possible. You recommend all of the following types of applications except which one?","choices":["A. Long-running data warehouse data load procedures","B. IoT backend processing","C. Mobile application event processing","D. Asynchronous workflows Review Questions 113 Review Questions You can find the answers in the Appendix."],"answer":"20. A. Cloud Functions is best suited for event-driven processing, such as a file beinguploaded to Cloud Storage or an event being writing to a Pub/Sub queue. Long-runningjobs, such as loading data into a data warehouse, are better suited to Compute Engine orApp Engine.Chapter 5: Computing with ComputeEngine Virtual Machines"}],"5":[{"index":1,"questions":"1. You have just opened the GCP console at console.google.co .You have authenticated with the user you want to use. What is one of the first things you should do before perform- ing tasks on VMs?","choices":["A. Open Cloud Shell.","B. Verify you can SSH into a VM.","C. Verify that the selected project is the one you want to work with.","D. Review the list of running VMs."],"answer":"1. C. You should verify the project selected because all operations you perform will applyto resources in the selected project, making option C the correct answer. You do not needto open Cloud Shell unless you want to work with the command line, and if you did, youshould verify that the project is correctly selected first. Logging into a VM using SSH is oneof the tasks that requires you to be working with the correct project, so logging in via SSHshould not happen before verifying the project. The list of VMs in the VM Instance win-dow is a list of VMs in the current project. You should verify which project you are using toensure you are viewing the set of VMs you think you are using."},{"index":2,"questions":"2. What is a one-time task you will need to complete before using the console?","choices":["A. Set up billing","B. Create a project","C. Create a storage bucket","D. Specify a default zone"],"answer":"2. A. You will need to set up billing if it is not already enabled when you start using the con-sole, so option A is the right answer. You may create a project, but you will be able to dothis only if billing is enabled. You do not need to create a storage bucket to work with theconsole. Specifying a default zone is not a one-time task; you may change zones throughoutthe life of your project. Chapter 5: Computing with Compute Engine Virtual Machines 473"},{"index":3,"questions":"3. A colleague has asked for your assistance setting up a test environment in Google Cloud. They have never worked in GCP. You suggest starting with a single VM. Which of the following is the minimal set of information you will need?","choices":["A. A name for the VM and a machine type","B. A name for the VM, a machine type, a region, and a zone","C. A name for the VM, a machine type, a region, a zone, and a CIDR block","D. A name for the VM, a machine type, a region, a zone, and an IP address"],"answer":"3. B. The name of the VM, the region and zone, and the machine type can all be specifiedin the console along with other parameters, so option B is correct. Option A is missingrequired parameters. A CIDR block is a range of IP addresses that is associated with asubnet and not needed to create a VM. An IP address is assigned automatically so it is notrequired."},{"index":4,"questions":"4. An architect has suggested a particular machine type for your workload. You are in the console creating a VM and you don’t see the machine type in the list of available machine types. What could be the reason for this?","choices":["A. You have selected the incorrect subnet.","B. That machine type is not available in the zone you specified.","C. You have chosen an incompatible operating system.","D. You have not specified a correct memory configuration."],"answer":"4. B. Different zones may have different machine types available, so you will need to specify aregion first and then a zone to determine the set of machine types available. If the machinetype does not appear in the list, it is not available in that zone. This makes option B thecorrect answer. Options A and C are incorrect. Subnets and IP addresses are not relatedto the machine types available. Unless you are specifying a custom machine type, youdo not specify the amount of memory; that is defined by the machine type, so option Dis incorrect."},{"index":5,"questions":"5. Your manager asks for your help with understanding cloud computing costs. Your team runs dozens of VMs for three different applications. Two of the applications are for use by the marketing department and one is use by the finance department. Your manager wants a way to bill each department for the cost of the VMs used for their applications. What would you suggest to help solve this problem?","choices":["A. Access controls","B. Persistent disks","C. Labels and descriptions","D. Descriptions only114 Chapter 5 ■ Computing with Compute Engine Virtual Machines"],"answer":"5. C. Labels and descriptions are for helping us track our own attributes of resources; GCPdoes not need them to perform its tasks. As the number of servers grows, it can becomedifficult to track which VMs are used for which applications and services, so option C isthe correct answer. Labels and a general description will help administrators track numbersof VMs and their related costs. Options A and B are used for security and storage but donot help with managing multiple VMs. Option D is only partially correct. Descriptions arehelpful but so are labels."},{"index":6,"questions":"6. If you wanted to set the preemptible property using Cloud Console, in which section of the Create An Instance page would you find the option?","choices":["A. Availability Policy","B. Identity And API Access","C. Sole Tenancy","D. Networking"],"answer":"6. A. The Availability Policy section within the Management tab is where you set preempti-bility, so option A is correct. Identity And API Access is used to control the VM’s access toGoogle Cloud APIs and which service account is used with the VM. Sole Tenancy is usedif you need to run your VMs on physical servers that only run your VMs. Networking isused to set network tags and change the network interface."},{"index":7,"questions":"7. You need to set up a server with a high level of security. You want to be prepared in case of attacks on your server by someone trying to inject a rootkit (a kind of malware that can alter the operating system). Which option should you select when creating a VM?","choices":["A. Firewall","B. Shield VM","C. Project-wide SSH keys","D. Boot disk integrity check"],"answer":"7. B. Shield VM is an advanced set of security controls that includes Integrity Monitoring, acheck to ensure boot images have not been tampered with, which makes option B the rightanswer. Firewalls are used to control ingress and egress of network traffic to a server orsubnet. Project-wide SSH keys are used for authenticating users across servers within a proj-ect. Boot disk integrity check is a fictional feature."},{"index":8,"questions":"8. All of the following parameters can be set when adding an additional disk through Google Cloud Console, except one. Which one?","choices":["A. Disk type","B. Encryption key management","C. Block size","D. Source image for the disk"],"answer":"8. C. Block size is not an option in the Additional Disks dialog, so option C is correct.Encryption key management, disk type, and the option of specifying a source image are allavailable options."},{"index":9,"questions":"9. You lead a team of cloud engineers who maintain cloud resources for several departments in your company. You’ve noticed a problem with configuration drift. Some machine config- urations are no longer in the same state as they were when created. You can’t find notes or documentation on how the changes were made or why. What practice would you implement to solve this problem?","choices":["A. Have all cloud engineers use only command-line interface in Cloud Shell.","B. Write scripts using gcloud commands to change configuration and store those scripts in a version control system.","C. Take notes when making changes to configuration and store them in Google Drive.","D. Limit privileges so only you can make changes so you will always know when and why configurations were changed."],"answer":"9. B. Using version-controlled scripts is the best approach of the four options. Scripts canbe documented with reasons for the changes and they can be run repeatedly on differentmachines to implement the same change. This reduces the chance of error when manuallyentering a command. Option A does not help to improve documenting why changes weremade. Option C could help improve documentation, but executable scripts are precise andaccurate reflections of what was executed. Notes may miss details. Option D is not advis-able. You could become a bottleneck to making changes, changes cannot be made whenyou are unavailable, and your memory may not be a reliable way to track all configurationchanges.474 Appendix ■ Answers to Review Questions"},{"index":10,"questions":"10. When using the Cloud SDK command-line interface, which of the following is part of commands for administering resources in Compute Engine?","choices":["A. gcloud compute instances","B. gcloud instances","C. gcloud instances compute","D. None of the above Review Questions 115"],"answer":"10. A. gcloud compute instance issthe start of commands for administering ComputeEngine resources, making option A the right answer. Option B, gcloud instance ,ismissing the compute keyword that indicates we are working with Compute Engine. OptionC has switched the order of computeand instances . Option D is false because option A isthe correct answer."},{"index":11,"questions":"11. A newly hired cloud engineer is trying to understand what VMs are running in a particular project. How could the engineer get summary information on each VM running in a project?","choices":["A. Execute the command gcloud compute list","B. Execute the command gcloud compute instances list","C. Execute the command gcloud instances list","D. Execute the command gcloud list instances"],"answer":"11. B. Option B follows the pattern of the glcoudcommand, which is hierarchical and startswith the glcoudname of the service, in this case computefor Compute Engine, followed bythe next level down, which in this case is instances. Finally, there is the action or verb, inthis case list. Option A is missing the term instancesto indicate you are working withVM instances. Option C is missing the computekeyword to indicate you are working withCompute Engine. Option D is missing the compute instanck eeyword and has switchedthe order of instancesand list."},{"index":12,"questions":"12. When creating a VM using the command line, how should you specify labels for the VM?","choices":["A. Use the --labelsoption with labels in the format of KEYS:VALUES.","B. Use the --labelsoption with labels in the format of KEYS=VALUE.","C. Use the --labelsoption with labels in the format of KEYS,VALUES.","D. This is not possible in the command line."],"answer":"12. B. The correct format is to use the --labelsparameter and specify the key followed byan equal sign followed by the value in option B. Options A and C have the wrong characterseparating the key and value. Option D is incorrect because it is possible to specify labels inthe command line."},{"index":13,"questions":"13. In the boot disk advanced configuration, which operations can you specify when creating a new VM?","choices":["A. Add a new disk, reformat an existing disk, attach an existing disk","B. Add a new disk and reformat an existing disk","C. Add a new disk and attach an existing disk","D. Reformat an existing disk and attach an existing disk"],"answer":"13. C. The two operations you can specify when using the book disk configuration are addinga new disk and attaching an existing disk, so option C is correct. Reformatting an existingdisk is not an option, so options A, B, and D cannot be the correct answer."},{"index":14,"questions":"14. You have acquired a 10 GB data set from a third-party research firm. A group of data scientists would like to access this data from their statistics programs written in R. R works well with Linux and Windows file systems, and the data scientists are familiar with file operations in R. The data scientists would each like to have their own dedicated VM with the data available in the VM’s file system. What is a way to make this data readily available on a VM and minimize the steps the data scientists will have to take?","choices":["A. Store the data in Cloud Storage.","B. Create VMs using a source image created from a disk with the data on it.","C. Store the data in Google Drive.","D. Load the data into BigQuery."],"answer":"14. B. 10 GB of data is small enough to store on a single disk. By creating an image of a diskwith the data stored on it, you can specify that source image when creating a VM. OptionA would require the data scientist to copy the data from Cloud Storage to a disk on theVM. Option C would similarly require copying the data. Option D would load data into adatabase, not a file system as specified in the requirements."},{"index":15,"questions":"15. The Network tab of the create VM form is where you would perform which of the follow- ing operations?","choices":["A. Set the IP address of the VM","B. Add a network interface to the VM","C. Specify a default router","D. Change firewall configuration rules116 Chapter 5 ■ Computing with Compute Engine Virtual Machines"],"answer":"15. B. In the Network tab of the VM form, you can add another network interface, sooption B is correct. GCP sets the IP address, so option A is incorrect. There is no optionto specify a router or change firewall rules on the Network tab, so options C and D areincorrect."},{"index":16,"questions":"16. You want to create a VM using thecloudcommand. What parameter would you include to specify the type of boot disk?","choices":["A. boot-disk-type","B. boot-disk","C. disk-type","D. type-boot-disk"],"answer":"16. A. The correct option is boot-disk-typ,ewhich is option A. The other three options arenot parameters to the gcloud compute instance csmmand."},{"index":17,"questions":"17. Which of the following commands will create a VM with four CPUs that is named web- server-1?","choices":["A. gcloud compute instances create --machine-type=n1-standard-4 web-server-1","B. gcloud compute instances create --cpus=4 web-server-1","C. gcloud compute instances create --machine-type=n1-standard-4 –instance- name web-server-1","D. gcloud compute instances create --machine-type=n1-4-cpu web-server-1"],"answer":"17. A. Option A is the correct command. It is the only option that includes a correct machinetype and properly specifies the name of the instance. Option B uses the --cpusparameter,which does not exist. Option C uses the parameter instance-nam,ewhich does not exist.The instance name is passed as an argument and does not need a parameter name. OptionD is incorrect because machine type n1-4-cp isunot a valid machine type."},{"index":18,"questions":"18. Which of the following commands will stop a VM named web-server-1?","choices":["A. gcloud compute instances halt web-server-1","B. gcloud compute instances --terminate web-server1","C. gcloud compute instances stop web-server-1","D. gcloud compute stop web-server-1"],"answer":"18. C. Option C is the correct command, which is gcloud compute instanc,ets o indicateyou are working with VMs, followed by the stopcommand and the name of the VM.Option A is incorrect because haltis not an option. Option B is incorrect because–terminateis not a parameter. Option D is missing the word instances , whichindicates you are working with VMs. Chapter 6: Managing Virtual Machines 475"},{"index":19,"questions":"19. You have just created an Ubuntu VM and want to log into the VM to install some software packages. Which network service would you use to access the VM?","choices":["A. FTP","B. SSH","C. RDP","D. ipconfig"],"answer":"19. B. SSH is service for connecting to a remote server and logging into a terminal window.Once logged in, you would have access to a command line, so option B is the right answer.FTP is a file transfer protocol and does not allow you to log in and perform system admin-istration tasks. RDP is a protocol used to remotely access Windows servers, not Ubuntu,which is a Linux distribution. ipconfigis a command-line utility for configuring IP stackson a device and does not allow you to log into a remote server."},{"index":20,"questions":"20. Your management team is considering three different cloud providers. You have been asked to summarize billing and cost information to help the management team compare cost structures between clouds. Which of the following would you mention about the cost of VMs in GCP?","choices":["A. VMs are billed in 1-second increments, cost varies with the number of CPUs and amount of memory in a machine type, you can create custom machine types, preemptible VMs cost up to 80 percent less than standard VMs, and Google offers discounts for sustained usage.","B. VMs are billed in 1-second increments and VMs can run up to 24 hours before they will be be shut down.","C. Google offers discounts for sustained usage in only some regions, cost varies with the number of CPUs and amount of memory in a machine type, you can create custom machine types, preemptible VMs cost up to 80 percent less than standard VMs.","D. VMs are charged for a minimum of 1 hour of use and cost varies with the number of CPUs and amount of memory in a machine type. Exam Essentials 139 Know how to create a VM in the console and at the command line. You can specify machine type, choose an image, and configure disks with the console. You can use com- mands at the command line to list and describe, and you can find the same information in the console. Understand when to use customized images and how to deprecate them. Images are copies of contents of a disk, and they are used to create VMs. Deprecated marks an image as no longer supported. Understand why GPUs are used and how to attach them to a VM. GPUs are used for compute-intensive operations; a common use case for using GPUs is machine learning. It is best to use an image that has GPU libraries installed. Understand how to determine which locations have GPUs available, because there are some restrictions. The CPU must be com- patible with the GPU selected, and GPUs cannot be attached to shared memory machines. Know how GPU costs are charged. Understand images and snapshots. Snapshots save the contents of disks for backup and data-sharing purposes. Images save the operating system and related configurations so you can create identical copies of the instance. Understand instance groups and instance group templates. Instance groups are sets of instances managed as a single entity. Instance group templates specify the configuration of an instance group and the instances in it. Managed instance groups support autoscaling and load balancing. ■ 140 Chapter 6 Managing Virtual Machines Review Questions You can find the answers in the Appendix."],"answer":"20. A. All of the statements in option A are true and relevant to billing and costs. Option Bis correct that VMs are billed in 1-second increments, but the only preemptible VMs areshut down within 24 hours of starting. Option C is incorrect because discounts are notlimited to some regions. Option D is incorrect because VMs are not charged for a minimumof 1 hour.Chapter 6: Managing Virtual Machines"}],"6":[{"index":1,"questions":"1. Which page in Google Cloud Console would you use to create a single instance of a VM?","choices":["A. Compute Engine","B. App Engine","C. Kubernetes Engine","D. Cloud Functions"],"answer":"1. A. The Compute Engine page is where you have the option of creating a single VMinstance, so option A is the correct answer. App Engine is used for containers and runningapplications in language-specific runtime environments. Kubernetes Engine is used to createand manage Kubernetes clusters. Cloud Functions is where you would create a function torun in Google’s serverless cloud function environment."},{"index":2,"questions":"2. You view a list of Linux VM instances in the console. All have public IP addresses assigned. You notice that the SSH option is disabled for one of the instances. Why might that be the case?","choices":["A. The instance is preemptible and therefore does not support SSH.","B. The instance is stopped.","C. The instance was configured with the No SSH option.","D. The SSH option is never disabled."],"answer":"2. B. Instances can be stopped, and when they are, then you cannot connect to them via SSH,which makes option B the correct answer. Starting the instance will enable SSH access.Option A is not correct because you can log into preemptible machines. Option C is incor-rect because there is no No SSH option. Option D is incorrect because the SSH option canbe disabled."},{"index":3,"questions":"3. You have noticed unusually slow response time when issuing commands to a Linux server, and you decide to reboot the machine. Which command would you use in the console to reboot?","choices":["A. Reboot","B. Reset","C. Restart","D. Shutdown followed by Startup"],"answer":"3. B. The Reset command can be used to restart a VM; thus, option B is correct. The prop-erties of the VM will not change, but data in memory will be lost. There is no Reboot,Restart, Shutdown, or Startup option in the console."},{"index":4,"questions":"4. In the console, you can filter the list of VM instances by which of the following?","choices":["A. Labels only","B. Member of managed instance group only","C. Labels, status, or members of managed instance group","D. Labels and status only"],"answer":"4. C. Labels, members of a managed instance group, and status are all available for filtering,so option C is the correct answer. You can also filter by internal IP, external IP, zone, net-work, deletion protection, and member of a managed or unmanaged instance group."},{"index":5,"questions":"5. You will be building a number of machine learning models on an instance and attaching GPU to the instance. When you run your machine learning models they take an unusually long time to run. It appears that GPU is not being used. What could be the cause of this?","choices":["A. GPU libraries are not installed.","B. The operating system is based on Ubuntu.","C. You do not have at least eight CPUs in the instance.","D. There isn’t enough persistent disk space available. Review Questions 141"],"answer":"5. A. To function properly, the operating system must have GPU libraries installed, so optionA is correct. The operating system does not have to be Ubuntu based, and there is no needto have at least eight CPUs in an instance before you can attach and use a GPU. Availabledisk space does not determine if a GPU is used or not."},{"index":6,"questions":"6. When you add a GPU to an instance, you must ensure that:","choices":["A. The instance is set to terminate during maintenance.","B. The instance is preemptible.","C. The instance does not have nonboot disks attached.","D. The instance is running Ubuntu 14.02 or later."],"answer":"6. A. If you add a GPU to a VM, you must set the instance to terminate during maintenance,which makes option A the correct response. This is set in the Availability Policies section ofthe VM configuration form. The instance does not need to be preemptible and it can havenon-boot disks attached. The instance is not required to run Ubuntu 14.02 or later.476 Appendix ■ Answers to Review Questions"},{"index":7,"questions":"7. You are using snapshots to save copies of a 100GB disk. You make a snapshot and then add 10GB of data. You create a second snapshot. How much storage is used in total for the two snapshots (assume no compression)?","choices":["A. 210 GB, with 100GB for the first and 110GB for the second","B. 110 GB, with 100GB for the first and 10GB for the second","C. 110 GB, with 110 for the second (the first snapshot is deleted automatically)","D. 221 GB, with 100GB for the first, 110GB for the second, plus 10 percent of the second snapshot (11 GB) for metadata overhead"],"answer":"7. B. When you first create a snapshot, GCP will make a full copy of the data on the persis-tent disk. The next time you create a snapshot from that disk, GCP will only copy the datathat has changed since the last snapshot. Option A is incorrect; GCP does not store a fullcopy of the second snapshot. Option C is incorrect; the first snapshot is not deleted auto-matically. Option D is incorrect, subsequent snapshots do not incur 10 percent overhead."},{"index":8,"questions":"8. You have decided to delegate the task of making backup snapshots to a member of your team. What role would you need to grant to your team member to create snapshots?","choices":["A. Compute Image Admin","B. Storage Admin","C. Compute Snapshot Admin","D. Compute Storage Admin"],"answer":"8. D. To work with snapshots, a user must be assigned the Compute Storage Admin role,which makes option D the correct answer. The other options are fictitious roles."},{"index":9,"questions":"9. The source of an image may be:","choices":["A. Only disks","B. Snapshots or disks only","C. Disks, snapshots, or another image","D. Disks, snapshots, or any database export file"],"answer":"9. C. Images can be created from four sources, namely, disks, snapshots, cloud storage files,or another image, so option C is the right answer. Database export files are not sources forimages."},{"index":10,"questions":"10. You have built images using Ubuntu 14.04 and now want users to start using Ubuntu 16.04. You don’t want to just delete images based on Ubuntu 14.04, but you want users to know they should start using Ubuntu 16.04. What feature of images would you use to accomplish this?","choices":["A. Redirection","B. Deprecated","C. Unsupported","D. Migration"],"answer":"10. B. Deprecated marks the image as no longer supported and allows you to specify a replace-ment image to use going forward, making option B the correct answer. Deprecated imagesare available for use but may not be patched for security flaws or have other updates. Theother options are fictitious features of images."},{"index":11,"questions":"11. You want to generate a list of VMs in your inventory and have the results in JSON format. What command would you use?","choices":["A. gcloud compute instances list","B. gcloud compute instances describe","C. gcloud compute instances list --format json","D. gcloud compute instances list --output json142 Chapter 6 ■ Managing Virtual Machines"],"answer":"11. C. The base command for working with instances is gcloud compute instanc,eswhich makes option C the correct answer. The listcommand is used to show detailsof all instances. By default, outputis in human-readable form, not json. Using the--format json option forces the output to be in JSON format. --outputis not avalid option."},{"index":12,"questions":"12. You would like to understand details of how GCP starts a virtual instance. Which optional parameter would you use when starting an instance to display those details?","choices":["A. --verbose","B. --async","C. --describe","D. --details"],"answer":"12. B. –-asynccauses information about the start process to be displayed; therefore, option Bis correct. --verboseis an analogous parameter in many Linux commands. --describeprovides details about an instance but not necessarily the startup process. --detailsis nota valid parameter."},{"index":13,"questions":"13. Which command will delete an instance named ch06-instance-3?","choices":["A. gcloud compute instances delete instance=ch06-instance-3","B. gcloud compute instance stop ch06-instance-3","C. gcloud compute instances delete ch06-instance-3","D. gcloud compute delete ch06-instance-3"],"answer":"13. C. The command to delete an instance is gcloud compute instances dele ftllowedby the name of the instance, so option C is correct. Option A is incorrect because there isno instanceparameter. Option B is incorrect because that command stops but does notdelete the instance. Option D is missing instancesin the command, which is required toindicate what type of entity is being deleted."},{"index":14,"questions":"14. You are about to delete an instance named ch06-instance-1 but want to keep its boot disk. You do not want to keep other attached disks. What gcloudcommand would you use?","choices":["A. gcloud compute instances delete ch06-instance-1 ––keep-disks=boot","B. gcloud compute instances delete ch06-instance-1 ––save-disks=boot","C. gcloud compute instances delete ch06-instance-1 ––keep-disks=filesystem","D. gcloud compute delete ch06-instance-1 ––keep-disks=filesystem"],"answer":"14. A. gcloud compute instance issthe base command followed by delete , the name ofthe instance, and --keep-disks=boo ,tso option A is correct. There is no --save-diskparameter. Option C is wrong because filesystemis not a valid value for the keep-diskparameter. Option D is missing the instancesoption which is required in the command."},{"index":15,"questions":"15. You want to view a list of fields you can use to sort a list of instances. What command would you use to see the field names?","choices":["A. gcloud compute instances list","B. gcloud compute instances describe","C. gcloud compute instances list --detailed","D. gcloud compute instances describe --detailed"],"answer":"15. B. The correct answer is option B, which is to use the describecommand. Option A willshow some fields but not all. Options C and D are incorrect because there is no detailedparameter."},{"index":16,"questions":"16. You are deploying an application that will need to scale and be highly available. Which of these Compute Engine components will help achieve scalability and high availability?","choices":["A. Preemptible instances","B. Instance groups","C. Cloud Storage","D. GPUs"],"answer":"16. B. Instance groups are sets of VMs that can be configured to scale and are used with loadbalancers, which contribute to improving availability, so option B is correct. Preemptibleinstances are not highly available because they can be shut down at any time by GCP.Cloud Storage is not a Compute Engine component. GPUs can help improve throughput formath-intensive operations but do not contribute to high availability. Chapter 7: Computing with Kubernetes 477"},{"index":17,"questions":"17. Before creating an instance group, you need to create what?","choices":["A. Instances in the instance group","B. Instance group template","C. Boot disk image","D. Source snapshot Review Questions 143"],"answer":"17. B. An instance group template is used to specify how the instance group should be created,which makes option B the correct answer. Option A is incorrect because instances are cre-ated automatically when an instance group is created. Boot disk images and snapshots donot have to be created before creating an instance group."},{"index":18,"questions":"18. How would you delete an instance group template using the command line?","choices":["A. gcloud compute instances instance-template delete","B. glcoud compute instance-templates delete","C. gcloud compute delete instance-template","D. gcloud compute delete instance-templates"],"answer":"18. B. The command to delete an instance group is gcloud compute instance-templatedelete , so option B is correct. Option A incorrectly includes the term instance. OptionC is in incorrect order. Option D is wrong because instance-templatie s in the wrongposition and is plural in the option."},{"index":19,"questions":"19. What can be the basis for scaling up an instance group?","choices":["A. CPU utilization and operating system updates","B. Disk usage and CPU utilization only","C. Network latency, load balancing capacity, and CPU utilization","D. Disk usage and operating system updates only"],"answer":"19. C. You can configure an autoscaling policy to trigger adding or removing instances basedon CPU utilization, monitoring metric, load balancing capacity, or queue-based workloads.Disk, network latency, and memory can trigger scaling if monitoring metrics on thoseresources are configured. So, option C is correct."},{"index":20,"questions":"20. An architect is moving a legacy application to Google Cloud and wants to minimize the changes to the existing architecture while administering the cluster as a single entity. The legacy application runs on a load-balanced cluster that runs nodes with two different configurations. The two configurations are required because of design decisions made several years ago. The load on the application is fairly consistent, so there is rarely a need to scale up or down. What GCP Compute Engine resource would you recommended using?","choices":["A. Preemptible instances","B. Unmanaged instance groups","C. Managed instance groups","D. GPUs ■ 170 Chapter 7 Computing with Kubernetes Review Questions You can find the answers in the Appendix."],"answer":"20. B. Unmanaged instance groups are available for limited use cases such as this. Unmanagedinstance groups are not recommended in general. Managed instance groups are the recom-mended way to use instance groups, but the two different configurations prevents their use.Preemptible instances and GPUs are not relevant to this scenario.Chapter 7: Computing with Kubernetes"}],"7":[{"index":1,"questions":"1. A new engineer is asking for clarification about when it is best to use Kubernetes and when to use instance groups. You point out that Kubernetes uses instance groups. What purpose do instance groups play in a Kubernetes cluster?","choices":["A. They monitor the health of instances.","B. They create pods and deployments.","C. They create sets of VMs that can be managed as a unit.","D. They create alerts and notification channels."],"answer":"1. C. Kubernetes creates instance groups as part of the process of creating a cluster, whichmakes option C the correct answer. Stackdriver, not instance groups, is used to monitor thehealth of nodes and to create alerts and notifications. Kubernetes creates pods and deploy-ments; they are not provided by instance groups."},{"index":2,"questions":"2. What kinds of instances are required to have a Kubernetes cluster?","choices":["A. A cluster master and nodes to execute workloads.","B. A cluster master, nodes to execute workloads, and Stackdriver nodes to monitor node health.","C. Kubernetes nodes; all instances are the same.","D. Instances with at least four vCPUs."],"answer":"2. A. A Kubernetes cluster has a single cluster master and one or more nodes to execute work-loads, so option A is the correct answer. Stackdriver is not part of the Kubernetes cluster;it is a separate GCP service. Kubernetes does not require instances with at least four vCPUs;in fact, the default node configuration uses one vCPU."},{"index":3,"questions":"3. What is a pod in Kubernetes?","choices":["A. A set of containers","B. Application code deployed in a Kubernetes cluster","C. A single instance of a running process in a cluster","D. A controller that manages communication between clients and Kubernetes services"],"answer":"3. C. Pods are single instances of a running process in a cluster, so option C is correct. Podsrun containers but are not sets of containers. Application code runs in containers that aredeployed in pods. Pods are not controllers, so they cannot manage communication withclients and Kubernetes services."},{"index":4,"questions":"4. You have developed an application that calls a service running in a Kubernetes cluster. The service runs in pods that can be terminated if they are unhealthy and replaced with other pods that might have a different IP address. How should you code your application to ensure it functions properly in this situation?","choices":["A. Query Kubernetes for a list of IP addresses of pods running the service you use.","B. Communicate with Kubernetes services so applications do not have to be coupled to specific pods.","C. Query Kubernetes for a list of pods running the service you use.","D. Use a gcloudcommand to get the IP addresses needed."],"answer":"4. B. Services are applications that provide API endpoints that allow applications to discoverpods running a particular application, making option B correct. Options A and C, if theycould be coded using the API designed for managing clusters, would require more codethan working with services and are subject to changes in a larger set of API functions.Option D is not an actual option.478 Appendix ■ Answers to Review Questions"},{"index":5,"questions":"5. You have noticed that an application’s performance has degraded significantly. You have recently made some configuration changes to resources in your Kubernetes cluster and suspect that those changes have alerted the number of pods running in the cluster. Where would you look for details on the number of pods that should be running?","choices":["A. Deployments","B. Stackdriver","C. ReplicaSet","D. Jobs Review Questions 171"],"answer":"5. C. ReplicaSets are controllers that are responsible for maintaining the correct number ofpods, which makes option C the correct answer. Deployments are versions of applicationcode running on a cluster. Stackdriver is a monitoring and logging service that monitors butdoes not control Kubernetes clusters. Jobs is an abstraction of workloads and is not tied tothe number of pods running in a cluster."},{"index":6,"questions":"6. You are deploying a high availability application in Kubernetes Engine. You want to main- tain availability even if there is a major network outage in a data center. What feature of Kubernetes Engine would you employ?","choices":["A. Multiple instance groups","B. Multizone/region cluster","C. Regional deployments","D. Load balancing"],"answer":"6. B. Multizone/multiregion clusters are available in Kubernetes Engine and are used to pro-vide resiliency to an application, so option B is correct. Option A refers to instance groupsthat are a feature of Compute Engine, not directly of Kubernetes Engine. Option C is incor-rect; regional deployments is a fictitious term. Load balancing distributes load and is part ofKubernetes by default. If load is not distributed across zones or regions, it does not help toadd resiliency across data centers."},{"index":7,"questions":"7. You want to write a script to deploy a Kubernetes cluster with GPUs. You have deployed clusters before, but you are not sure about all the required parameters. You need to deploy this script as quickly as possible. What is one way to develop this script quickly?","choices":["A. Use the GPU template in the Kubernetes Engine cloud console to generate the gcloud command to create the cluster","B. Search the Web for a script","C. Review the documentation on gcloud parameters for adding GPUs","D. Use an existing script and add parameters for attaching GPUs"],"answer":"7. A. Option A is the best answer. Starting with an existing template, filling in parameters,and generating the gcloudcommand is the most reliable way. Option D may work, butmultiple parameters that are needed for your configuration may not be in the script youstart with. There may be some trial and error with this option. Options B and C may leadto a solution but could take some time to complete."},{"index":8,"questions":"8. What gcloudcommand will create a cluster named ch07-cluster-1 with four nodes?","choices":["A. gcloud beta container clusters create ch07-cluster-1 --num-nodes=4","B. gcloud container beta clusters create ch07-cluster-1 --num-nodes=4","C. gcloud container clusters create ch07-cluster-1 --num-nodes=4","D. gcloud beta container clusters create ch07-cluster-1 4"],"answer":"8. A. The correct command is option A. Option B has betain the wrong position. Option Cis missing beta. Option D is missing the --num-nodes parameter name."},{"index":9,"questions":"9. When using Create Deployment from Cloud Console, which of the following cannot be specified for a deployment?","choices":["A. Container image","B. Application name","C. Time to live (TTL)","D. Initial command"],"answer":"9. C. Time to Live is not an attribute of deployments, so option C is the correct answer.Application name, container image, and initial command can all be specified."},{"index":10,"questions":"10. Deployment configuration files created in Cloud Console use what type of file format?","choices":["A. CSV","B. YAML","C. TSV","D. JSON"],"answer":"10. B. Deployment configuration files created in Cloud Console are saved in YAML format.CSV, TSV, and JSON are not used."},{"index":11,"questions":"11. What command is used to run a Docker image on a cluster?","choices":["A. gcloud container run","B. gcloud beta container run","C. kubectl run","D. kubectl beta run172 Chapter 7 ■ Computing with Kubernetes"],"answer":"11. C. The kubectlcommand is used to control workloads on a Kubernetes cluster once it iscreated, so option C is correct. Options A and B are incorrect because gcloudis not usedto manipulate Kubernetes processes. Option D is wrong because betais not required inkubectlcommands."},{"index":12,"questions":"12. What command would you use to have 10 replicas of a deployment named ch07-app-deplo?y","choices":["A. kubectl upgrade deployment ch07-app-deploy --replicas=5","B. gcloud containers deployment ch07-app-deploy --replicas=5","C. kubectl scale deployment ch07-app-deploy --replicas=10","D. kubectl scale deployment ch07-app-deploy --pods=5"],"answer":"12. C. Option C is the correct command. Option A uses the term upgradeinstead of scale.Option B incorrectly uses gcloud . Option D uses the incorrect parameter pods."},{"index":13,"questions":"13. Stackdriver is used for what operations on Kubernetes clusters?","choices":["A. Notifications only","B. Monitoring and notifications only","C. Logging only","D. Notifications, monitoring, and logging"],"answer":"13. D. Stackdriver is a comprehensive monitoring, logging, alerting, and notification servicethat can be used to monitor Kubernetes clusters."},{"index":14,"questions":"14. Before monitoring a Kubernetes cluster, what must you create with Stackdriver?","choices":["A. Log","B. Workspace","C. Pod","D. ReplicaSet"],"answer":"14. B. Workspaces are logical structures for storing information about resources in a projectthat are being monitored, so option B is correct. Stackdriver works with logs, but a log isnot required before starting to use Stackdriver. Pods and ReplicaSets are part of Kuber-netes, not Stackdriver."},{"index":15,"questions":"15. What kind of information is provided in the Details page about an instance in Stackdriver?","choices":["A. CPU usage only","B. Network traffic only","C. Disk I/O, CPU usage, and network traffic","D. CPU usage and disk I/O"],"answer":"15. C. The Stackdriver Instance Detail page includes time-series charts on CPU usage, networktraffic, and disk I/O."},{"index":16,"questions":"16. When creating an alerting policy, what can be specified?","choices":["A. Conditions, notifications, and time to live","B. Conditions, notifications, and documentation","C. Conditions only","D. Conditions, documentation, and time to live"],"answer":"16. B. When creating an alert policy, you can specify conditions, notifications, and documenta-tion, making option B the correct answer. Options A and D are incorrect because there isno Time to Live attribute on policies. Option C is wrong because it does not include notifi-cations and documentation. Chapter 8: Managing Kubernetes Clusters 479"},{"index":17,"questions":"17. Your development team needs to be notified if there is a problem with applications running on several Kubernetes clusters. Different team members prefer different notification methods in addition to Stackdriver alerting. What is the most efficient way to send notifications and meet your team’s requests?","choices":["A. Set up SMS text messaging, Slack, and email notifications on an alert.","B. Create a separate alert for each notification channel.","C. Create alerts with email notifications and have those notification emails forwarded to other notification systems.","D. Use a single third-party notification mechanism. Review Questions 173"],"answer":"17. A. Alerts can have multiple channels, so Option A is correct. Channels include email,webhooks, and SMS text messaging as well as third-party tools such as PagerDuty,Campfire, and Slack. There is no need for multiple alerts with individual notifications.Option C is ad hoc and would require additional maintenance overhead. Option D does notmeet requirements."},{"index":18,"questions":"18. A new engineer is trying to set up alerts for a Kubernetes cluster. The engineer seems to be creating a large number of alerts and you are concerned this is not the most efficient way and will lead to more maintenance work than required. You explain that a more efficient way is to create alerts and apply them to what?","choices":["A. One instance only","B. An instance or entire group","C. A group only","D. A pod"],"answer":"18. B. Alerts are assigned to instances or sets of instances; therefore, option B is correct.Option A is incorrect because it does not include groups. Option C is incorrect because itdoes not include instances. Option D is wrong because alerts are not assigned to pods."},{"index":19,"questions":"19. You are attempting to execute commands to initiate a deployment on a Kubernetes cluster. The commands are not having any effect. You suspect that a Kubernetes component is not functioning correctly. What component could be the problem?","choices":["A. The Kubernetes API","B. A StatefulSet","C. Cloud SDK gcloudcommands","D. ReplicaSet"],"answer":"19. A. All interactions with the cluster are done through the master using the Kubernetes API.If an action is to be taken on a node, the command is issued by the cluster master, so optionA is the correct answer. Options B and D are incorrect because they are controllers withinthe cluster and do not impact how commands are received from client devices. Option C isincorrect because kubectl , not gcloud, is used to initiate deployments."},{"index":20,"questions":"20. You have deployed an application to a Kubernetes cluster. You have noticed that several pods are starved for resources for a period of time and the pods are shut down. When resources are available, new instantiations of those pods are created. Clients are still able to connect to pods even though the new pods have different IP addresses from the pods that were terminated. What Kubernetes component makes this possible?","choices":["A. Services","B. ReplicaSet","C. Alerts","D. StatefulSet ■ 204 Chapter 8 Managing Kubernetes Clusters Review Questions You can find the answers in the Appendix."],"answer":"20. A. Services provide a level of indirection to accessing pods. Pods are ephemeral. Clientsconnect to services, which can discover pods. ReplicaSets and StatefulSets provide managedpods. Alerts are for reporting on the state of resources.Chapter 8: Managing KubernetesClusters"}],"8":[{"index":1,"questions":"1. You are running several microservices in a Kubernetes cluster. You’ve noticed some performance degradation. After reviewing some logs, you begin to think the cluster may be improperly configured, and you open Cloud Console to investigate. How do you see the details of a specific cluster?","choices":["A. Type the cluster name into the search bar.","B. Click the cluster name.","C. Use the gcloudcluster detailc sommand.","D. None of the above."],"answer":"1. B. When on the Cloud Console pages, you can click the cluster name to see a Details page,so option B is the correct answer. Typing the name of cluster in the search bar does notalways return cluster details; it can return instance group details. There is no such com-mand as gcloud cluster detai.ls"},{"index":2,"questions":"2. You are viewing the details of a cluster in Cloud Console and want to see how many vCPUs are available in the cluster. Where would you look for that information?","choices":["A. Node Pools section of the Cluster Details page","B. Labels section of the Cluster Details page","C. Summary line of the Cluster Listing page","D. A and C"],"answer":"2. D. You can find the number of vCPUs on the cluster listing in the Total Cores column or onthe Details page in the Node Pool section in the size parameter, making option D correct.The Labels section does not have vCPU information."},{"index":3,"questions":"3. You have been assigned to help diagnose performance problems with applications running on several Kubernetes clusters. The first thing you want to do is understand, at a high level, the characteristics of the clusters. Which command should you use?","choices":["A. gcloud container list","B. gcloud container clusters list","C. gcloud clusters list","D. None of the above"],"answer":"3. B. The correct command includes gcloud containetr o describe the service, clusterstoindicate the resource you are referring to, and listto indicate the command, which makesoption B the correct answer. Options A and C are not valid commands."},{"index":4,"questions":"4. When you first try to use the kubectlcommand, you get an error message indicating that the resource cannot be found or you cannot connect to the cluster. What command would you use to try to eliminate the error?","choices":["A. gcloud container clusters access","B. gdcloud container clusters get-credentials","C. gcloud auth container","D. gcloud auth container clusters"],"answer":"4. B. It is likely you do not have access privileges to the cluster. The gdcloud containerclusters get-credentials command is the correct command to configure kubectltouse GCP credentials for the cluster, so option B is the right option. Options A, C, and D areinvalid commands."},{"index":5,"questions":"5. An engineer recently joined your team and is not aware of your team’s standards for creating clusters and other Kubernetes objects. In particular, the engineer has not properly labeled several clusters. You want to modify the labels on the cluster from Cloud Console. How would you do it?","choices":["A. Click the Connect button.","B. Click the Deploy menu option.","C. Click the Edit menu option.","D. Type the new labels in the Labels section. Review Questions 205"],"answer":"5. C. Clicking the Edit button allows you to change, add, or remove labels, so option C is thecorrect answer. The Connect button is on the cluster listing page, and the Deploy buttonis for creating new deployments. There is no way to enter labels under the Labels sectionwhen displaying details.480 Appendix ■ Answers to Review Questions"},{"index":6,"questions":"6. You receive a page in the middle of the night informing you that several services running on a Kubernetes cluster have high latency when responding to API requests. You review moni- toring data and determine that there are not enough resources in the cluster to keep up with the load. You decide to add six more VMs to the cluster. What parameters will you need to specify when you issue the cluster resize command?","choices":["A. Cluster size","B. Cluster name","C. Node pool name","D. All of the above"],"answer":"6. D. When resizing, the gcloud container clusters resi come mand requires the nameof the cluster and the node pool to modify. The size is required to specify how many nodesshould be running. Therefore, option D is correct."},{"index":7,"questions":"7. You want to modify the number of pods in a cluster. What is the best way to do that?","choices":["A. Modify pods directly","B. Modify deployments","C. Modify node pools directly","D. Modify nodes"],"answer":"7. B. Pods are used to implement replicas of a deployment. It is a best practice to modifythe deployments, which are configured with a specification of the number of replicas thatshould always run, so option B is the correct answer. Option A is incorrect; you should notmodify pods directly. Options C and D are incorrect because they do not change the num-ber of pods running an application."},{"index":8,"questions":"8. You want to see a list of deployments. Which option from the Kubernetes Engine navigation menu would you select?","choices":["A. Clusters","B. Storage","C. Workloads","D. Deployments"],"answer":"8. C. Deployments are listed under Workloads, making option C the correct answer. TheCluster option shows details about clusters but does not have details on deployments. Stor-age shows information about persistent volumes and storage classes. Deployments is not anoption."},{"index":9,"questions":"9. What actions are available from the Actions menu when viewing deployment details?","choices":["A. Scale and Autoscale only","B. Autoscale, Expose, and Rolling Update","C. Add, Modify, and Delete","D. None of the above"],"answer":"9. B. There are four actions available for deployments (Autoscale, Expose, Rolling Update,and Scale), so option B is correct. Add, Modify, and Delete are not options."},{"index":10,"questions":"10. What is the command to list deployments from the command line?","choices":["A. gcloud container clusters list-deployments","B. gcloud container clusters list","C. kubectl get deployments","D. kubectl deployments list"],"answer":"10. C. Since deployments are managed by Kubernetes and not GCP, we need to use a kubectlcommand and not a gcloudcommand, which makes option C correct. Option D isincorrect because it follows the gcloudcommand structure, not the kubectlcommandstructure. The kubectlcommand has the verb, like get, before the resource type, likedeployment,sfor example."},{"index":11,"questions":"11. What parameters of a deployment can be set in the Create Deployment page in Cloud Console?","choices":["A. Container image","B. Cluster name","C. Application name","D. All of the above206 Chapter 8 ■ Managing Kubernetes Clusters"],"answer":"11. D. You can specify container image, cluster name, and application name along with thelabels, initial command, and namespace; therefore, option D is the correct answer."},{"index":12,"questions":"12. Where can you view a list of services when using Cloud Console?","choices":["A. In the Deployment Details page","B. In the Container Details page","C. In the Cluster Details page","D. None of the above"],"answer":"12. A. The Deployment Details page includes services, so option A is the correct answer. Con-tainers are used to implement services; service details are not available there. The ClustersDetail page does not contain information on services running in the cluster."},{"index":13,"questions":"13. What kubectlcommand is used to add a service?","choices":["A. run","B. start","C. initiate","D. deploy"],"answer":"13. A. kubectl run is the command used to start a deployment. It takes a name for thedeployment, an image, and a port specification. The other options are not valid kubectlcommands."},{"index":14,"questions":"14. You are supporting machine learning engineers who are testing a series of classifiers. They have five classifiers, called ml-classifier-1, ml-classifier-2, etc. They have found that ml- classifier-3 is not functioning as expected and they would like it removed from the cluster. What would you do to delete a service called ml-classifier-?3","choices":["A. Run the command kubectl delete service ml-classifie . r-3","B. Run the command kubectl delete ml-classifie.r-3","C. Run the command gcloud service delete ml-classifie .r-3","D. Run the command gcloud container service delete ml-classifi .er-3"],"answer":"14. A. Option A shows the correct command, which is kubectl delete service ml-classifier-3 . Option B is missing the service term. Options C and D cannot be correctbecause services are managed by Kubernetes, not GCP."},{"index":15,"questions":"15. What service is responsible for managing container images?","choices":["A. Kubernetes Engine","B. Compute Engine","C. Container Registry","D. Container Engine"],"answer":"15. C. The Container Registry is the service for managing images that can be used in otherservices, including Kubernetes Engine and Compute Engine, making option C correct. BothCompute Engine and Kubernetes Engine use images but do not manage them. There is noservice called Container Engine."},{"index":16,"questions":"16. What command is used to list container images in the command line?","choices":["A. gcloud container images list","B. gcloud container list images","C. kubectl list container images","D. kubectl container list images"],"answer":"16. A. Images are managed by GCP, so the correct command will be a gcloudcommand,so option A is the correct answer. Option B is incorrect because the verb is placed beforethe resource. Options C and D are incorrect because kubectlis for managing Kubernetesresources, not GCP resources like container images. Chapter 9: Computing with App Engine 481"},{"index":17,"questions":"17. A data warehouse designer wants to deploy an extraction, transformation, and load process to Kubernetes. The designer provided you with a list of libraries that should be installed, including drivers for GPUs. You have a number of container images that you think may meet the requirements. How could you get a detailed description of each of those containers?","choices":["A. Run the command gcloud container images list deta .ils","B. Run the command gcloud container images descr.ibe","C. Run the command gcloud image descri.be","D. Run the command gcloud container descri.be Review Questions 207"],"answer":"17. B. The correct command is gcloud container images descr,iw behich makes optionB the right answer. describeis the gcloudverb or operation for showing the details of anobject. All other options are invalid commands."},{"index":18,"questions":"18. You have just created a deployment and want applications outside the cluster to have access to the services provided by the deployment. What do you need to do to the service?","choices":["A. Give it a public IP address.","B. Issue a kubectl expose deploymec notmmand.","C. Issue a gcloud expose deploymen ctmmand.","D. Nothing, making it accessible must be done at the cluster level."],"answer":"18. B. The kubectl expose deploymec notmmand makes a service accessible, so option B isthe correct answer. IP addresses are assigned to VMs, not services. The command gclouddoes not manage Kubernetes services, so option C is incorrect. Option D is incorrectbecause making a service accessible is not a cluster-level task."},{"index":19,"questions":"19. You have deployed an application to a Kubernetes cluster that processes sensor data from a fleet of delivery vehicles. The volume of incoming data depends on the number of vehicles making deliveries. The number of vehicles making deliveries is dependent on the number of customer orders. Customer orders are high during daytime hours, holiday seasons, and when major advertising campaigns are run. You want to make sure you have enough nodes running to handle the load, but you want to keep your costs down. How should you config- ure your Kubernetes cluster?","choices":["A. Deploy as many nodes as your budget allows.","B. Enable autoscaling.","C. Monitor CPU, disk, and network utilization and add nodes as necessary.","D. Write a script to run gcloudcommands to add and remove nodes when peaks usually start and end, respectively."],"answer":"19. B. Autoscaling is the most cost-effective and least burdensome way to respond to changesin demand for a service, so option B is the correct answer. Option A may run nodes evenwhen they are not needed. Option C is manually intensive and requires human intervention.Option D reduces human intervention but does not account for unexpected spikes or lullsin demand."},{"index":20,"questions":"20. When using Kubernetes Engine, which of the following might a cloud engineer need to configure?","choices":["A. Nodes, pods, services, and clusters only","B. Nodes, pods, services, clusters, and container images","C. Nodes, pods, clusters, and container images only","D. Pods, services, clusters, and container images only ■ 220 Chapter 9 Computing with App Engine Review Questions You can find the answers in the Appendix."],"answer":"20. B. Cloud engineers working with Kubernetes will need to be familiar with working withclusters, nodes, pods, and container images. They will also need to be familiar with deploy-ment. Option B is the correct answer because the other options are all missing an importantcomponent of Kubernetes that cloud engineers will have to manage.Chapter 9: Computing with App Engine"}],"9":[{"index":1,"questions":"1. You have designed a microservice that you want to deploy to production. Before it can be deployed, you have to review how you will manage the service lifecycle. The architect is particularly concerned about how you will deploy updates to the service with minimal dis- ruption. What aspect of App Engine components would you use to minimize disruptions during updates to the service?","choices":["A. Services","B. Versions","C. Instance groups","D. Instances"],"answer":"1. B. Versions support migration. An app can have multiple versions, and by deploying withthe --migrateparameter, you can migrate traffic to the new version, so option B is thecorrect answer. Services are a higher-level abstraction and represent the functionalityof a microservice. An app may have multiple services, but they serve different purposes.Instances execute code in a version. Instances may be added and removed as needed, butthey will run only one version of a service. Instance groups are part of Compute Engine andare not an App Engine component."},{"index":2,"questions":"2. You’ve just released an application running in App Engine Standard. You notice that there are peak demand periods in which you need up to 12 instances, but most of the time 5 instances are sufficient. What is the best way to ensure that you have enough instances to meet demand without spending more than you have to?","choices":["A. Configure your app for autoscaling and specify max instances of 12 and min instances of 5.","B. Configure your app for basic scaling and specify max instances of 12 and min instances of 5.","C. Create a cron job to add instances just prior to peak periods and remove instances after the peak period is over.","D. Configure your app for instance detection and do not specify a max or minimum num- ber of instances."],"answer":"2. A. Autoscaling enables setting a maximum and minimum number of instances, whichmakes option A correct. Basic scaling does not support maximum and minimum instances.Option C is not recommended because it is difficult to predict when load will peak and evenif the schedule is predictable today, it may change over time. Option D is wrong; there is noinstance detection option."},{"index":3,"questions":"3. In the hierarchy of App Engine components, what is the lowest-level component?","choices":["A. Application","B. Instance","C. Version","D. Service"],"answer":"3. B. Application is the top-level component, so option B is the correct answer. Applicationshave one or more services. Services have one or more versions. Versions are executed on oneor more instances when the application is running."},{"index":4,"questions":"4. What command should you use to deploy an App Engine app from the command line?","choices":["A. gcloud components app deploy","B. gcloud app deploy","C. gcloud components instances deploy","D. gcloud app instance deploy Review Questions 221"],"answer":"4. B. The correct command is gcloud app deplo ,which is option B. Options A and C areincorrect because gcloud componentcsommands are used to install gcloudcommands forworking with parts of App Engine, such as the Python runtime environment. Option D isincorrect; you do not need to specify instance in the command."},{"index":5,"questions":"5. You have deployed a Django 1.5 Python application to App Engine. This version of Django requires Python 3. For some reason, App Engine is trying to run the application using Python 2. What file would you check and possibly modify to ensure that Python 3 is used with this application?","choices":["A. app.config","B. app.yaml","C. services.yaml","D. deploy.yaml"],"answer":"5. B. The app.yamlfile is used to configure an App Engine application, which makes optionB correct. The other options are not files used to configure App Engine.482 Appendix ■ Answers to Review Questions"},{"index":6,"questions":"6. You have several App Engine apps you plan to deploy from your project. What have you failed to account for in this design?","choices":["A. App Engine only supports one app per project.","B. App Engine only supports two apps per project.","C. App Engine apps exist outside of projects.","D. Nothing, this is a common pattern."],"answer":"6. A. A project can support only one App Engine app, so option A is the right answer. If you’dlike to run other applications, they will need to be placed in their own projects."},{"index":7,"questions":"7. The latest version of your microservice code has been approved by your manager, but the product owner does not want the new features released until a press release is published. You’d like to get the code out but not expose it to customers. What is the best way to get the code out as soon as possible without exposing it to customers?","choices":["A. Deploy with gcloud app deploy --no-traffic.","B. Write a cron job to deploy after the press release is published.","C. Deploy with gcloud app deploy --no-promote.","D. Deploy as normal after the press release is published."],"answer":"7. C. The correct answer is option C because the correct parameter is --no-promot.eOption Auses no-traffi,cwhich is not a valid parameter to the gcloud app deplocyommand.Option B does not get the code out and could release the code too early if there is a delay ingetting the press release out. Option D does not meet the requirements of getting the codeout as soon as possible."},{"index":8,"questions":"8. You have just deployed an app that hosts services that provide the current time in any time zone. The project containing the code is called current-time-zon,the service providing the user interface is called time-zone-u,iand the service performing the calculation is called time-zone-calculat . What is the URL where a user could find your service?","choices":["A. current-time-zone.appengine.com","B. current-time-zone.appspot.com","C. time-zone-ui.appspot.com","D. time-zone-calculate.appspot.com"],"answer":"8. B. App Engine applications are accessible from URLs that consist of the project name fol-lowed by appspot.co,mso option B is correct. Option A is incorrect because the domain isnot appengine.co.mOptions C and D are incorrect because the names of services are notused to reference the application as a whole."},{"index":9,"questions":"9. You are concerned that as users make connections to your application, the performance will degrade. You want to make sure that more instances are added to your App Engine application when there are more than 20 concurrent requests. What parameter would you specify in app.yaml?","choices":["A. max_concurrent_requests","B. target_throughput_utilization","C. max_instances","D. max_pending_latency222 Chapter 9 ■ Computing with App Engine"],"answer":"9. A. max_concurrent_request lts you specify the maximum number of concurrentrequests before another instance is started, which makes option A correct. target_throughput_utilization functions similarly but uses a 0.05 to 0.95 scale to specify max-imum throughput utilization. max_instances specifies the maximum number of instancesbut not the criteria for adding instances. max_pending_latenciy s based on the time arequest waits, not the number of requests."},{"index":10,"questions":"10. What parameters can be configured with basic scaling?","choices":["A. max_instances and min_instances","B. idle_timeout and min_instances","C. idle_timeout and max_instances","D. idle_timeout and target_throughput_utilization"],"answer":"10. C. Basic scaling only allows for idle time and maximum instances, so option C is the rightanswer. min_instances is not supported. target_throughput_utilizatiio snan auto-scaling parameter, not a basic scaling parameter."},{"index":11,"questions":"11. The runtimeparameter in app.yamlis used to specify what?","choices":["A. The script to execute","B. The URL to access the application","C. The language runtime environment","D. The maximum time an application can run"],"answer":"11. C. The runtimeparameter specifies the language environment to execute in, which makesoption C correct. The script to execute is specified by the scriptparameter. The URL toaccess the application is based on the project name and the domain appspot.co.mThere isno parameter for specifying the maximum time an application can run."},{"index":12,"questions":"12. What are the two kinds of instances available in App Engine Standard?","choices":["A. Resident and dynamic","B. Persistent and dynamic","C. Stable and dynamic","D. Resident and nonresident"],"answer":"12. A. Resident instances are used with manual scaling while dynamic instances are used withautoscaling and basic scaling, so option A is the correct answer. There are no persistent,stable, or nonresident types of App Engine instances."},{"index":13,"questions":"13. You work for a startup, and costs are a major concern. You are willing to take a slight per- formance hit if it will save you money. How should you configure the scaling for your apps running in App Engine?","choices":["A. Use dynamic instances by specifying autoscaling or basic scaling.","B. Use resident instances by specifying autoscaling or basic scaling.","C. Use dynamic instances by specifying manual scaling.","D. Use resident instances by specifying manual scaling."],"answer":"13. A. Using dynamic instances by specifying autoscaling or basic scaling will automaticallyadjust the number of instances in use based on load, so option A is correct. Option B isincorrect because autoscaling and basic scaling only create dynamic instances. Options Cand D are incorrect because manual scaling will not adjust instances automatically, so youmay continue to run more instances than needed at some points."},{"index":14,"questions":"14. A team of developers has created an optimized version of a service. This should run 30 percent faster in most cases. They want to roll it out to all users immediately, but you are concerned that the substantial changes need to be released slowly in case there are significant bugs. What can you do to allocate some users to the new version without exposing all users to it?","choices":["A. Issue the command gcloud app services set-traffic.","B. Issue the command gcloud instances services set-traffic.","C. Issue the command gcloud app set-traffic.","D. Change the target IP address of the service for some clients."],"answer":"14. A. The correct answer is gcloud app services set-traf.fO icption B is incorrectbecause the term instancesis not needed. Option C is incorrect because it does not specifythe term services . Option D is incorrect because that would require changes on theclient’s part."},{"index":15,"questions":"15. What parameter to gcloud app services set-traff iscsed to specify the method to use when splitting traffic?","choices":["A. ––split-traffic","B. ––split-by","C. ––traffic-split","D. ––split-method Review Questions 223"],"answer":"15. A. --split-traffiics the parameter used to specify the method for splitting traffic,which makes option A correct. Valid options are cookie , ip, and random. All other optionsare not valid parameters to the gcloud app services set-traff command. Chapter 10: Computing with Cloud Functions 483"},{"index":16,"questions":"16. What parameter to gcloud app services set-traff iscsed to specify the percentage of traffic that should go to each instance?","choices":["A. ––split-by","B. ––splits","C. ––split-percent","D. ––percent-split"],"answer":"16. B. --splitis the parameter for specifying a list of instances and the percent of traffic theyshould receive, so option B is the right answer. The other options are not valid parametersfor the gcloud app services set-traff command."},{"index":17,"questions":"17. You have released a new version of a service. You have been waiting for approval from the product manager to start sending traffic to the new version. You get approval to route traf- fic to the new version. What parameter to gcloud app services set-traff iscsed to specify that traffic should be moved to a newer version of the app?","choices":["A. ––move-to-new","B. ––migrate-to-new","C. ––migrate","D. ––move"],"answer":"17. C. --migrateis the parameter for specifying that traffic should be moved or migrated tothe newer instance, which makes option C the correct answer. The other options are notvalid parameters for the gcloud app services set-traff cocmmand."},{"index":18,"questions":"18. The status of what components can be viewed in the App Engine console?","choices":["A. Services only","B. Versions only","C. Instances and versions","D. Services, versions, and instances"],"answer":"18. D. From the App Engine console you can view the list of services and versions as well asinformation about the utilization of each instance."},{"index":19,"questions":"19. What are valid methods for splitting traffic?","choices":["A. By IP address only","B. By HTTP cookie only","C. Randomly and by IP address only","D. By IP address, HTTP cookies, and randomly"],"answer":"19. D. All three methods listed, IP address, HTTP cookie, and random splitting, are allowedmethods for splitting traffic."},{"index":20,"questions":"20. What is the name of the cookie used by App Engine when cookie-based splitting is used?","choices":["A. GOOGID","B. GOOGAPPUID","C. APPUID","D. UIDAPP Review Questions 237 Review Questions You can find the answers in the Appendix."],"answer":"20. B. The cookie used for splitting in App Engine is called GOOGAPPUID, which makesoption B the correct answer. Options A, C, and D are not valid names.Chapter 10: Computing with CloudFunctions"}],"10":[{"index":1,"questions":"1. A product manager is proposing a new application that will require several backend ser- vices, three business logic services, and access to relational databases. Each service will provide a single function, and it will require several of these services to complete a business task. Service execution time is dependent on the size of input and is expected to take up to 30 minutes in some cases. Which GCP product is a good serverless option for running this related service?","choices":["A. Cloud Functions","B. Compute Engine","C. App Engine","D. Cloud Storage"],"answer":"1. C. App Engine is designed to support multiple tightly coupled services comprising anapplication, making option C the correct answer. This is unlike Cloud Functions, which isdesigned to support single-purpose functions that operate independently and in response toisolated events in the Google Cloud and complete within a specified period of time. Com-pute Engine is not a serverless option. Cloud Storage is not a computing product."},{"index":2,"questions":"2. You have been asked to deploy a cloud function to reformat image files as soon as they are uploaded to Cloud Storage. You notice after a few hours that about 10 percent of the files are not processed correctly. After reviewing the files that failed, you realize they are all sub- stantially larger than average. What could be the cause of the failures?","choices":["A. There is a syntax error in the function code.","B. The wrong runtime was selected.","C. The timeout is too low to allow enough time to process large files.","D. There is a permissions error on the Cloud Storage bucket containing the files."],"answer":"2. C. A timeout period that is too low would explain why the smaller files are processed intime but the largest are not, which makes option C the right answer. If only 10 percent ofthe files are failing, then it is not a syntax error or the wrong runtime selected, as in optionsA and B. Those errors would affect all files, not just the largest ones. Similarly, if there wasa permission problem with the Cloud Storage bucket, it would affect all files."},{"index":3,"questions":"3. When an action occurs in GCP, such as a file being written to Cloud Storage or a message being added to a Cloud Pub/Sub topic, that action is called what?","choices":["A. An incident","B. An event","C. A trigger","D. A log entry"],"answer":"3. B. Those actions are known as events in Google Cloud terminology; thus, option B is thecorrect answer. An incident may be a security or performance-related occurrence, but thoseare unrelated to the expected and standardized actions that constitute events. A trigger isa declaration that a certain function should execute when an event occurs. A log entry isrelated to applications recording data about significant events. Log entries are helpful formonitoring and compliance, but in themselves are not event-related actions."},{"index":4,"questions":"4. All of the following generate events that can be triggered using Cloud Functions, except which one?","choices":["A. Cloud Storage","B. Cloud Pub/Sub","C. SSL","D. Firebase238 Chapter 10 ■ Computing with Cloud Functions"],"answer":"4. C. The correct answer is option C because SSL is a secure protocol for remotely accessingservers. It is used, for example, to access instances in Compute Engine. It does not haveevents that can be triggered using Cloud Functions. The three GCP products listed dogenerate events that can have triggers associated with them."},{"index":5,"questions":"5. Which runtimes are supported in Cloud Functions?","choices":["A. Node.js 5, Node.js 6, and Node.js 8","B. Node.js 8, Python, and Go","C. Node.js 6, Node.js 8, and Python","D. Node.js 8, Python, and Go"],"answer":"5. C. Cloud Functions supports three runtimes: Node.js 6, Node.js 8, and Python. Go andNode.js 5 are not supported runtimes.484 Appendix ■ Answers to Review Questions"},{"index":6,"questions":"6. An HTTP trigger can be invoked by making a request using which of the following?","choices":["A. GET only","B. POST and GET only","C. DELETE, POST, and GET","D. DELETE, POST, REVISE, and GET"],"answer":"6. D. HTTP requests using GET, POST, DELETE, PUT, and OPTIONS can invoke an HTTPtrigger in Cloud Functions, so option C is the right answer."},{"index":7,"questions":"7. What types of events are available to Cloud Functions working with Cloud Storage?","choices":["A. Upload or finalize and delete only","B. Upload or finalize, delete, and list only","C. Upload or finalize, delete, and metadata update only","D. Upload or finalize, delete, metadata update, and archive"],"answer":"7. D. The correct answer, option D, shows the four events supported in Cloud Storage.google.storage.object.finalizegoogle.storage.object.deletegoogle.storage.object.archivegoogle.storage.object.metadataUpdate"},{"index":8,"questions":"8. You are tasked with designing a function to execute in Cloud Functions. The function will need more than the default amount of memory and should be applied only when a finalize event occurs after a file is uploaded to Cloud Storage. The function should only apply its logic to files with a standard image file type. Which of the following required features can- not be specified in a parameter and must be implemented in the function code?","choices":["A. Cloud function name","B. Memory allocated for the function","C. File type to apply the function to","D. Event type"],"answer":"8. C. There is no option to specify the file type to apply the function to, so option C is cor-rect. You can, however, specify the bucket to which the function is applied. You could onlysave files or the types you want processed in that bucket, or you could have your functioncheck file type and then execute the rest of the function or not, based on type. All the otheroptions listed are parameters to a Cloud Storage function."},{"index":9,"questions":"9. How much memory can be allocated to a Cloud Function?","choices":["A. 128MB to 256MB","B. 128MB to 512MB","C. 128MB to 1GB","D. 128MB to 2GB"],"answer":"9. D. Cloud Functions can have between 128MB and 2GB of memory allocated, which makesoption D the correct answer. The default is 256MB."},{"index":10,"questions":"10. How long can a cloud function run by default before timing out?","choices":["A. 30 seconds","B. 1 minute","C. 9 minutes","D. 20 minutes Review Questions 239"],"answer":"10. B. By default Cloud Functions can run for up to 1 minute before timing out, so option B iscorrect. You can, however, set the timeoutparameter for a cloud function for periods of upto 9 minutes before timing out."},{"index":11,"questions":"11. You want to use the command line to manage Cloud Functions that will be written in Python. In addition to running the gcloud components updat cemmand, what com- mand should you run to ensure you can work with Python functions?","choices":["A. gcloud component install","B. gcloud components install beta","C. gcloud components install python","D. gcloud functions install beta"],"answer":"11. B. Python Cloud Functions is currently in beta. The standard set of gcloudcommandsdoes not include commands for alpha or beta release features by default. You will need toexplicitly install beta features using the gcloud components install bect ommand, sooption B is the right answer. Option A will install standard gcloudcommands. Options Cand D are not valid gcloudcommands."},{"index":12,"questions":"12. You want to create a cloud function to transform audio files into different formats. The audio files will be uploaded into Cloud Storage. You want to start transformations as soon as the files finish uploading. Which trigger would you specify in the cloud function to cause it to execute after the file is uploaded?","choices":["A. google.storage.object.finalize","B. google.storage.object.upload","C. google.storage.object.archive","D. google.storage.object.metadataUpdate"],"answer":"12. A. The correct trigger in option A is google.storage.object.final,iw zhich occursafter a file is uploaded. Option B is not a valid trigger name. Option C triggers when a fileis archived, not uploaded. Option D is triggered when some metadata attribute changes, butnot necessarily only after a file uploads."},{"index":13,"questions":"13. You are defining a cloud function to write a record to a database when a file in Cloud Stor- age is archived. What parameters will you have to set when creating that function?","choices":["A. runtimeonly","B. trigger-resourco enly","C. runtime , trigger-resourc ,trigger-event only","D. runtime , trigger-resourc ,trigger-even,tfile-type"],"answer":"13. C. The three parameters are runtime , trigger-resourc ,eand trigger-even,tas listedin option C. All must be set, so options A and B are incorrect. file-typeis not a param-eter to creating a cloud function on Cloud Storage, so option D is incorrect."},{"index":14,"questions":"14. You’d like to stop using a cloud function and delete it from your project. Which command would you use from the command line to delete a cloud function?","choices":["A. gcloud functions delete","B. gcloud components function delete","C. gcloud components delete","D. gcloud delete functions"],"answer":"14. A. The correct answer is option A, gcloud functions dele.tO eption B referencescomponents, which is incorrect. You do need to reference components when installing orupdating gcloudcommands but not when deleting a cloud function, so options B and Care incorrect. Option D is incorrect because the GCP entity type, in this case functio,scomes before the name of the operation, in this case delet, in a gcloudcommand."},{"index":15,"questions":"15. You have been asked to deploy a cloud function to work with Cloud Pub/Sub. As you review the Python code, you notice a reference to a Python function called base64.b64d.eod Why would a decode function be required in a Pub/Sub cloud function?","choices":["A. It’s not required and should not be there.","B. Messages in Pub/Sub topics are encoded to allow binary data to be used in places where text data is expected. Messages need to be decoded to access the data in the message.","C. It is required to add padding characters to the end of the message to make all messages the same length.","D. The decode function maps data from a dictionary data structure to a list data structure.240 Chapter 10 ■ Computing with Cloud Functions"],"answer":"15. B. Messages are stored in a text format, base64, so that binary data can be stored in themessage in a text format, so option B is correct. Option A is incorrect; it is needed to mapfrom a binary encoding to a standard text encoding. Option C is incorrect because thefunction does not pad with extra characters to make them the same length. Option D isincorrect; it does not change dictionary data types into list data types. Chapter 11: Planning Storage in the Cloud 485"},{"index":16,"questions":"16. Which of these commands will deploy a Python cloud function called pub_sub_function_te? st","choices":["A. gcloud functions deploy pub_sub_function_test","B. gcloud functions deploy pub_sub_function_test --runtime python37","C. gcloud functions deploy pub_sub_function_test --runtime python37 --trigger-topic gcp-ace-exam-test-topic","D. gcloud functions deploy pub_sub_function_test --runtime python --trigger-topic gcp-ace-exam-test-topic"],"answer":"16. C. Option C is correct because it includes the name of the function, the runtime environ-ment, and the name of the Pub/Sub topic. Option A is incorrect because it’s missing boththe runtime and the topic. Option B is incorrect because it is missing the topic. Option D isincorrect because the runtime specification is incorrect; you have to specify python37andnot pythonas the runtime."},{"index":17,"questions":"17. When specifying a Cloud Storage cloud function, you have to specify an event type, such as finalize , delete, or archive. When specifying a Cloud Pub/Sub cloud function, you do not have to specify an event type. Why is this the case?","choices":["A. Cloud Pub/Sub does not have triggers for event types.","B. Cloud Pub/Sub has triggers on only one event type, when a message is published.","C. Cloud Pub/Sub determines the correct event type by analyzing the function code.","D. The statement in the question is incorrect; you do have to specify an event type with Cloud Pub/Sub functions."],"answer":"17. B. There is only one type of event that is triggered in Cloud Pub/Sub, and that is when amessage is published, which is option B. Option A is incorrect; Cloud Pub/Sub has oneevent type that can have a trigger. Option C is incorrect; Cloud Pub/Sub does not analyzethe code to determine when it should be run. Option D is incorrect; you do not have tospecify an event type with Cloud Pub/Sub functions."},{"index":18,"questions":"18. Your company has a web application that allows job seekers to upload résumé files. Some files are in Microsoft Word, some are PDFs, and others are text files. You would like to store all résumés as PDFs. How could you do this in a way that minimizes the time between upload and conversion and with minimal amounts of coding?","choices":["A. Write an App Engine application with multiple services to convert all documents to PDF.","B. Implement a Cloud Function on Cloud Storage to execute on a finalize event. The function checks the file type, and if it is not PDF, the function calls a PDF converter function and writes the PDF version to the bucket that has the original.","C. Add the names of all files to a Cloud Pub/Sub topic and have a batch job run at regular intervals to convert the original files to PDF.","D. Implement a Cloud Function on Cloud Pub/Sub to execute on a finalize event. The function checks the file type, and if it is not PDF, the function calls a PDF converter function and writes the PDF version to the bucket that has the original."],"answer":"18. B. The correct answer is option B because it uses a Cloud Storage finalize event to triggerconversion if needed. There is minimal delay between the time the file is uploaded andwhen it is converted. Option A is a possibility but would require more coding than optionB. Option C is not a good option because files are not converted until the batch job runs.Option D is incorrect because you cannot create a cloud function for Cloud Pub/Sub usinga finalize event. That event is for Cloud Storage, not Cloud Pub/Sub."},{"index":19,"questions":"19. What are options for uploading code to a cloud function?","choices":["A. Inline editor","B. Zip upload","C. Cloud source repository","D. All of the above"],"answer":"19. D. All of the options are available along with zip from Cloud Storage."},{"index":20,"questions":"20. What type of trigger allows developers to use HTTP POST, GET, and PUT calls to invoke a cloud function?","choices":["A. HTTP","B. Webhook","C. Cloud HTTP","D. None of the above Review Questions 271 Review Questions You can find the answers in the Appendix."],"answer":"20. A. The HTTP trigger allows for the use of POST, GET, and PUT calls, so option A is thecorrect answer. Webhook and Cloud HTTP are not valid trigger types. Option D is incor-rect because option A is the correct answer.Chapter 11: Planning Storage inthe Cloud"}],"11":[{"index":1,"questions":"1. You are tasked with defining lifecycle configurations on buckets in Cloud Storage. You need to consider all possible options for transitioning from one storage class to another. All of the following transitions are allowed except for one. Which one is that?","choices":["A. Nearline to coldline","B. Regional to nearline","C. Multiregional to coldline","D. Regional to multiregional"],"answer":"1. D. Once a bucket is created as either regional or multiregional, it cannot be changed to theother, so option D is correct. Nearline to coldline and regional to nearline are both allowed,as is multiregional to coldline."},{"index":2,"questions":"2. Your manager has asked for your help in reducing Cloud Storage charges. You know that some of the files stored in Cloud Storage are rarely accessed. What kind of storage would you recommend for those files?","choices":["A. Nearline","B. Regional","C. Coldline","D. Multiregional"],"answer":"2. C. The goal is to reduce cost, so you would want to use the least costly storage option.Coldline has the lowest per-gigabyte charge at $0.07/GB/month, so option C is correct.Nearline is the next lowest followed by regional. Multiregional has the highest per-gigabytecharge. Both nearline and coldline have access charges, but those are not considered in thisquestion."},{"index":3,"questions":"3. You are working with a startup developing analytics software for IoT data. You have to be able to ingest large volumes of data consistently and store it for several months. The startup has several applications that will need to query this data. Volumes are expected to grow to petabyte volumes. Which database should you use?","choices":["A. Cloud Spanner","B. Bigtable","C. BigQuery","D. Datastore"],"answer":"3. B. Bigtable is a wide-column database that can ingest large volumes of data consistently,so option B is correct. It also supports low-millisecond latency, making it a good choicefor supporting querying. Cloud Spanner is a global relational database that is not suitablefor high-speed ingestion of large volumes of data. Datastore is an object data model andnot a good fit for IoT or other time series data. BigQuery is an analytics database and notdesigned for ingestion of large volumes of data in short periods of time.486 Appendix ■ Answers to Review Questions"},{"index":4,"questions":"4. A software developer on your team is asking for your help improving the query performance of a database application. The developer is using a Cloud SQL MySQL, Second Generation instance. Which options would you recommend?","choices":["A. Memorystore and SSD persistent disks","B. Memorystore and HDD persistent disks","C. Datastore and SSD persistent disks","D. Datastore and HDD persistent disks272 Chapter 11 ■ Planning Storage in the Cloud"],"answer":"4. A. Option A is correct because Memorystore is a managed Redis cache. The cache canbe used to store the results of queries. Follow-on queries that reference the data stored inthe cache can read it from the cache, which is much faster than reading from persistentdisks. SSDs have significantly lower latency than hard disk drives and should be used forperformance-sensitive applications like databases. Options B and D are incorrect becauseHDD persistent disks do give the best performance with respect to IOPS. Options C andD are incorrect because Datastore is a managed NoSQL database and would not have anyimpact on SQL query performance."},{"index":5,"questions":"5. You are creating a set of persistent disks to store data for exploratory data analysis. The disks will be mounted on a virtual machine in the us-west2-a zone. The data is historical data retrieved from Cloud Storage. The data analysts do not need peak performance and are more concerned about cost than performance. The data will be stored in a local relational database. Which type of storage would you recommend?","choices":["A. SSDs","B. HDDs","C. Datastore","D. Bigtable"],"answer":"5. B. HDDs are the better choice for persistent disks for a local database when performanceis not the primary concern and you are trying to keep costs down, so option B is correct.Option A is wrong because SSDs are more expensive and the users do not need the lowestlatency available. Options C and D are wrong; both of those are other databases that wouldnot be used to store data in a local relational database."},{"index":6,"questions":"6. Which of the following statements about Cloud Storage is not true?","choices":["A. Cloud Storage buckets can have retention periods.","B. Lifecycle configurations can be used to change storage class from regional to multiregional.","C. Cloud Storage does not provide block-level access to data within files stored in buckets.","D. Cloud Storage is designed for high durability."],"answer":"6. B. Lifecycle configurations can change storage class from regional to nearline or coldline.Once a bucket is created as regional or multiregional, it cannot be changed to the other, sooption B is the right answer. Option A is true; you can set retention periods when creating abucket. Option C is true; Cloud Storage does not provide file system–like access to internaldata blocks. Option D is true because Cloud Storage is highly durable."},{"index":7,"questions":"7. When using versioning on a bucket, what is the latest version of the object called?","choices":["A. Live version","B. Top version","C. Active version","D. Safe version"],"answer":"7. A. The most recent version of an object is called the live version, so option A is correct.Options B and C are incorrect; top and active are not terms used to refer to versions.Option D is incorrect because option A is correct."},{"index":8,"questions":"8. A product manager has asked for your advice on which database services might be options for a new application. Transactions and support for tabular data are important. Ideally, the database would support common query tools. What databases would you recommend the product manager consider?","choices":["A. BigQuery and Spanner","B. Cloud SQL and Spanner","C. Cloud SQL and Bigtable","D. Bigtable and Spanner"],"answer":"8. B. Both Cloud SQL and Spanner are relational databases and are well suited for transaction-processing applications, so option B is right. Option A is incorrect because BigQuery isrelational, but it is designed for data warehousing and analytics, not transaction processing.Options C and D are incorrect because Bigtable a wide-column NoSQL database, not arelational database."},{"index":9,"questions":"9. The Cloud SQL service provides fully managed relational databases. What two types of databases are available in Cloud SQL?","choices":["A. SQL Server and MySQL","B. SQL Server and PostgreSQL","C. PostgreSQL and MySQL","D. MySQL and Oracle"],"answer":"9. C. Both MySQL and PostgreSQL are Cloud SQL options so Option C is correct. Options Aand B are incorrect, SQL Server is not a Cloud SQL option. Option D is incorrect becauseOracle is not a Cloud SQL option. You could choose to run SQL Server or Oracle on yourinstances but you would have to manage them, unlike Cloud SQL managed databases."},{"index":10,"questions":"10. Which of the following Cloud Spanner configurations would have the highest hourly cost?","choices":["A. Located in us-central1","B. Located in nam3 Review Questions 273","C. Located in us-west1-a","D. Located in nam-eur-asia1"],"answer":"10. D. The multiregional and multi-super-regional location of nam-eur-aisa1 is the mostexpensive, which makes option D the right answer. Option A is a region that costs lessthan the multi-super-regional nam-eur-asia1. Option C is incorrect; that is a zone, andSpanner is configured to regions or super regions. Option B is incorrect; it is only a singlesuper region, which cost less than deploying to multiple super regions."},{"index":11,"questions":"11. Which of the following are database services that do not require you to specify configuration information for VMs?","choices":["A. BigQuery only","B. Datastore only","C. Firebase and Datastore","D. BigQuery, Datastore, and Firebase"],"answer":"11. D. BigQuery, Datastore, and Firebase are all fully managed services that do not require youto specify configuration information for VMs, which makes option D correct. Cloud SQLand Bigtable require you to specify some configuration information for VMs."},{"index":12,"questions":"12. What kind of data model is used by Datastore?","choices":["A. Relational","B. Document","C. Wide-column","D. Graph"],"answer":"12. B. Datastore is a document database, which makes option B correct. Cloud SQL and Span-ner are relational databases. Bigtable is a wide-column database. Google does not offer amanaged graph database. Chapter 12: Deploying Storage in Google Cloud Platform 487"},{"index":13,"questions":"13. You have been tasked with creating a data warehouse for your company. It must support tens of petabytes of data and use SQL for a query language. Which managed database service would you choose?","choices":["A. BigQuery","B. Bigtable","C. Cloud SQL","D. SQL Server"],"answer":"13. A. BigQuery is a managed service designed for data warehouses and analytics. It usesstandard SQL for querying, which makes option A the right answer. Bigtable can supportthe volume of data described, but it does not use SQL as a query language. Cloud SQL isnot the best option to scale to tens of petabytes. SQL Server is a relational database fromMicrosoft; it is not a GCP-managed database service."},{"index":14,"questions":"14. A team of mobile developers is developing a new application. It will require synchronizing data between mobile devices and a backend database. Which database service would you recommend?","choices":["A. BigQuery","B. Firestore","C. Spanner","D. Bigtable"],"answer":"14. B. Firestore is a document database that has mobile supporting features, like data synchro-nization, so option B is the right answer. BigQuery is for analytics, not mobile or transac-tional applications. Spanner is a global relational database but does not have mobile-specificfeatures. Bigtable could be used with mobile devices, but it does not have mobile-specificfeatures like synchronization."},{"index":15,"questions":"15. A product manager is considering a new set of features for an application that will require additional storage. What features of storage would you suggest the product manager consider?","choices":["A. Read and write patterns only","B. Cost only","C. Consistency and cost only","D. None, they are all relevant considerations.274 Chapter 11 ■ Planning Storage in the Cloud"],"answer":"15. D. In addition to read and write patterns, cost, and consistency, you should consider trans-action support and latency, which makes option D correct."},{"index":16,"questions":"16. What is the maximum size of a Memorystore cache?","choices":["A. 100GB","B. 300GB","C. 400GB","D. 50GB"],"answer":"16. B. Option B is correct because Memorystore can be configured to use between 1GB and300GB of memory."},{"index":17,"questions":"17. Once a bucket has its storage class set to coldline, what are other storage classes it can transition to?","choices":["A. Regional","B. Nearline","C. Multi-regional","D. None of the above"],"answer":"17. D. Once a bucket is set to coldline, it cannot be changed to another storage class; thus,option D is correct. Regional and multiregional can change to nearline and coldline.Nearline buckets can change to coldline."},{"index":18,"questions":"18. Before you can start storing data in BigQuery, what must you create?","choices":["A. A data set","B. A bucket","C. A persistent disk","D. An entity"],"answer":"18. A. To use BigQuery to store data, you must have a data set to store it, which makes optionA the right answer. Buckets are used by Cloud Storage, not BigQuery. You do not managepersistent disks when using BigQuery. An entity is a data structure in Datastore, not Big-Query."},{"index":19,"questions":"19. What features can you configure when running a Second Generation MySQL database in Cloud SQL?","choices":["A. Machine type","B. Maintenance windows","C. Failover replicas","D. All of the above"],"answer":"19. D. With a second-generation instance, you can configure the MySQL version, connectivity,machine type, automatic backups, failover replicas, database flags, maintenance windows,and labels, so option D is correct."},{"index":20,"questions":"20. A colleague is wondering why some storage charges are so high. They explain that they have moved all their storage to nearline and coldline storage. They routinely access most of the object on any given day. What is one possible reason the storage costs are higher than expected?","choices":["A. Nearline and coldline incur access charges.","B. Transfer charges.","C. Multiregional coldline is more expensive.","D. Regional coldline is more expensive. Review Questions 305 Review Questions You can find the answers in the Appendix."],"answer":"20. A. Access charges are used with nearline and coldline storage, which makes option A cor-rect. There is no transfer charge involved. Options C and D do not refer to actual storageclasses.Chapter 12: Deploying Storage inGoogle Cloud Platform"}],"12":[{"index":1,"questions":"1. Cloud SQL is a fully managed relational database service, but database administrators still have to perform some tasks. Which of the following tasks do Cloud SQL users need to perform?","choices":["A. Applying security patches","B. Performing regularly scheduled backups","C. Creating databases","D. Tuning the operating system to optimize Cloud SQL performance"],"answer":"1. C. Creating databases is the responsibility of database administrators or other users ofCloud SQL, so option C is correct. Google applies security patches and performs othermaintenance, so option A is incorrect. GCP performs regularly scheduled backups, sooption B is incorrect. Database administrators need to schedule backups, but GCP makessure they are performed on schedule. Cloud SQL users can’t SSH into a Cloud SQL server,so they can’t tune the operating system. That’s not a problem; Google takes care of that.488 Appendix ■ Answers to Review Questions"},{"index":2,"questions":"2. Which of the following commands is used to create a backup of a Cloud SQL database?","choices":["A. gcloud sql backups create","B. gsutil sql backups create","C. gcloud sql create backups","D. gcloud sql backups export"],"answer":"2. A. Cloud SQL is controlled using the gcloudcommand; the sequence of terms in gcloudcommands is gcloudfollowed by the service, in this case SQL; followed by a resource, inthis case backups , and a command or verb, in this case create . Option A is the correctanswer. Option B is incorrect because gsutilis used to work with Cloud Storage, notCloud SQL. Option C is wrong because the order of terms is incorrect; backupscomesbefore create . Option D is incorrect because the command or verb should be create ."},{"index":3,"questions":"3. Which of the following commands will run an automatic backup at 3:00 a.m. on an instance called ace-exam-mysq?l","choices":["A. gcloud sql instances patch ace-exam-mysql --backup-start-time 03:00","B. gcloud sql databases patch ace-exam-mysql –-backup-start-time 03:00","C. cbt sql instances patch ace-exam-mysql -–backup-start-time 03:00","D. bq gcloud sql instances patch ace-exam-mysql -–backup-start-time 03:00"],"answer":"3. A. Option A is the correct answer. The base command is gcloud sql instances pat ,chwhich is followed by the instance name and a start time passed to the –-backup-start-timeparameter. Option B is incorrect because databasesis not the correct resource to refer-ence; instancesis. Option C uses the cbtcommand, which is for use with Bigtable, so it isincorrect. Similarly, Option D is incorrect because it uses the bqcommand, which is used tomanage BigQuery resources."},{"index":4,"questions":"4. What is the query language used by Datastore?","choices":["A. SQL","B. MDX","C. GQL","D. DataFrames"],"answer":"4. C. Datastore uses a SQL-like query language called GQL, so option C is correct. OptionA is incorrect; SQL is not used with this database. Option B is incorrect; MDX is a querylanguage for online analytic processing (OLAP) systems. Option D is incorrect becauseDataFrames is a data structure used in Spark."},{"index":5,"questions":"5. What is the correct command-line structure to export data from Datastore?","choices":["A. gcloud datastore export '[NAMESPACE]' gs://[BUCKET_NAME]","B. gcloud datastore export gs://[BUCKET_NAME]","C. gcloud datastore export --namespaces='[NAMESPACE]' gs://[BUCKET_NAME]","D. gcloud datastore dump --namespaces='[NAMESPACE]' gs://[BUCKET_NAME]306 Chapter 12 ■ Deploying Storage in Google Cloud Platform"],"answer":"5. C. Option C is the correct command. It has the correct base command, gcloud datastoreexport , followed by the --namespaces parameter and the name of a Cloud Storage bucketto hold the export file. Option A is incorrect because the --namespaces parameter nameis missing. Option B is incorrect because it is missing a namespace. Option D is incorrectbecause it uses the command or verb dumpinstead of export ."},{"index":6,"questions":"6. When you enter a query into the BigQuery query form, BigQuery analyzes the query and displays an estimate of what metric?","choices":["A. Time required to enter the query","B. Cost of the query","C. Amount of data scanned","D. Number of bytes passed between servers in the BigQuery cluster"],"answer":"6. C. Option C is correct; BigQuery displays an estimate of the amount of data scanned. Thisis important because BigQuery charges for data scanned in queries. Option A is incorrect;knowing how long it took you to enter a query is not helpful. Option B is incorrect; youneed to use the scanned data estimate with the Pricing Calculator to get an estimate cost.Option D is incorrect; you do not create clusters in BigQuery as you do with Bigtable andDataproc. Network I/O data is not displayed."},{"index":7,"questions":"7. You want to get an estimate of the volume of data scanned by BigQuery from the command line. Which option shows the command structure you should use?","choices":["A. gcloud BigQuery query estimate [SQL_QUERY]","B. bq ––location=[LOCATION] query --use_legacy_sql=fa –ldsey_run [SQL_QUERY]","C. gsutil –– location=[LOCATION] query --use_legacy_sql=fa ––sey_run [SQL_QUERY]","D. cbt BigQuery query estimate [SQL_QUERY]"],"answer":"7. B. Option B shows the correct bqcommand structure, which includes locationand the––dry_runoption. This option calculates an estimate without actually running the query.Options A and C are incorrect because they use the wrong command; gcloudand gsutilare not used with BigQuery. Option D is also wrong. cbtis a tool for working with Big-table, not BigQuery. Be careful not to confuse the two because their names are similar."},{"index":8,"questions":"8. You are using Cloud Console and want to check on some jobs running in BigQuery. You navigate to the BigQuery part of the console. Which menu item would you click to view jobs?","choices":["A. Job History.","B. Active Jobs.","C. My Jobs.","D. You can’t view job status in the console; you have to use bqon the command line."],"answer":"8. A. Option A is correct; the menu option is Job History. Options B and C are incorrect;there is no Active Jobs or My Jobs option. Job History shows active jobs, completed jobs,and jobs that generated errors. Option D is incorrect; you can get job status in the console."},{"index":9,"questions":"9. You want to estimate the cost of running a BigQuery query. What two services within Google Cloud Platform will you need to use?","choices":["A. BigQuery and Billing","B. Billing and Pricing Calculator","C. BigQuery and Pricing Calculator","D. Billing and Pricing Calculator"],"answer":"9. C. BigQuery provides an estimate of the amount of data scanned, and the Pricing Calculatorgives a cost estimate for scanning that volume of data. Options A, B, and C are incorrect;the Billing service tracks charges incurred. It is not used to estimate future or potentialcharges. Chapter 12: Deploying Storage in Google Cloud Platform 489"},{"index":10,"questions":"10. You have just created a Cloud Spanner instance. You have been tasked with creating a way to store data about a product catalog. What is the next step after creating a Cloud Spanner instance that you would perform to enable you to load data?","choices":["A. Run gcloud spanner update-security-patc . hes","B. Create a database within the instance.","C. Create tables to hold the data.","D. Use the Cloud Spanner console to import data into tables created with the instance. Review Questions 307"],"answer":"10. B. Option B is correct; the next step is to create a database within the instance. Once adatabase is created, tables can be created, and data can be loaded into tables. Option Ais incorrect; Cloud Spanner is a managed database, so you do not need to apply securitypatches. Option C is incorrect because you can’t create tables without first having created adatabase. Option D is incorrect; no tables are created that you could import data into whenan instance is created."},{"index":11,"questions":"11. You have created a Cloud Spanner instance and database. According to Google best practices, how often should you update VM packages using apt-get ?","choices":["A. Every 24 hours.","B. Every 7 days.","C. Every 30 days.","D. Never, Cloud Spanner is a managed service."],"answer":"11. D. Option D is correct because there is no need to apply patches to the underlying computeresources when using Cloud Spanner. because Google manages resources used by CloudSpanner. Updating packages is a good practice when using VMs, for example, withCompute Engine, but it is not necessary with a managed service."},{"index":12,"questions":"12. Your software team is developing a distributed application and wants to send messages from one application to another. Once the consuming application reads a message, it should be deleted. You want your system to be robust to failure, so messages should be available for at least three days before they are discarded. Which GCP service is best designed to support this use case?","choices":["A. Bigtable","B. Dataproc","C. Cloud Pub/Sub","D. Cloud Spanner"],"answer":"12. C. This use case is well suited to Pub/Sub, so option C is correct. It involves sendingmessages to the topic, and the subscription model is a good fit. Pub/Sub has a retentionperiod to support the three-day retention period. Option A is incorrect; Bigtable is designedfor storing large volumes of data. Dataproc is for processing and analyzing data, notpassing it between systems. Cloud Spanner is a global relational database. You could designan application to meet this use case, but it would require substantial development and becostly to run."},{"index":13,"questions":"13. Your manager asks you to set up a bare-bones Pub/Sub system as a sandbox for new devel- opers to learn about messaging systems. What are the two resources within Pub/Sub you will need to create?","choices":["A. Topics and tables","B. Topics and databases","C. Topics and subscriptions","D. Tables and subscriptions"],"answer":"13. C. Pub/Sub works with topics, which receive and hold messages, and subscriptions, whichmake messages available to consuming applications; therefore, option C is correct. OptionA is incorrect; tables are data structures in relational databases, not message queues.Similarly, option B is wrong because databases exist in instances of database managementsystems, not messaging systems. Option D is wrong because tables are not a resource inmessaging systems."},{"index":14,"questions":"14. Your company is launching an IoT service and will receive large volumes of streaming data. You have to store this data in Bigtable. You want to explore the Bigtable environment from the command line. What command would you run to ensure you have command-line tools installed?","choices":["A. apt-get install bigtable-tools","B. apt-get install cbt","C. gcloud components install cbt","D. gcloud components install bigtable-tools"],"answer":"14. C. The correct command is gcloud components install ctb otinstall the Bigtablecommand-line tool, so option C is correct. Options A and B are incorrect; apt-getis usedto install packages on some Linux systems but is not specific to GCP. Option D is incorrect;there is no such command as bigtable-tool.s"},{"index":15,"questions":"15. You need to create a table called iot-ingest-datn Bigtable. What command would you use?","choices":["A. cbt createtable iot-ingest-data","B. gcloud bigtable tables create ace-exam-bt-table","C. gcloud bigtable create tables ace-exam-bt-table","D. gcloud create ace-exam-bt-table308 Chapter 12 ■Deploying Storage in Google Cloud Platform"],"answer":"15. A. You would need to use a cbtcommand, which is the command-line tool for workingwith Bigtable, so option A is correct. All other options reference gcloudand are thereforeincorrect."},{"index":16,"questions":"16. Cloud Dataproc is a managed service for which two big data platforms?","choices":["A. Spark and Cassandra","B. Spark and Hadoop","C. Hadoop and Cassandra","D. Spark and TensorFlow"],"answer":"16. B. Cloud Dataproc is a managed service for Spark and Hadoop, so option B is correct.Cassandra is a big data distributed database but is not offered as a managed service byGoogle, so options A and C are incorrect. Option D is incorrect because TensorFlow is adeep learning platform not included in Dataproc."},{"index":17,"questions":"17. Your department has been asked to analyze large batches of data every night. The jobs will run for about three to four hours. You want to shut down resources as soon as the analysis is done, so you decide to write a script to create a Dataproc cluster every night at midnight. What command would you use to create a cluster called spark-nightly-analysisthe us-west2-a zon?e","choices":["A. bq dataproc clusters create spark-nightly-anal ysisne us-west2-a","B. gcloud dataproc clusters create spark-nightly-anal ––zone us-west2-a","C. gcloud dataproc clusters spark-nightly-analy –szisne us-west2-a","D. None of the above"],"answer":"17. B. The correct command is gcloud dataproc clusters crea ftllowed by the name ofthe cluster and the a --zoneparameter. Option B is correct. Option A is incorrect becausebqis the command-line tool for BigQuery, not Dataproc. Option C is a gcloudcommandmissing a verb or command, so it is incorrect. Option D is wrong because option B is thecorrect answer. ■490 Appendix Answers to Review Questions"},{"index":18,"questions":"18. You have a number of buckets containing old data that is hardly ever used. You don’t want to delete it, but you want to minimize the cost of storing it. You decide to change the storage class to coldline for each of those buckets. What is the command structure that you would use?","choices":["A. gcloud rewrite -s [STORAGE_CLASS] gs://[PATH_TO_OBJECT]","B. gsutil rewrite -s [STORAGE_CLASS] gs://[PATH_TO_OBJECT]","C. cbt rewrite -s [STORAGE_CLASS] gs://[PATH_TO_OBJECT]","D. bq rewrite -s [STORAGE_CLASS] gs://[PATH_TO_OBJECT]"],"answer":"18. B. gsutilis the correct command, so option B is correct. Option A is incorrect becausegcloudcommands are not used to manage Cloud Storage. Similarly, options C and D areincorrect because they use commands for Bigtable and BigQuery, respectively."},{"index":19,"questions":"19. You want to rename an object stored in a bucket. What command structure would you use?","choices":["A. gsutil cp gs://[BUCKET_NAME]/[OLD_OBJECT_NAME] gs://[BUCKET_NAME]/ [NEW_OBJECT_NAME]","B. gsutil mv gs://[BUCKET_NAME]/[OLD_OBJECT_NAME] gs://[BUCKET_NAME]/ [NEW_OBJECT_NAME]","C. gsutil mv gs://[OLD_OBJECT_NAME] gs://[NEW_OBJECT_NAME]","D. gcloud mv gs://[OLD_OBJECT_NAME] gs://[NEW_OBJECT_NAME]"],"answer":"19. B. The command in option B correctly renames an object from an old name to a newname. Option A is incorrect because it uses a cpcommand instead of mv. Option C doesnot include bucket names, so it is incorrect. Option D uses gcloud , but gsutilis the com-mand-line tool for working with Cloud Storage."},{"index":20,"questions":"20. An executive in your company emails you asking about creating a recommendation system that will help sell more products. The executive has heard there are some GCP solutions that may be good fits for this problem. What GCP service would you recommend the executive look into?","choices":["A. Cloud Dataproc, especially Spark and its machine learning library","B. Cloud Dataproc, especially Hadoop","C. Cloud Spanner, which is a global relational database that can hold a lot of data","D. Cloud SQL, because SQL is a powerful query language Review Questions 333 Review Questions You can find the answers in the Appendix."],"answer":"20. A. Dataproc with Spark and its machine learning library are ideal for this use case, sooption A is correct. Option B suggests Hadoop, but it is not a good choice for machinelearning applications. Option C is incorrect because Spanner is designed as a global rela-tional database with support for transaction processing systems, not analytic and machinelearning systems. Option D is incorrect. SQL is a powerful query language, but it does notsupport the kinds of machine learning algorithms needed to solve the proposed problem.Chapter 13: Loading Data into Storage"}],"13":[{"index":1,"questions":"1. Which of the following commands is used to create buckets in Cloud Storage?","choices":["A. gcloud storage buckets create","B. gsutil storage buckets create","C. gsutil mb","D. gcloud mb"],"answer":"1. C. gsutilis the command-line utility for working with Cloud Storage. It is one of the fewGCP services that does not use gcloud . (BigQuery and Bigtable are others.) Option C isthe correct answer because mb, short for “make bucket,” is the verb that follows gsutiltocreate a bucket. Options A and D are wrong because they use gcloudinstead of gsutil .Option B is wrong because it uses gsutilwith a command syntax used by gcloud ."},{"index":2,"questions":"2. You need to copy files from your local device to a bucket in Cloud Storage. What command would you use? Assume you have Cloud SDK installed on your local computer.","choices":["A. gsutil copy","B. gsutil cp","C. gcloud cp","D. gcloud storage objects copy"],"answer":"2. B. The correct answer is option B; gsutilis the command to copy files to Cloud Storage.Option A is incorrect; the verb is cp, not copy. Options C and D are wrong because gsutil ,not gcloud , is the command-line utility for working with Cloud Storage."},{"index":3,"questions":"3. You are migrating a large number of files from a local storage system to Cloud Storage. You want to use the Cloud Console instead of writing a script. Which of the following Cloud Storage operations can you perform in the console?","choices":["A. Upload files only","B. Upload folders only","C. Upload files and folders","D. Compare local files with files in the bucket using the diffcommand"],"answer":"3. C. From the console, you can upload both files and folders. Options A and B are incorrectbecause they are missing an operation that can be performed in the console. Option D isincorrect because there is no diffoperation in Cloud Console."},{"index":4,"questions":"4. A software developer asks for your help exporting data from a Cloud SQL database. The developer tells you which database to export and which bucket to store the export file in, but hasn’t mentioned which file format should be used for the export file. What are the options for the export file format?","choices":["A. CSV and XML","B. CSV and JSON","C. JSON and SQL","D. CSV and SQL"],"answer":"4. D. When exporting a database from Cloud SQL, the export file format options are CSVand SQL, which makes option D correct. Option A is incorrect because XML is not anoption. Options B and C are incorrect because JSON is not an option."},{"index":5,"questions":"5. A database administrator has asked for an export of a MySQL database in Cloud SQL. The database administrator will load the data into another relational database and would to do it with the least amount of work. Specifically, the loading method should not require the data- base administrator to define a schema. What file format would you recommend for this task?","choices":["A. SQL","B. CSV","C. XML","D. JSON334 Chapter 13 ■ Loading Data into Storage"],"answer":"5. A. Option A, SQL format, exports a database as a series of SQL data definition commands.These commands can be executed in another relational database without having to first cre-ate a schema. Option B could be used, but that would require mapping columns to columnsin a schema that was created before loading the CSV, and the database administrator wouldlike to avoid that. Options C and D are incorrect because they are not export file formatoptions."},{"index":6,"questions":"6. Which command will export a MySQL database called ace-exam-mysqlt1o a file called ace-exam-mysql-export.siqnla bucket named ace-exam-buckete ?1","choices":["A. gcloud storage export sql ace-exam-mysql1 gs://ace-exam-buckete1/ace- exam-mysql-export.sql \\ ––database=mysql","B. gcloud sql export ace-exam-mysql1 gs://ace-exam-buckete1/ace-exam- mysql-export.sql \\ ––database=mysql","C. gcloud sql export sql ace-exam-mysql1 gs://ace-exam-buckete1/ace-exam- mysql-export.sql \\ ––database=mysql","D. gcloud sql export sql ace-exam-mysql1 gs://ace-exam-mysql-export.sql/ ace-exam-buckete1/ \\ ––database=mysql"],"answer":"6. C. Option C is the correct command, gcloud sql export s,qil ndicating that the service isCloud SQL, the operation is export, and the export file format is SQL. The filename and tar-get bucket are correctly formed. Option A is incorrect because it references gcloud storag,enot gcloud sq.lOption B is incorrect because it is missing an export file format parameter.Option D is incorrect because the bucket name and filename are in the wrong order. Chapter 13: Loading Data into Storage 491"},{"index":7,"questions":"7. As part of a compliance regimen, your team is required to back up data from your Datastore database to an object storage system. Your data is stored in the default namespace. What command would you use to export the default namespace from Datastore to a bucket called ace-exam-bucket ?1","choices":["A. gcloud datastore export ––namespaces=\"(default)\" gs://ace-exam-bucket1","B. gcloud datastore export ––namespaces=\"(default)\" ace-exam-bucket1","C. gcloud datastore dump ––namespaces=\"(default)\" gs://ace-exam-bucket1","D. gcloud datastore dump ––namespaces=\"(default)\" ace-exam-bucket1"],"answer":"7. A. Option A uses the correct command, which is gcloud datastore expor ftllowed bya namespace and a bucket name. Option B is incorrect because the bucket name is miss-ing gs://. Options C and D are incorrect because they use the command dumpinstead ofexport . The bucket name in option D is missing gs://."},{"index":8,"questions":"8. As required by your company’s policy, you need to back up your Datastore database at least once per day. An auditor is questioning whether or not Datastore export is sufficient. You explain that the Datastore export command produces what outputs?","choices":["A. A single entity file","B. A metadata file","C. A metadata file and a folder with the data","D. A metadata file, an entity file, and a folder with the data"],"answer":"8. C. The export process creates a metadata file with information about the data exportedand a folder that has the data itself, so option C is correct. Option A is incorrect becauseexport does not produce a single file; it produces a metadata file and a folder with the data.Option B is incorrect because it does not include the data folder. Option D is incorrectbecause the correct answer is option C."},{"index":9,"questions":"9. Which of the following file formats is not an option for an export file when exporting from BigQuery?","choices":["A. CSV","B. XML","C. Avro","D. JSON"],"answer":"9. B. Option B is correct because XML is not an option in BigQuery’s export process. Allother options are available."},{"index":10,"questions":"10. Which of the following file formats is not supported when importing data into BigQuery?","choices":["A. CSV","B. Parquet","C. Avro","D. YAML Review Questions 335"],"answer":"10. D. Option D is correct because YAML is not a file storage format; it used for specifyingconfiguration data. Options A, B, and C are all supported import file types."},{"index":11,"questions":"11. You have received a large data set from an Internet of Things (IoT) system. You want to use BigQuery to analyze the data. What command-line command would you use to make data available for analysis in BigQuery?","choices":["A. bq load ––autodetect ––source_format=[FORMAT] [DATASET].[TABLE] [PATH_TO_SOURCE]","B. bq import ––autodetect ––source_format=[FORMAT] [DATASET].[TABLE] [PATH_TO_SOURCE]","C. gloud BigQuery load ––autodetect ––source_format=[FORMAT] [DATASET]. [TABLE] [PATH_TO_SOURCE]","D. gcloud BigQuery load ––autodetect ––source_format=[FORMAT] [DATASET]. [TABLE] [PATH_TO_SOURCE]"],"answer":"11. A. The correct command is bqload in option A. The autodetectand source_formatparameters and path to source are correctly specified in all options. Option B is incorrectbecause it uses the term importinstead of load. Options C and D are incorrect becausethey use gcloudinstead of bq."},{"index":12,"questions":"12. You have set up a Cloud Spanner process to export data to Cloud Storage. You notice that each time the process runs you incur charges for another GCP service, which you think is related to the export process. What other GCP service might be incurring charges during the Cloud Spanner export?","choices":["A. Dataproc","B. Dataflow","C. Datastore","D. bq"],"answer":"12. B. The correct answer is B because Dataflow is a pipeline service for processing streamingand batch data that implements workflows used by Cloud Spanner. Option A is incorrect;Dataproc is a managed Hadoop and Spark service, which is used for data analysis. OptionC is incorrect; Datastore is a NoSQL database. Option D is incorrect because bqis usedwith BigQuery only."},{"index":13,"questions":"13. As a developer on a project using Bigtable for an IoT application, you will need to export data from Bigtable to make some data available for analysis with another tool. What would you use to export the data, assuming you want to minimize the amount of effort required on your part?","choices":["A. A Java program designed for importing and exporting data from Bigtable","B. gcloud bigtable table export","C. bq bigtable table export","D. An import tool provided by the analysis tool"],"answer":"13. A. Bigtable data is exported using a compiled Java program, so option A is correct. OptionB is incorrect; there is no gcloudBigtable command. Option C is incorrect; bqis not usedwith Bigtable. Option D is incorrect because it does not export data from Bigtable."},{"index":14,"questions":"14. You have just exported from a Dataproc cluster. What have you exported?","choices":["A. Data in Spark DataFrames","B. All tables in the Spark database","C. Configuration data about the cluster","D. All tables in the Hadoop database"],"answer":"14. C. Exporting from Dataproc exports data about the cluster configuration, which makesoption C correct. Option A is incorrect; data in DataFrames is not exported. Option B isincorrect; Spark does not have tables for persistently storing data like relational databases.Option D is incorrect; no data from Hadoop is exported."},{"index":15,"questions":"15. A team of data scientists has requested access to data stored in Bigtable so that they can train machine learning models. They explain that Bigtable does not have the features required to build machine learning models. Which of the following GCP services are they most likely to use to build machine learning models?","choices":["A. Datastore","B. Dataflow","C. Dataproc","D. DataAnalyze336 Chapter 13 ■Loading Data into Storage"],"answer":"15. C. The correct answer is option C; the service Dataproc supports Apache Spark, whichhas libraries for machine learning. Options A and B are incorrect, neither is an analysis ormachine learning service. Option D, DataAnalyze, is not an actual service."},{"index":16,"questions":"16. The correct command to create a Pub/Sub topic is which of the following?","choices":["A. gcloud pubsub topics create","B. gcloud pubsub create topics","C. bq pubsub create topics","D. cbt pubsub topics create"],"answer":"16. A. The correct command in option A uses gcloudfollowed by the service, in this casepubsub , followed by the resource, in this case topics ; and finally the verb, in this casecreate . Option B is incorrect because the last two terms are out of order. Options C andD are incorrect because they do not use gcloud . bqis the command-line tool for BigQuery.cbtis the command-line tool for Bigtable."},{"index":17,"questions":"17. Which of the following commands will create a subscription on the topic ace-exam-topic?1","choices":["A. gcloud pubsub create ––topic=ace-exam-topic1 ace-exam-sub1","B. gcloud pubsub subscriptions create ––topic=ace-exam-topic1","C. gcloud pubsub subscriptions create ––topic=ace-exam-topic1 ace-exam-sub1","D. gsutil pubsub subscriptions create ––topic=ace-exam-topic1 ace-exam-sub1"],"answer":"17. C. The correct answer, option C, uses gcloud pubsub subscriptions crea fotlowedby the topic and the name of the subscription. Option A is incorrect because it is missingthe term subscription.sOption B is incorrect because it is missing the name of the sub-scription. Option D is incorrect because it uses gsutilinstead of gcloud .492 Appendix ■ Answers to Review Questions"},{"index":18,"questions":"18. What is one of the direct advantages of using a message queue in distributed systems?","choices":["A. It increases security.","B. It decouples services, so if one lags, it does not cause other services to lag.","C. It supports more programming languages.","D. It stores messages until they are read by default."],"answer":"18. B. Using a message queue between services decouples the services, so if one lags it does notcause other services to lag, which makes option B correct. Option A is incorrect becauseadding a message queue does not directly mitigate any security risks that might exist in thedistributed system, such as overly permissive permissions. Option C is incorrect; adding aqueue is not directly related to programming languages. Option D is incorrect; by default,message queues have a retention period."},{"index":19,"questions":"19. To ensure you have installed beta gcloudcommands, which command should you run?","choices":["A. gcloud components beta install","B. gcloud components install beta","C. gcloud commands install beta","D. gcloud commands beta install"],"answer":"19. B. The correct answer is B, gcloud componentfs ollowed by installand then beta.Option A is incorrect because betaand installare in the wrong order. Options C and Dare wrong because commandsis used instead of component.s"},{"index":20,"questions":"20. What parameter is used to tell BigQuery to automatically detect the schema of a file on import?","choices":["A. ––autodetect","B. ––autoschema","C. ––detectschema","D. ––dry_run"],"answer":"20. A. The correct parameter name is autodetec,twhich is option A. Options B and C are notactually valid bqparameters. Option D is a valid parameter, but it returns the estimatedsize of data scanned to when executing a query."},{"index":21,"questions":"21. The compression options deflate and snappy are available for what file types when exporting from BigQuery?","choices":["A. Avro","B. CSV","C. XML","D. Thrift Review Questions 357 Review Questions You can find the answers in the Appendix."],"answer":"21. A. Avro supports Deflate and Snappy compression. CSV supports Gzip and no compression.XML and Thrift are not export file type options.Chapter 14: Networking in the Cloud:Virtual Private Clouds and VirtualPrivate Networks"}],"14":[{"index":1,"questions":"1. Virtual private clouds have a scope.","choices":["A. Zonal","B. Regional","C. Super-regional","D. Global"],"answer":"1. D. Virtual private clouds are global, so option D is correct. By default, they have subnets inall regions. Resources in any region can be accessed through the VPC. Options A, B, and Care all incorrect."},{"index":2,"questions":"2. You have been tasked with defining CIDR ranges to use with a project. The project includes 2 VPCs with several subnets in each VPC. How many CIDR ranges will you need to define?","choices":["A. One for each VPC","B. One for each subnet","C. One for each region","D. One for each zone"],"answer":"2. B. IP ranges are assigned to subnets, so option B is correct. Each subnet is assigned an IPrange for its exclusive use. IP ranges are assigned network structures, not zones and regions.VPCs can have multiple subnets but each subnet has its own address range."},{"index":3,"questions":"3. The legal department needs to isolate its resources on its own VPC. You want to have network provide routing to any other service available on the global network. The VPC network has not learned global routes. What parameter may have been missed when creating the VPC subnets?","choices":["A. DNS server policy","B. Dynamic routing","C. Static routing policy","D. Systemic routing policy"],"answer":"3. B. Option B is correct; dynamic routing is the parameter that specifies whether routes arelearned regionally or globally. Option A is incorrect; DNS is a name resolution service andis not involved with routing. Option C is incorrect; there is no static routing policy param-eter. Option D is incorrect because global routing is not an actual option."},{"index":4,"questions":"4. The command to create a VPC from the command line is:","choices":["A. gcloud compute networks create","B. gcloud networks vpc create","C. gsutil networks vpc create","D. gcloud compute create networks"],"answer":"4. A. The correct answer is gcloud compute networks cre,aw thich is option A. OptionB is incorrect; networks vpc is not a correct part of the command. Option C is incorrectbecause gsutilis the command used to work with Cloud Storage. Option D is incorrectbecause there is no such thing."},{"index":5,"questions":"5. You have created several subnets. Most of them are sending logs to Stackdriver. One subnet is not sending logs. What option may have been misconfigured when creating the subnet that is not forwarding logs?","choices":["A. Flow Logs","B. Private IP Access","C. Stackdriver Logging","D. Variable-Length Subnet Masking358 Chapter 14 ■ Networking in the Cloud: Virtual Private Clouds"],"answer":"5. A. The Flow Log option of the create vpccommand determines whether logs are sentto Stackdriver, so option A is correct. Option B, Private IP Access, determines whetheran external IP address is needed by a VM to use Google services. Option C is incorrectbecause Stackdriver Logging is the service, not a parameter used when creating a sub-net. Option D is incorrect because variable-length subnet masking has to do with CIDRaddresses, not logging. Chapter 14: Networking in the Cloud Virtual Private Clouds 493"},{"index":6,"questions":"6. At what levels of the resource hierarchy can a shared VPC be created?","choices":["A. Folders and resources","B. Organizations and project","C. Organizations and folders","D. Folders and subnets"],"answer":"6. C. Shared VPCs can be created at the organization or folder level of the resource hierarchy,so option C is correct. Options A and B are incorrect; shared VPCs are not created at theresource or project levels. Option D is incorrect; shared VPCs are not applied at subnets,which are resources in the resource hierarchy."},{"index":7,"questions":"7. You are using Cloud Console to create a VM that you want to exist in a custom subnet you just created. What section of the Create Instance form would you use to specify the custom subnet?","choices":["A. Networking tab of the Management, Security, Disks, Networking, Sole Tenancy section","B. Management tab of the Management, Security, Disks, Networking, Sole Tenancy section","C. Sole Tenancy tab of Management, Security, Disks, Networking, Sole Tenancy","D. Sole Tenancy tab of Management, Security, Disks, Networking"],"answer":"7. A. The correct answer is the Networking tab of the Management, Security, Disks, Net-working, Sole Tenancy section of the form, which makes option A correct. The Manage-ment tab is not about subnet configurations. Option D is incorrect because it does not leadto Sole Tenancy options."},{"index":8,"questions":"8. You want to implement interproject communication between VPCs. Which feature of VPCs would you use to implement this?","choices":["A. VPC peering","B. Interproject peering","C. VPN","D. Interconnect"],"answer":"8. A. VPC is used for interproject communications. Option B is incorrect; there is no inter-project peering. Options C and D are incorrect; they have to do with linking on-premisenetworks with networks in GCP."},{"index":9,"questions":"9. You want to limit traffic to a set of instances. You decide to set a specific network tag on each instance. What part of a firewall rule can reference the network tag to determine the set of instances affected by the rule?","choices":["A. Action","B. Target","C. Priority","D. Direction"],"answer":"9. B. The target can be all instances in a network, instances with particular network tags,or instances using a specific service account, so option B is correct. Option A is incorrect;action is either allow or deny. Option C is incorrect; priority determines which of all thematching rules is applied. Option D is incorrect; it specifies whether the rule is applied toincoming or outgoing traffic."},{"index":10,"questions":"10. What part of a firewall rule determines whether a rule applies to incoming or outgoing traffic?","choices":["A. Action","B. Target","C. Priority","D. Direction"],"answer":"10. D. Direction specifies whether the rule is applied to incoming or outgoing traffic, whichmakes option D the right answer. Option A is incorrect; action is either allow or deny.Option B is incorrect; target specifies the set of instances that the rule applies to. Option Cis incorrect; priority determines which of all matching rules is applied."},{"index":11,"questions":"11. You want to define a CIDR range that applies to all destination addresses. What IP address would you specify?","choices":["A. 0.0.0.0/0","B. 10.0.0.0/8","C. 172.16.0.0/12","D. 192.168.0.0/16 Review Questions 359"],"answer":"11. A. The 0.0.0.0/0 matches all IP addresses, so option A is correct. Option B represents ablock of 16,777,214 addresses. Option C represents a block of 1,048,574 addresses. OptionD represents a block of 65,534. You can experiment with CIDR block options using aCIDR calculator such as the one at www.subnet-calculator.com/cidr..php"},{"index":12,"questions":"12. You are using gcloudto create a firewall rule. Which command would you use?","choices":["A. gcloud network firewall-rules create","B. gcloud compute firewall-rules create","C. gcloud network rules create","D. gcloud compute rules create"],"answer":"12. B. The product you are working with is compute and the resource you are creating is a fire-wall rule, so option B is correct. Options A and C references network instead of compute.Option D references rulesinstead of firewall-rule.s"},{"index":13,"questions":"13. You are using gcloudto create a firewall rule. Which parameter would you use to specify the subnet it should apply to?","choices":["A. ––subnet","B. ––network","C. ––destination","D. ––source-ranges"],"answer":"13. B. The correct parameter is network , which makes option B correct. Option A is incorrect;subnetis not a parameter to gcloudto create a firewall. Option C is incorrect; desti-nationis not a valid parameter. Option D is incorrect; source-ranges is for specifyingsources of network traffic the rule applies to."},{"index":14,"questions":"14. An application development team is deploying a set of specialized service endpoints and wants to limit traffic so that only traffic going to one of the endpoints is allowed through by firewall rules. The service endpoints will accept any UDP traffic and each endpoint will use a port in the range of 20000–30000. Which of the following commands would you use?","choices":["A. gcloud compute firewall-rules create fwr1 --allow=udp:20000-30000 --direction=ingress","B. gcloud network firewall-rules create fwr1 --allow=udp:20000-30000 --direction=ingress","C. gcloud compute firewall-rules create fwr1 --allow=udp","D. gcloud compute firewall-rules create fwr1 --direction=ingress"],"answer":"14. A. The rule in option A uses the correct gcloudcommand and specifies the allowanddirectionparameters. Option B is incorrect because it references gcloud network insteadof gcloud comput.eOption C is incorrect because it does not specify the port range. Option Dis incorrect because it does not specify the protocol or port range."},{"index":15,"questions":"15. You have a rule to allow inbound traffic to a VM. You want it to apply only if there is not another rule that would deny that traffic. What priority should you give this rule?","choices":["A. 0","B. 1","C. 1000","D. 65535"],"answer":"15. D. Option D is correct because it is the largest number allowed in the range of values forpriorities. The larger the number, the lower the priority. Having the lowest priority willensure that other rules that match will apply."},{"index":16,"questions":"16. You want to create a VPN using Cloud Console. What section of Cloud Console should you use?","choices":["A. Compute Engine","B. App Engine","C. Hybrid Connectivity","D. IAM & Admin360 Chapter 14 ■ Networking in the Cloud: Virtual Private Clouds"],"answer":"16. C. The VPC create option is available in the Hybrid Connectivity section, so option C is cor-rect. Compute Engine, App Engine, and IAM & Admin do not have features related to VPNs.494 Appendix ■ Answers to Review Questions"},{"index":17,"questions":"17. You are using Cloud Console to create a VPN. You want to configure the GCP end of the VPN. What section of the Create VPN form would you use?","choices":["A. Tunnels","B. Routing Options","C. Google Compute Engine VPN","D. IKE Version"],"answer":"17. C. The Google Compute Engine VPN is where you specify information about the GoogleCloud end of the VPN connection, so option C is correct. You specify name, descrip-tion, network, region, and IP address. Option A is incorrect because tunnels are about theconnections between the cloud and the remote network. Option B is incorrect; RoutingOptions is about how to configure routers. Option D is incorrect; IKE Version is aboutexchanging secret keys."},{"index":18,"questions":"18. You want the router on a tunnel you are creating to learn routes from all GCP regions on the network. What feature of GCP routing would you enable?","choices":["A. Global dynamic routing","B. Regional routing","C. VPC","D. Firewall rules"],"answer":"18. A. Option A is correct because global dynamic routing is used to learn all routes on a net-work. Option B is incorrect; regional routing would learn only routes in a region. OptionsC and D are incorrect because they are not used to configure routing options."},{"index":19,"questions":"19. When you create a cloud router, what kind of unique identifier do you need to assign for the BGP protocol?","choices":["A. IP address","B. ASN","C. Dynamic load routing ID","D. None of the above"],"answer":"19. B. The autonomous system number (ASN) is a number used to identify a cloud router on anetwork, so option B is correct. IP addresses are not unique identifiers for the BGP protocol.Option C is incorrect; there is no dynamic load routing ID. Option D is incorrect becauseoption B is correct."},{"index":20,"questions":"20. You are using gcloudto create a VPN. Which command would you use?","choices":["A. gcloud compute target-vpn-gateways only","B. gcloud compute forwarding-rule and gcloud compute target-vpn-gateways only","C. gcloud compute vpn-tunnels only","D. gcloud compute forwarding-rule, gcloud compute target-vpn-gateways, and gcloud compute vpn-tunnels Review Questions 379 Review Questions You can find the answers in the Appendix."],"answer":"20. D. When using gcloudto create a VPN, you need to create forwarding rules, tunnels, andgateways, so all the gcloudcommands listed would be used.Chapter 15: Networking in the Cloud:DNS, Load Balancing, and IP Addressing"}],"15":[{"index":1,"questions":"1. What record type is used to specify the IPv4 address of a domain?","choices":["A. AAAA","B. A","C. NS","D. SOA"],"answer":"1. B. The A record is used to map a domain name to an IPv4 address, so option B is correct.Option A is incorrect because the AAAA record is used for IPv6 addresses. Option C isincorrect; NS is a name server record. Option D is incorrect; SOA is a start of authorityrecord."},{"index":2,"questions":"2. The CEO of your startup just read a news report about a company that was attacked by something called cache poisoning. The CEO wants to implement additional security measures to reduce the risk of DNS spoofing and cache poisoning. What would you recommend?","choices":["A. Using DNSSEC","B. Adding SOA records","C. Adding CNAME records","D. Deleting CNAME records"],"answer":"2. A. DNSSEC is a secure protocol designed to prevent spoofing and cache poisoning, sooption A is correct. Options B and C are incorrect because SOA and CNAME records con-tain data about the DNS record; they are not an additional security measure. Option D isincorrect because deleting a CNAME record does not improve security."},{"index":3,"questions":"3. What do the TTL parameters specify in a DNS record?","choices":["A. Time a record can exist in a cache before it should be queried again","B. Time a client has to respond to a request for DNS information","C. Time allowed to create a CNAME record","D. Time before a human has to manually verify the information in the DNS record"],"answer":"3. A. The TTL parameters specify the time a record can be in a cache before the data shouldbe queried again, so option A is correct. Option B is incorrect; this time period is notrelated to timeouts. Option C is incorrect; the TTLs are not related to time restriction ondata change operations. Option D is not correct; there is no manual review required."},{"index":4,"questions":"4. What command is used to create a DNS zone in the command line?","choices":["A. gsutil dns managed-zones create","B. gcloud beta dns managed-zones create","C. gcloud beta managed-zones create","D. gcloud beta dns create managed zones"],"answer":"4. B. The correct answer, Option B, is gcloud beta dns managed-zones create. Option A isincorrect, it uses the gsutil command which is used to work with Cloud Storage. Option C isincorrect, it is missing the term dns. Option D is incorrect, the ordering of terms is incorrect."},{"index":5,"questions":"5. What parameter is used to make a DNS zone private?","choices":["A. --private","B. --visibility=private","C. --private=true","D. --status=private380 Chapter 15 ■ Networking in the Cloud: DNS, Load Balancing, and IP Addressing"],"answer":"5. B. The visibilityparameter is the parameter that can be set to private, so option B iscorrect. Option A is not a valid parameter. Option C is incorrect; private is not a parameter.Similarly, option D is incorrect; status is not a valid parameter for making a DNS zoneprivate.Chapter 15: Networking in the Cloud: DNS, Load Balancing, and IP Addressing 495"},{"index":6,"questions":"6. Which load balancers provide global load balancing?","choices":["A. HTTP(S) only","B. SSL Proxy and TCP Proxy only","C. HTTP(S), SSL Proxy, and TCP Proxy","D. Internal TCP/UDP, HTTP(S), SSL Proxy, and TCP Proxy"],"answer":"6. C. The three global load balancers are HTTP(S), SSL Proxy, and TCP Proxy, so option Cis correct. Options A and B are missing at least one global load balancer. Option D is incor-rect because Internal TCP/UD is a regional load balancer."},{"index":7,"questions":"7. Which regional load balancer allows for load balancing based on IP protocol, address, and port?","choices":["A. HTTP(S)","B. SSL Proxy","C. TCP Proxy","D. Network TCP/UDP"],"answer":"7. D. Network TCP/UDP enables balancing based on IP protocol, address, and port, sooption D is correct. Options A, B, and C are all global load balancers, not regional ones."},{"index":8,"questions":"8. You are configuring a load balancer and want to implement private load balancing. Which option would you select?","choices":["A. Only Between My VMs","B. Enable Private","C. Disable Public","D. Local Only"],"answer":"8. A. In the console there is an option to select between From Internet To My VMs and OnlyBetween My VMs. This is the option to indicate private or public, so option A is correct.Options B, C, and D are all fictitious parameters."},{"index":9,"questions":"9. What two components need to be configured when creating a TCP Proxy load balancer?","choices":["A. Frontend and forwarding rule","B. Frontend and backend","C. Forwarding rule and backend only","D. Backend and forwarding rule only"],"answer":"9. B. TCP Proxy load balancers require you to configure both the frontend and backendthe ,so option B is correct. Options A and D are incorrect because they are missing one compo-nent. Option C is incorrect; forwarding rules are the one component specified with networkload balancing. There is no component known as a traffic rule."},{"index":10,"questions":"10. A health check is used to check what resources?","choices":["A. Load balancer","B. VMs","C. Storage buckets","D. Persistent disks"],"answer":"10. B. Health checks monitor the health of VMs used with load balancers, so option B is correct.Option A is incorrect, nearline storage is a type of Cloud Storage. Option C and D areincorrect; storage devices or buckets are not health checked."},{"index":11,"questions":"11. Where do you specify the ports on a TCP Proxy load balancer that should have their traffic forwarded?","choices":["A. Backend","B. Frontend","C. Network Services section","D. VPC Review Questions 381"],"answer":"11. B. You specify ports to forward when configuring the frontend, so option B is correct. Thebackend is where you configure how traffic is routed to VMs. Option C is incorrect; Net-work Services is a high-level area of the console. Option D is incorrect; VPCs are not whereyou specify load balancer configurations."},{"index":12,"questions":"12. What command is used to create a network load balancer at the command line?","choices":["A. gcloud compute forwarding-rules create","B. gcloud network forwarding-rules create","C. gcloud compute create forwarding-rules","D. gcloud network create forwarding-rules"],"answer":"12. A. The correct answer, option A, is gcloud compute forwarding-rules cr.eateOption B is incorrect; the service should be compute , not network . Option C is incorrect;createcomes after forwarding-rule .Option D is incorrect because it has the wrongservice, and the verb is in the wrong position."},{"index":13,"questions":"13. A team is setting up a web service for internal use. They want to use the same IP address for the foreseeable future. What type of IP address would you assign?","choices":["A. Internal","B. External","C. Static","D. Ephemeral"],"answer":"13. C. Static addresses are assigned until they are released, so option C is correct. Options Aand B are incorrect because internal and external addresses determine whether traffic isrouted into and out of the subnet. External addresses can have traffic reach them from theInternet; internal addresses cannot. Option D is incorrect; ephemeral addresses are releasedwhen a VM shuts down or is deleted."},{"index":14,"questions":"14. You are starting up a VM to experiment with a new Python data science library. You’ll SSH via the server name into the VM, use the Python interpreter interactively for a while and then shut down the machine. What type of IP address would you assign to this VM?","choices":["A. Ephemeral","B. Static","C. Permanent","D. IPv8"],"answer":"14. A. An ephemeral address is sufficient, since resources outside the subnet will not needto reach the VM and you can SSH into the VM from the console, so option A is correct.Option B is incorrect because there is no need to assign a permanent address, which wouldthen have to be released. Option C is incorrect; there is no Permanent type. Option D isincorrect; there is no IPv8 address."},{"index":15,"questions":"15. You have created a subnet called sn1 using 192.168.0.0 with 65,534 addresses. You realize that you will not need that many addresses, and you’d like to reduce that number to 254. Which of the following commands would you use?","choices":["A. gcloud compute networks subnets expand-ip-range sn1 --prefix-length=24","B. gcloud compute networks subnets expand-ip-range sn1 --prefix-length=-8","C. gcloud compute networks subnets expand-ip-range sn1 --size=256","D. There is no command to reduce the number of IP addresses available."],"answer":"15. D. You cannot reduce the number of addresses using any of the commands, so option D iscorrect. Option A is incorrect because the prefix length specified in the expand-ip-rangecommand must be a number less than the current length. If there are 65,534 addresses,then the prefix length is 16. Option B is incorrect for the same reason, and the prefix lengthcannot be a negative number. Option C is incorrect; there is no ––sizeparameter.496 Appendix ■ Answers to Review Questions"},{"index":16,"questions":"16. You have created a subnet called sn1 using 192.168.0.0. You want it to have 14 addresses. What prefix length would you use?","choices":["A. 32","B. 28","C. 20","D. 16"],"answer":"16. B. The prefix length specifies the length in bits of the subnet mask. The remaining bits ofthe IP address are used for device addresses. Since there are 32 bits in an IP address, yousubtract the length of the mask to get the number of bits used to represent the address. 16 isequal to 2 , so you need 4 bits to represent 14 addresses. 32-4 is 28, so option B is the cor-rect answer. Option A would leave 1 address, option C would provide 4,094 addresses, andoption D would provide 65,534."},{"index":17,"questions":"17. You want all your network traffic to route over the Google network and not traverse the public Internet. What level of network service should you choose?","choices":["A. Standard","B. Google-only","C. Premium","D. Non-Internet382 Chapter 15 ■ Networking in the Cloud: DNS, Load Balancing, and IP Addressing"],"answer":"17. C. Premium is the network service level that routes all traffic over the Google network,so option C is correct. Option A is incorrect; the Standard tier may use the public Inter-net when routing traffic. Options B and D are incorrect; there are no service tiers calledGoogle-only or non-Internet."},{"index":18,"questions":"18. You have a website hosted on a Compute Engine VM. Users can access the website using the domain name you provided. You do some maintenance work on the VM and stop the server and restart it. Now users cannot access the website. No other changes have occurred on the subnet. What might be the cause of the problem?","choices":["A. The restart caused a change in the DNS record.","B. You used an ephemeral instead of a static IP address.","C. You do not have enough addresses available on your subnet.","D. Your subnet has changed."],"answer":"18. B. Stopping and starting a VM will release ephemeral IP addresses, so option B is correct.Use a static IP address to have the same IP address across reboots. Option A is incorrect;rebooting a VM does not change a DNS record. Option C is incorrect because if you hadenough addresses to get an address when you first started the VM and you then releasedthat IP address, there should be at least one IP address assuming no other devices are addedto the subnet. Option D is incorrect because no other changes, including changes to thesubnet, were made."},{"index":19,"questions":"19. You are deploying a distributed system. Messages will be passed between Compute Engine VMs using a reliable UDP protocol. All VMs are in the same region. You want to use the load balancer that best fits these requirements. Which kind of load balancer would you use?","choices":["A. Internal TCP/UDP","B. TCP Proxy","C. SSL Proxy","D. HTTP(S)"],"answer":"19. A. Internal TCP/UDP is a good option. It is a regional load balancer that supports UDP, sooption A is correct. Options B, C, and D are all global load balancers. Option B supportsTCP, not UDP. Option D supports HTTP and HTTPS, not UDP."},{"index":20,"questions":"20. You want to use Cloud Console to review the records in a DNS entry. What section of Cloud Console would you navigate to?","choices":["A. Compute Engine","B. Network Services","C. Kubernetes Engine","D. Hybrid Connectivity ■ 400 Chapter 16 Deploying Applications with Cloud Launcher Review Questions"],"answer":"20. B. Network Services is the section of Cloud Console that has the Cloud DNS console, sooption B is correct. Option A is incorrect; Compute Engine does not have DNS manage-ment forms. Neither does option C, Kubernetes Engine. Option D is related to networking,but the services in Hybrid Connectivity are for services such as VPNs.Chapter 16: Deploying Applicationswith Cloud Launcher and DeploymentManager"}],"16":[{"index":1,"questions":"1. What are the categories of Cloud Launcher solutions?","choices":["A. Data sets only","B. Operating systems only","C. Developer tools and operating systems only","D. Data sets, operating systems, and developer tools"],"answer":"1. D. Categories of solutions include all of the categories mentioned, so option D is correct.Others include Kubernetes Apps, API & Services, and Databases."},{"index":2,"questions":"2. What is the other name of Cloud Launcher?","choices":["A. Cloud Deployment Manager","B. Marketplace","C. Cloud Tools","D. Cloud Solutions: Third Party"],"answer":"2. B. The Cloud Launcher is also known as Marketplace, so option B is correct. Option A isincorrect because the Cloud Deployment Manager is used to create deployment templates.Options C and D are fictional names of services."},{"index":3,"questions":"3. Where do you navigate to launch a Cloud Launcher solution?","choices":["A. Overview page of the solution","B. Main Cloud Launcher page","C. Network Services","D. None of the above"],"answer":"3. A. You launch a solution by clicking the Launch on Compute Engine link in the overviewpage, so option A is correct. Option B is incorrect; the main page has summary informa-tion about the products. Option C is incorrect; Network Services is unrelated to this topic.Option D is incorrect because option A is the correct answer.Chapter16:DeployingApplicationswithCloudLauncherandDeploymentManager 497"},{"index":4,"questions":"4. You want to quickly identify the set of operating systems available in Cloud Launcher. Which of these steps would help with that?","choices":["A. Use Google Search to search the Web for a listing.","B. Use filters in Cloud Launcher.","C. Scroll through the list of solutions displayed on the start page of Cloud Launcher.","D. It is not possible to filter to operating systems."],"answer":"4. B. Cloud Launcher has a set of predefined filters, including filtering by operating system, sooption B is correct. Option A may eventually lead to the correct information, but it is notefficient. Option D is incorrect because it is impractical for such a simple task."},{"index":5,"questions":"5. You want to use Cloud Launcher to deploy a WordPress site. You notice there is more than one WordPress option. Why is that?","choices":["A. It’s a mistake. Submit a ticket to Google support.","B. Multiple vendors may offer the same application.","C. It’s a mistake. Submit a ticket to the vendors.","D. You will never see such an option."],"answer":"5. B. Multiple vendors may offer configurations for the same applications, so option B is cor-rect. This gives users the opportunity to choose the one best suited to their requirements.Options A and C are incorrect; this is a feature of Cloud Launcher. Option D is incorrectbecause option B is the correct answer."},{"index":6,"questions":"6. You have used Cloud Launcher to deploy a WordPress site and would now like to deploy a database. You notice that the configuration form for the databases is different from the form used with WordPress. Why is that?","choices":["A. It’s a mistake. Submit a ticket to Google support.","B. You’ve navigated to a different subform of Cloud Launcher.","C. Configuration properties are based on the application you are deploying and will be different depending on what application you are deploying.","D. This cannot happen. Review Questions 401"],"answer":"6. C. Cloud Launcher will display configuration options appropriate for the application youare deploying, so option C is correct. For example, when deploying WordPress, you willhave the option of deploying an administration tool for PHP. Option A is incorrect; this isa feature of Cloud Launcher. Option B is incorrect; you are not necessarily on the wrongform. Option D is incorrect; this is a feature of Cloud Launcher."},{"index":7,"questions":"7. You have been asked by your manager to deploy a WordPress site. You expect heavy traf- fic, and your manager wants to make sure the VM hosting the WordPress site has enough resources. Which resources can you configure when launching a WordPress site using Cloud Launcher?","choices":["A. Machine type","B. Disk type","C. Disk size","D. All of the above"],"answer":"7. D. You can change the configuration of any of the items listed, so option D is correct. Youcan also specify firewall rules to allow both HTTP and HTTPS traffic or change the zonein which the VM runs."},{"index":8,"questions":"8. You would like to define as code the configuration of a set of application resources. The GCP service for creating resources using a configuration file made up of resource specifica- tions defined in YAML syntax is called what?","choices":["A. Compute Engine","B. Deployment Manager","C. Marketplace Manager","D. Marketplace Deployer"],"answer":"8. B. Deployment Manager is the name of the service for creating application resourcesusing a YAML configuration file, so option B is correct. Option A is incorrect, althoughyou could use scripts with gcloudcommands to deploy resources in Compute Engine.Options C and D are incorrect because those are fictitious names of products."},{"index":9,"questions":"9. What file format is used to define Deployment Manager configuration files?","choices":["A. XML","B. JSON","C. CSV","D. YAML"],"answer":"9. D. Configuration files are defined in YAML syntax, so option D is correct. Options A, B,and C are all incorrect; configuration files are defined in YAML."},{"index":10,"questions":"10. A Deployment Manager configuration file starts with what term?","choices":["A. Deploy","B. Resources","C. Properties","D. YAML"],"answer":"10. B. Configuration files define resources and start with the term resources, so option B is cor-rect. Options A, B, and C are all incorrect. Those terms do not start the configuration file."},{"index":11,"questions":"11. Which of the following are used to define a resource in a Cloud Deployment Manager con- figuration file?","choices":["A. type only","B. properties only","C. name and type only","D. type, properties, and name"],"answer":"11. D. All three, type,propertie,sand name, are used when defining resources in a CloudDeployment Manager configuration file, so option D is correct."},{"index":12,"questions":"12. What properties may be set when defining a disk on a VM?","choices":["A. A device name only","B. A Boolean indicating a boot disk and a Boolean indicating autodelete","C. A Boolean indicating autodelete only","D. A device name, a Boolean indicating a boot disk, and a Boolean indicating autodelete402 Chapter 16 ■ Deploying Applications with Cloud Launcher"],"answer":"12. D. All three can be set; specifically, the keys are deviceNam,eboot, and autodelet.eOption D is correct."},{"index":13,"questions":"13. You need to look up what images are available in the zone in which you want to deploy a VM. What command would you use?","choices":["A. gcloud compute images list","B. gcloud images list","C. gsutil compute images list","D. gcloud compute list images"],"answer":"13. A. Option A is the correct command. Option B is incorrect; it is missing the term compute .Option C is incorrect; gsutilis the command for working with Cloud Storage. Option Dis incorrect because the terms listand imagesare in the wrong order."},{"index":14,"questions":"14. You want to use a template file with Deployment Manager. You expect the file to be complicated. What language would you use?","choices":["A. Jinja2","B. Ruby","C. Go","D. Python"],"answer":"14. D. Google recommends using Python for complicated templates, so option D is correct.Option A is incorrect because Jinja2 is recommended only for simple templates. Options Band C are incorrect; neither language is supported for templates."},{"index":15,"questions":"15. What command launches a deployment?","choices":["A. gcloud deployment-manager deployments create","B. gcloud cloud-launcher deployments create","C. gcloud deployment-manager deployments launch","D. gcloud cloud-launcher deployments launch"],"answer":"15. A. The correct answer is gcloud deployment-manager deployments cr,esa otoeptionA is correct. Options B and D are incorrect; the service is not called cloud-launcher in thecommand. Option C is incorrect; launchis not a valid verb for this command.498 Appendix ■ Answers to Review Questions"},{"index":16,"questions":"16. A DevOps engineer is noticing a spike in CPU utilization on your servers. You explain you have just launched a deployment. You’d like to show the DevOps engineer the details of a deployment you just launched. What command would you use?","choices":["A. gcloud cloud-launcher deployments describe","B. gcloud deployment-manage deployments list","C. gcloud deployment-manager deployments describe","D. gcloud cloud-launcher deployments list"],"answer":"16. C. The correct answer is gcloud deployment-manager deployments desc ,sibeoption C is correct. Options A and D are incorrect; cloud-launcheris not the name ofthe service. Option B is incorrect; listdisplays a brief summary of each deployment.describedisplays a detailed description."},{"index":17,"questions":"17. If you expand the More link in the Networking section when deploying a Cloud Launcher solution, what will you be able to configure?","choices":["A. IP addresses","B. Billing","C. Access controls","D. Custom machine type"],"answer":"17. A. You will be able to configure IP addresses, so option A is correct. You cannot configurebilling or access controls in Deployment Manager, so options B and C are incorrect. Youcan configure the machine type, but that is not the More section of Networking."},{"index":18,"questions":"18. What are the license types referenced in Cloud Launcher?","choices":["A. Free only","B. Free and Paid only","C. Free and Bring your own license (BYOL) only","D. Free, paid, and bring your own license Review Questions 403"],"answer":"18. D. The correct answer is option D because free, paid, and BYOL are all license optionsused in Cloud Launcher."},{"index":19,"questions":"19. Which license type will add charges to your GCP bill when using Cloud Launcher with this type of license?","choices":["A. Free","B. Paid","C. BYOL","D. Chargeback"],"answer":"19. B. The paid license types include payment for the license in your GCP charges, so option Bis correct. The free license type does not incur charges. The BYOL license type requires youto work with the software vendor to get and pay for a license. There is no such license typeas chargeback, so option D is incorrect."},{"index":20,"questions":"20. You are deploying a Cloud Launcher application that includes a LAMP stack. What soft- ware will this deploy?","choices":["A. Apache server and Linux only","B. Linux only","C. MySQL and Apache only","D. Apache, MySQL, Linux, and PHP ■ 420 Chapter 17 Configuring Access and Security Review Questions You can find the answers in the Appendix."],"answer":"20. D. LAMP is short for Linux, Apache, MySQL, and PHP. All are included when installingLAMP solutions, so option D is correct.Chapter 17: Configuring Accessand Security"}],"17":[{"index":1,"questions":"1. What does IAM stand for?","choices":["A. Identity and Authorization Management","B. Identity and Access Management","C. Identity and Auditing Management","D. Individual Access Management"],"answer":"1. B. IAM stands for Identity and Access Management, so option B is correct. Option A isincorrect; the A does not stand for authorization, although that is related. Option C isincorrect; the A does not stand for auditing, although that is related. Option D is incorrect.IAM also works with groups, not just individuals."},{"index":2,"questions":"2. When you navigate to IAM & Admin in Cloud Console, what appears in the main body of the page?","choices":["A. Members and roles assigned","B. Roles only","C. Members only","D. Roles and permissions assigned"],"answer":"2. A. Members and their roles are listed, so option A is correct. Options B and C are incorrectbecause they are missing the other main piece of information provided in the listing. Option Dis incorrect; permissions are not displayed on that page."},{"index":3,"questions":"3. Why are primitive roles classified in a category in addition to IAM?","choices":["A. They are part of IAM.","B. They were created before IAM.","C. They were created after IAM.","D. They are not related to access control."],"answer":"3. B. Primitive roles were created before IAM and provided coarse-grained access controls,so option B is correct. Option A is incorrect; they are used for access control. Option C isincorrect; IAM is the newer form of access control. Option D is incorrect; they do provideaccess control functionality."},{"index":4,"questions":"4. A developer intern is confused about what roles are used for. You describe IAM roles as a collection of what?","choices":["A. Identities","B. Permissions","C. Access control lists","D. Audit logs"],"answer":"4. B. Roles are used to group permissions that can then be assigned to identities, so option Bis correct. Option A is incorrect; roles do not have identities, but identities can be grantedroles. Option C is incorrect; roles do not use access control lists. Option D is incorrect;roles do not include audit logs. Logs are collected and managed by Stackdriver Logging."},{"index":5,"questions":"5. You want to list roles assigned to users in a project called ace-exam-project. What gcloud command would you use?","choices":["A. gcloud iam get-iam-policy ace-exam-project","B. gcloud projects list ace-exam-project","C. gcloud projects get-iam-policy ace-exam-project","D. gcloud iam list ace-exam-project Review Questions 421"],"answer":"5. C. The correct answer is gcloud projects get-iam-policy ace-exam-pro ,sectoption C is correct. Option A is incorrect because the resource should be projectsand notiam. Option B is incorrect; listdoes not provide detailed descriptions. Option D is incor-rect because iamand listare incorrectly referenced. Chapter 17: Configuring Access and Security 499"},{"index":6,"questions":"6. You are working in the form displayed after clicking the Add link in the IAM form of IAM & Admin in Cloud Console. There is a parameter called New Members. What items would you enter in that parameter?","choices":["A. Individual users only","B. Individual users or groups","C. Roles or individual users","D. Roles or groups"],"answer":"6. B. New members can be users, indicated by their email addresses, or groups, so option Bis correct. Option A is incorrect; it does not include groups. Options C and D are incorrectbecause roles are not added there."},{"index":7,"questions":"7. You have been assigned the App Engine Deployer role. What operations can you perform?","choices":["A. Write new versions of an application only","B. Read application configuration and settings only","C. Read application configuration and settings and write new configurations","D. Read application configuration and settings and write new versions"],"answer":"7. D. Deployers can read application configurations and settings and write new applicationversions, so option D is correct. Option A is incorrect because it is missing the ability toread configurations and settings. Option B is incorrect because it is missing writing newversions. Option C is incorrect because it references writing new configurations."},{"index":8,"questions":"8. You want to list permissions in a role using Cloud Console. Where would you go to see that?","choices":["A. IAM & Admin; select Roles. All permissions will be displayed.","B. IAM & Admin; select Roles. Check the box next to a role to display the permissions in that role.","C. IAM & Admin; select Audit Logs.","D. IAM & Admin; select Service Accounts and then Roles."],"answer":"8. B. The correct steps are navigating to IAM & Admin, selecting Roles, and then checkingthe box next to a role, so option B is correct. Option A is incorrect; all roles are not dis-played automatically. Option C is incorrect; audit logs do not display permissions. OptionD is incorrect; there is no Roles option in Service Accounts."},{"index":9,"questions":"9. You are meeting with an autidor to discuss security practices in the cloud. The auditor asks how you implement several best practices. You describe how IAM predefined roles help to implement which security best practice(s)?","choices":["A. Least privilege","B. Separation of duties","C. Defense in depth","D. Options A and B"],"answer":"9. D. Predefined roles help implement both least privilege and separation of duties, so optionD is correct. Predefined roles do not implement defense in depth by themselves but could beused with other security controls to implement defense in depth."},{"index":10,"questions":"10. What launch stages are available when creating custom roles?","choices":["A. Alpha and beta only","B. General availability only","C. Disabled only","D. Alpha, beta, general availability, and disabled"],"answer":"10. D. The four launch stages available are alpha, beta, general availability, and disabled, sooption D is correct."},{"index":11,"questions":"11. The gcloudcommand to create a custom role is what?","choices":["A. gcloud project roles create","B. gcloud iam roles create","C. gcloud project create roles","D. gcloud iam create roles422 Chapter 17 ■Configuring Access and Security"],"answer":"11. B. The correct answer, option B, is gcloud iam roles crea.tO eption A is incorrectbecause it references projectinstead of iam. Option C is incorrect because it referencesprojec t instead of iam, and the terms createand rolesare out of order. Option D isincorrect because the terms createand rolesare out of order."},{"index":12,"questions":"12. A DevOps engineer is confused about the purpose of scopes. Scopes are access controls that are applied to what kind of resources?","choices":["A. Storage buckets","B. VM instances","C. Persistent disks","D. Subnets"],"answer":"12. B. Scopes are permissions granted to VM instances, so option B is correct. Scopes in com-bination with IAM roles assigned to service accounts assigned to the VM instance deter-mine what operations the VM instance can perform. Options A and C are incorrect; scopesdo not apply to storage resources. Option D is incorrect; scopes do not apply to subnets."},{"index":13,"questions":"13. A scope is identified using what kind of identifier?","choices":["A. A randomly generated ID","B. A URL beginning with https://www.googleserviceaccounts/","C. A URL beginning with https://www.googleapis.com/auth/","D. A URL beginning with https://www.googleapis.com/auth/PROJEC]T_ID"],"answer":"13. C. Scope identifiers start with https://www.googleapis.com/aut an/d are followed bya scope-specific name, such as devstorage.read_onloy r logging.writ,eso option C iscorrect. Option A is incorrect; scope IDs are not randomly generated. Option B is incorrect;the domain name is not googleserviceaccoun.tO sption D is incorrect; scopes are notlinked directly to projects."},{"index":14,"questions":"14. A VM instance is trying to read from a Cloud Storage bucket. Reading the bucket is allowed by IAM roles granted to the service account of the VM. Reading buckets is denied by the scopes assigned to the VM. What will happen if the VM tries to read from the bucket?","choices":["A. The application performing the read will skip over the read operation.","B. The read will execute because the most permissive permission is allowed.","C. The read will not execute because both scopes and IAM roles are applied to determine what operations can be performed.","D. The read operation will succeed, but a message will be logged to Stackdriver Logging."],"answer":"14. C. Both scopes and IAM roles assigned to service accounts must allow an operation forit to succeed, so option C is correct. Option A is incorrect; access controls do not affectthe flow of control in applications unless explicitly coded for that. Option B is incorrect;the most permissive permission is not used. Option D is incorrect; the operation will notsucceed."},{"index":15,"questions":"15. What are the options for setting scopes in a VM?","choices":["A. Allow Default Access and Allow Full Access only","B. Allow Default Access, Allow Full Access, and Set Access for Each API","C. Allow Full Access or Set Access For Each API only","D. Allow Default Access and Set Access For Each API only"],"answer":"15. B. The options for setting scopes are: Allow Default Access, Allow Full Access, and SetAccess For Each API, so option B is correct. Option A is incorrect; it is missing Set AccessFor Each API. Option C is incorrect; it is missing Allow Default Access. Option D is incor-rect; it is missing Allow Full Access."},{"index":16,"questions":"16. What gcloudcommand would you use to set scopes?","choices":["A. gcloud compute instances set-scopes","B. gcloud compute instances set-service-account","C. gcloud compute service-accounts set-scopes","D. gcloud compute service-accounts define-scopes"],"answer":"16. B. The correct command is gcloud compute instances set-service-acc,osu ontoption B is correct. Option A is incorrect; there is no set-scopescommand verb. Option Cis incorrect; the command verb is not set-scope.sOption D is incorrect; there is no commandverb define-scope.s500 Appendix ■Answers to Review Questions"},{"index":17,"questions":"17. What gcloudcommand would you use to assign a service account when creating a VM?","choices":["A. gcloud compute instances create [INSTANCE_NAME] --service-account [SERVICE_ACCOUNT_EMAIL]","B. gcloud compute instances create-service-account [INSTANCE_NAME][SERVICE_ACCOUNT_EMAIL]","C. gcloud compute instances define-service-account [INSTANCE_NAME][SERVICE_ACCOUNT_EMAIL]","D. gcloud compute create instances-service-account [INSTANCE_NAME][SERVICE_ACCOUNT_EMAIL] Review Questions 423"],"answer":"17. A. You can assign a service account when creating a VM using the createcommand.Option B is incorrect; there is no create-service-accoun command verb. Option C isincorrect; there is no define-service-accoun command verb. Option D is incorrect;there is no instances-service-account comm;aanls do, createshould come at the end ofthe command."},{"index":18,"questions":"18. What GCP service is used to view audit logs?","choices":["A. Compute Engine","B. Cloud Storage","C. Stackdriver Logging","D. Custom logging"],"answer":"18. C. Stackdriver Logging collects, stores, and displays log messages, so option C is correct.Option A is incorrect; Compute Engine does not manage logs. Option B is incorrect; CloudStorage is not used to view logs, although log files can be stored there. Option D is incor-rect; custom logging solutions are not GCP services."},{"index":19,"questions":"19. What options are available for filtering log messages when viewing audit logs?","choices":["A. Period time and log level only","B. Resource, type of log, log level, and period of time only","C. Resource and period of time only","D. Type of log only"],"answer":"19. B. Logs can be filtered by resource, type of logs, log level, and period of time only, sooption B is correct. Options A, C, and D are incorrect because they are missing at leastone option."},{"index":20,"questions":"20. An auditor needs to review audit logs. You assign read-only permission to a custom role you create for auditors. What security best practice are you following?","choices":["A. Defense in depth","B. Least privilege","C. Separation of duties","D. Vulnerability scanning Review Questions 459 Review Questions"],"answer":"20. B. This is an example of assigning the least privilege required to perform a task, so optionB is correct. Option A is incorrect; defense in depth combines multiple security controls.Option C is incorrect because it is having different people perform sensitive tasks. Option Dis incorrect; vulnerability scanning is a security measure applied to applications that helpsreveal potential vulnerabilities in an application that an attacker could exploit.Chapter 18: Monitoring, Logging, andCost Estimating"}],"18":[{"index":1,"questions":"1. What Stackdriver service is used to generate alerts when the CPU utilization of a VM exceeds 80 percent?","choices":["A. Logging","B. Monitoring","C. Cloud Trace","D. Cloud Debug"],"answer":"1. B. The Monitoring service is used to set a threshold on metrics and generate alerts when ametric exceeds the threshold for a specified period of time, so option B is correct. Option Ais incorrect; Logging is for collecting logged events. Option C is incorrect; Cloud Trace isfor application tracing. Option D is incorrect; Debug is used to debug applications."},{"index":2,"questions":"2. You have just created a virtual machine, and you’d like Stackdriver Monitoring to alert you via email whenever the CPU average utilization exceeds 75 percent for 5 minutes. What do you need to do to the VM to have this happen?","choices":["A. Install a Stackdriver workspace","B. Install the Stackdriver monitoring agent on the VM","C. Edit the VM configuration in Cloud Console and check the Monitor With Stackdriver checkbox","D. Set a notification channel"],"answer":"2. B. You must install the monitoring agent on the VM. The agent will collect data and sendit to Stackdriver, so option B is correct. Option A is incorrect because a Workspace is notinstalled on a VM; it is created in Stackdriver. Option C is incorrect; there is no MonitorWith Stackdriver check box in the VM configuration form. Option D is incorrect becauseyou set notification channels in Stackdriver, not on a VM."},{"index":3,"questions":"3. Stackdriver can be used to monitor resources where?","choices":["A. In Google Cloud Platform only","B. In Google Cloud Platform and Amazon Web Services only","C. In Google Cloud Platform and on premises data centers","D. In Google Cloud Platform, Amazon Web Services, and on premises data centers"],"answer":"3. D. Stackdriver can monitor resources in GCP, AWS, and in on-premise data centers, sooption D is correct. Options A through C are incorrect because they do not include twoother correct options."},{"index":4,"questions":"4. Grouping a set of metrics that arrive in a period of time into regular-sized buckets is called what?","choices":["A. Aggregation","B. Alignment","C. Minimization","D. Consolidation"],"answer":"4. B. Aligning is the process of separating data points into regular buckets, so option B iscorrect. Option A is incorrect; aggregation is used to combine data points using a statistic,such as mean. Options C and D are incorrect; they are not processes related to processingstreams of metric data."},{"index":5,"questions":"5. You have created a condition of CPU utilization, and you want to receive notifications. Which of the following are options?","choices":["A. Email only","B. PagerDuty only","C. Hipchat and PagerDuty","D. Email, PagerDuty, and Hipchat460 Chapter 18 ■ Monitoring, Logging, and Cost Estimating"],"answer":"5. D. All three options are valid notification channels in Stackdriver Monitoring, so option Dis correct. PagerDuty and HipChat are popular DevOps tools. Chapter 18: Monitoring, Logging, and Cost Estimating 501"},{"index":6,"questions":"6. When you create a policy to notify you of a potential problem with your infrastructure, you can specify optional documentation. Why would you bother putting documentation in that form?","choices":["A. It is saved to Cloud Storage for future use.","B. It can help you or a colleague understand the purpose of the policy.","C. It can contain information that would help someone diagnose and correct the problem.","D. Options B and C."],"answer":"6. D. The documentation is useful for documenting the purpose of the policy and for provid-ing guidance for solving the problem, so option D is correct. Option A is incorrect; wherea policy is stored is irrelevant to its usefulness. Options B and C alone are partially correct,but option D is a better answer."},{"index":7,"questions":"7. What is alert fatigue, and why is it a problem?","choices":["A. Too many alert notifications are sent for events that do not require human intervention, and eventually DevOps engineers begin to pay less attention to notifications.","B. Too many alerts put unnecessary load on your systems.","C. Too few alerts leave DevOps engineers uncertain of the state of your applications and infrastructure.","D. Too many false alerts"],"answer":"7. A. Alert fatigue is a state caused by too many alert notifications being sent for events thatdo not require human intervention, so option A is correct. This creates the risk that eventu-ally DevOps engineers will begin to pay less attention to notifications. Option B is incor-rect, although it is conceivable that too many alerts could adversely impact performance,but that is not likely. Option C is a potential problem, too, but that is not alert fatigue.Option D is incorrect because too many true alerts contribute to alert fatigue."},{"index":8,"questions":"8. How long is log data stored in Stackdriver Logging?","choices":["A. 7 days","B. 15 days","C. 30 days","D. 60 days"],"answer":"8. C. Stackdriver Logging stores log entries for 30 days, so option C is correct."},{"index":9,"questions":"9. You need to store log entries for a longer period of time than Stackdriver Logging retains them. What is the best option for preserving log data?","choices":["A. There is no option; once the data retention period passes, Stackdriver Logging deletes the data.","B. Create a log sink and export the log data using Stackdriver Logging’s export functionality.","C. Write a Python script to use the Stackdriver API to write the data to Cloud Storage.","D. Write a Python script to use the Stackdriver API to write the data to BigQuery."],"answer":"9. B. The best option is to use Stackdriver Logging’s export functionality to write log datato a log sink, so option B is correct. Option A is incorrect; there is a way to export data.Options C and D are incorrect because writing a custom script would take more time todevelop and maintain than using Logging’s export functionality."},{"index":10,"questions":"10. Which of the following are options for logging sinks?","choices":["A. Cloud Storage bucket only","B. BigQuery dataset and Cloud Storage bucket only","C. Cloud Pub/Sub topic only","D. Cloud Storage bucket, BigQuery dataset, and Cloud Pub/Sub topic"],"answer":"10. D. All three, Cloud Storage buckets, BigQuery data sets, and Cloud Pub/Sub topics, areavailable as sinks for logging exports, so option D is correct."},{"index":11,"questions":"11. Which of the following can be used to filter log entries when viewing logs in Stackdriver Logging?","choices":["A. Label or text search only","B. Resource type and log type only Review Questions 461","C. Time and resource type only","D. Label or text search, resource type, log type, and time"],"answer":"11. D. All of the options listed can be used to filter, so option D is correct. Log level is anotheroption as well."},{"index":12,"questions":"12. Which of the following is not a standard log level that can be used to filter log viewings?","choices":["A. Critical","B. Halted","C. Warning","D. Info"],"answer":"12. B. The correct answer, option B, is halted. There is no such standard log level status. Sta-tuses include Critical, Error, Warning, Info, and Debug."},{"index":13,"questions":"13. You are viewing log entries and spot one that looks suspicious. You are not familiar with the kind of log entry, and you want to see the complete details of the log entry as quickly as possible. What would you do?","choices":["A. Drill down one by one into each structure in the log entry.","B. Click Expand all to show all details.","C. Write a Python script to reformat the log entry.","D. Click the Show Detail link next to the log entry."],"answer":"13. B. The fastest way to see the details is to expand all levels of structured data in the entry,so option B is correct. Option A would show the details, but it is not the fastest way. OptionC is more time-consuming than using the functionality built into Stackdriver Logging.Option D is incorrect; there is no such link."},{"index":14,"questions":"14. What Stackdriver service is best for identifying where bottlenecks exist in your application?","choices":["A. Monitoring","B. Logging","C. Trace","D. Debug"],"answer":"14. C. Cloud Trace is a distributed tracing application that provides details on how long dif-ferent parts of code run, so option C is correct. Option A is incorrect; monitoring is usedto notify DevOps engineers when resources are not functioning as expected. Option B isincorrect; Logging is for collecting, storing, and viewing log data, and although log entriesmight help diagnose bottlenecks, it is not specifically designed for that. Option D is incor-rect; Debug is used to generate snapshots and inject logpoints."},{"index":15,"questions":"15. There is a bug in a microservice. You have reviewed application outputs but cannot identify the problem. You decide you need to step through the code. What Stackdriver service would you use to give you insight into the status of the services at particular points in execution?","choices":["A. Monitoring","B. Logging","C. Trace","D. Debug"],"answer":"15. D. Debug is used to generate snapshots that provide a view of the status of an applicationat a particular point in its execution, so option D is correct. Option A is incorrect; moni-toring is used to notify DevOps engineers when resources are not functioning as expected.Option B is incorrect; Logging is for collecting, storing, and viewing log data. Option C isincorrect because Cloud Trace is a distributed tracing application that provides details onhow long different parts of code run.502 Appendix ■ Answers to Review Questions"},{"index":16,"questions":"16. You believe there may be a problem with BigQuery in the us-central zone. Where would you go to check the status of the BigQuery service for the quickest access to details?","choices":["A. Email Google Cloud Support.","B. Check https://status.cloud.google.c.om/","C. Check https://bigquery.status.cloud.google..com/","D. Call Google tech support.462 Chapter 18 ■ Monitoring, Logging, and Cost Estimating"],"answer":"16. B. The Google Cloud Status Dashboard at https://status.cloud.google.co hasinformation on the status of GCP services, so option B is correct. Options A and B mightlead to information, but they would take longer. Option C is not a link to a source of infor-mation on BigQuery."},{"index":17,"questions":"17. You would like to estimate the cost of GCP resources you will be using. Which services would require you to have information on the virtual machines you will be using?","choices":["A. Compute Engine and BigQuery","B. Compute Engine and Kubernetes Engine","C. BigQuery and Kubernetes Engine","D. BigQuery and Cloud Pub/Sub"],"answer":"17. B. Both Compute Engine and Kubernetes Engine will require details about the VMs’ con-figurations, so option B is correct. The other options are incorrect because BigQuery andCloud Pub/Sub are serverless services."},{"index":18,"questions":"18. You are generating an estimate of the cost of using BigQuery. One of the parameters is Query Pricing. You have to specify a value in TB units. What is the value you are specifying?","choices":["A. The amount of data stored in BigQuery","B. The amount of data returned by the query","C. The amount of data scanned by the query","D. The amount of data in Cloud Storage bucket"],"answer":"18. C. Query pricing in BigQuery is based on the amount of data scanned, so option C is cor-rect. Option A is incorrect; the amount of data storage is specified in the Storage Pricingsection. Option B is incorrect; query pricing is not based on the volume of data returned.Option D is incorrect because this is not related to Cloud Storage. Option D is incorrectbecause option C is correct."},{"index":19,"questions":"19. Why do you need to specify the operating system to be used when estimating the cost of a VM?","choices":["A. All operating systems are charged a fixed rate.","B. Some operating systems incur a cost.","C. It’s not necessary; it is only included for documentation.","D. To estimate the cost of Bring Your Own License configurations."],"answer":"19. B. Some operating systems, like Microsoft Windows Server, require a license, so option Bis correct. Google sometimes has arrangements with vendors to collect fees for using pro-prietary software. Option A is incorrect; there is no fixed rate charge for operating systems.Option C is incorrect; the information is sometimes needed to compute charges. Option Dis incorrect because if you Bring Your Own License, there is no additional license charge."},{"index":20,"questions":"20. You want to create a custom metric for use in Stackdriver Monitoring but do not want to use the low-level Stackdriver API. What is an alternative open source option for working with custom metrics?","choices":["A. Prometheus","B. OpenCensus","C. Grafana"],"answer":"20. B. OpenCensus is a library for developing custom metrics that can be used with StackdriverLogging, so option B is correct. Option A is incorrect; Prometheus is an open source moni-toring tool, but it is not used to define custom metrics in Stackdriver Monitoring. Option Cis incorrect; Grafana is a visualization tools for Prometheus. Option D is incorrect; Nagiosis an open source monitoring and alerting service, but it is not used for defining custommetrics in Stackdriver Logging."}]}